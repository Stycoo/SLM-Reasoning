+ export VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ MODEL_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k
+ OUTPUT_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs
+ GPU_NUM=8
+ TP=1
+ TEMP=0.6
+ TOP_P=0.95
+ MAX_LEN=32768
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 14:47:21,387	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=737135)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=737135)[0m No module named 'vllm._version'
[36m(pid=737135)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=737492)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=737492)[0m No module named 'vllm._version'
[36m(pid=737492)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=737476)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=737476)[0m No module named 'vllm._version'
[36m(pid=737476)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=737135)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=737502)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=737502)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=737502)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=737135)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=737502)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 116, in _wrapper
[36m(ActorRolloutRefWorker pid=737476)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=737476)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
[36m(ActorRolloutRefWorker pid=737476)[0m     output: SamplerOutput = self.model.sample(
[36m(ActorRolloutRefWorker pid=737476)[0m                             ^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
[36m(ActorRolloutRefWorker pid=737476)[0m     next_tokens = self.sampler(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=737476)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[36m(ActorRolloutRefWorker pid=737476)[0m     return self._call_impl(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=737476)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[36m(ActorRolloutRefWorker pid=737476)[0m     return forward_call(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=737476)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
[36m(ActorRolloutRefWorker pid=737476)[0m     self._init_sampling_tensors(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
[36m(ActorRolloutRefWorker pid=737476)[0m     do_min_p) = SamplingTensors.from_sampling_metadata(
[36m(ActorRolloutRefWorker pid=737476)[0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
[36m(ActorRolloutRefWorker pid=737476)[0m     sampling_tensors = SamplingTensors.from_lists(
[36m(ActorRolloutRefWorker pid=737476)[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
[36m(ActorRolloutRefWorker pid=737476)[0m     temperatures_t = torch.tensor(
[36m(ActorRolloutRefWorker pid=737476)[0m                      ^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m RuntimeError: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=737476)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=737476)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=737476)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=737476)[0m 
[36m(ActorRolloutRefWorker pid=737476)[0m 
[36m(ActorRolloutRefWorker pid=737476)[0m The above exception was the direct cause of the following exception:
[36m(ActorRolloutRefWorker pid=737476)[0m 
[36m(ActorRolloutRefWorker pid=737476)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
[36m(ActorRolloutRefWorker pid=737476)[0m     output = self.inference_engine.generate(
[36m(ActorRolloutRefWorker pid=737476)[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
[36m(ActorRolloutRefWorker pid=737476)[0m     return fn(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=737476)[0m            ^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
[36m(ActorRolloutRefWorker pid=737476)[0m     outputs = self._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=737476)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
[36m(ActorRolloutRefWorker pid=737476)[0m     outputs = super()._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=737476)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
[36m(ActorRolloutRefWorker pid=737476)[0m     step_outputs = self.llm_engine.step()
[36m(ActorRolloutRefWorker pid=737476)[0m                    ^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
[36m(ActorRolloutRefWorker pid=737476)[0m     outputs = self.model_executor.execute_model(
[36m(ActorRolloutRefWorker pid=737476)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
[36m(ActorRolloutRefWorker pid=737476)[0m     all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
[36m(ActorRolloutRefWorker pid=737476)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
[36m(ActorRolloutRefWorker pid=737476)[0m     return self.model_runner.execute_model(
[36m(ActorRolloutRefWorker pid=737476)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(ActorRolloutRefWorker pid=737476)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=737476)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=737476)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
[36m(ActorRolloutRefWorker pid=737476)[0m     raise type(err)(f"Error in model execution: "
[36m(ActorRolloutRefWorker pid=737476)[0m RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=737476)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=737476)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=737476)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=737476)[0m 
[36m(ActorRolloutRefWorker pid=737500)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m   warnings.warn([32m [repeated 7x across cluster][0m
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=737135)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=737135)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30",
[36m(ActorRolloutRefWorker pid=737135)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=737135)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=737135)[0m   ],
[36m(ActorRolloutRefWorker pid=737135)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=737135)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=737135)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=737135)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=737135)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=737135)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=737135)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=737135)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=737135)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=737135)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=737135)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=737135)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=737135)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=737135)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=737135)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=737135)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=737135)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=737135)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=737135)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=737135)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=737135)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=737135)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=737135)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=737135)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=737135)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=737135)[0m }
[36m(ActorRolloutRefWorker pid=737135)[0m 
[36m(ActorRolloutRefWorker pid=737135)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=737135)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=737135)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14b75c3ffec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=737135)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=737502)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1445b00d3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:48:11 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=737135)[0m WARNING 03-21 14:48:11 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=737135)[0m local rank 0
[36m(ActorRolloutRefWorker pid=737476)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=737135)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=737502)[0m INFO 03-21 14:48:11 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737502)[0m WARNING 03-21 14:48:11 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=737502)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=737135)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=737135)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=737502)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 500
wg.worker_names: ['W5WuIjActorRolloutRefWorker_0:0', 'W5WuIjActorRolloutRefWorker_0:1', 'W5WuIjActorRolloutRefWorker_0:2', 'W5WuIjActorRolloutRefWorker_0:3', 'W5WuIjActorRolloutRefWorker_0:4', 'W5WuIjActorRolloutRefWorker_0:5', 'W5WuIjActorRolloutRefWorker_0:6', 'W5WuIjActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:48:26 metrics.py:345] Avg prompt throughput: 1100.6 tokens/s, Avg generation throughput: 491.3 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=737500)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:48:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3137.6 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:48:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3139.5 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:48:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3128.8 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:48:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3064.2 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:48:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2907.1 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:48:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2489.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:49:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2255.8 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:49:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2082.7 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:49:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2010.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:49:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1733.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:49:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1594.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:49:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1545.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:49:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1508.6 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:49:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1407.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:49:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1241.8 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:49:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1112.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:49:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1019.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:50:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 860.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:50:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 919.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:50:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 854.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:50:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 937.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:50:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 902.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:50:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 602.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:50:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 593.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:50:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 540.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:50:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 518.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:50:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 476.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:50:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:51:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 457.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:51:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 661.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:51:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 411.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:51:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 410.2 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:51:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 410.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:51:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 409.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:51:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 410.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:51:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 332.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:51:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 332.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:51:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 332.6 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:52:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 534.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:52:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 474.0 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:52:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 308.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:52:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 249.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:52:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:52:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737499)[0m INFO 03-21 14:52:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 267.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:52:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 333.6 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:52:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 323.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:52:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:52:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:53:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 142.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:53:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 141.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:53:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 142.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737135)[0m INFO 03-21 14:53:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 141.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737499)[0m INFO 03-21 14:53:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 201.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:53:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=737500)[0m INFO 03-21 14:53:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=737476)[0m INFO 03-21 14:53:35 model_runner_base.py:120] Writing input of failed execution to /tmp/err_execute_model_input_20250321-145335.pkl...
[36m(ActorRolloutRefWorker pid=737476)[0m WARNING 03-21 14:53:35 model_runner_base.py:143] Failed to pickle inputs of failed execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=737476)[0m WARNING 03-21 14:53:35 model_runner_base.py:143] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=737476)[0m WARNING 03-21 14:53:35 model_runner_base.py:143] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=737476)[0m WARNING 03-21 14:53:35 model_runner_base.py:143] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=737476)[0m WARNING 03-21 14:53:35 model_runner_base.py:143] 
[36m(ActorRolloutRefWorker pid=737476)[0m Restarting vLLM due to error:  Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=737476)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=737476)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=737476)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=737476)[0m 
[36m(ActorRolloutRefWorker pid=737476)[0m Retrying...
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=1', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.95', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 147, in main
    output = wg.generate_sequences(data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=737476, ip=99.72.4.18, actor_id=a5897e45f0f1085e9b62c13501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14e912b086d0>)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
    output: SamplerOutput = self.model.sample(
                            ^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
    next_tokens = self.sampler(logits, sampling_metadata)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
    self._init_sampling_tensors(logits, sampling_metadata)
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
    do_min_p) = SamplingTensors.from_sampling_metadata(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
    sampling_tensors = SamplingTensors.from_lists(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
    temperatures_t = torch.tensor(
                     ^^^^^^^^^^^^^
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=737476, ip=99.72.4.18, actor_id=a5897e45f0f1085e9b62c13501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14e912b086d0>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
    output = self.inference_engine.generate(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
    outputs = self._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
    outputs = super()._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
    step_outputs = self.llm_engine.step()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
    outputs = self.model_executor.execute_model(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
    all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
    return self.model_runner.execute_model(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
    raise type(err)(f"Error in model execution: "
RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=737476, ip=99.72.4.18, actor_id=a5897e45f0f1085e9b62c13501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14e912b086d0>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 447, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 276, in generate_sequences
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=737476, ip=99.72.4.18, actor_id=a5897e45f0f1085e9b62c13501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14e912b086d0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 439, in generate_sequences
    with self.rollout_sharding_manager:
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/sharding_manager/fsdp_vllm.py", line 105, in __exit__
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 14:53:54,963	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=756229)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=756229)[0m No module named 'vllm._version'
[36m(pid=756229)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=757121)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=757121)[0m No module named 'vllm._version'
[36m(pid=757121)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=757122)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=757122)[0m No module named 'vllm._version'
[36m(pid=757122)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=757121)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=757126)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=757126)[0m   warnings.warn(
[36m(pid=757126)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=757126)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=757126)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (19791 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=756229)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=756229)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30",
[36m(ActorRolloutRefWorker pid=756229)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=756229)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=756229)[0m   ],
[36m(ActorRolloutRefWorker pid=756229)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=756229)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=756229)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=756229)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=756229)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=756229)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=756229)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=756229)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=756229)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=756229)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=756229)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=756229)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=756229)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=756229)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=756229)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=756229)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=756229)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=756229)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=756229)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=756229)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=756229)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=756229)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=756229)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=756229)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=756229)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=756229)[0m }
[36m(ActorRolloutRefWorker pid=756229)[0m 
[36m(ActorRolloutRefWorker pid=756229)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=756229)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=756229)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14343e543ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=756229)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:54:14 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=757126)[0m WARNING 03-21 14:54:14 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=757124)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1440d3bd3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=757126)[0m local rank 0
[36m(ActorRolloutRefWorker pid=757126)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=756229)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=756229)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:54:14 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m WARNING 03-21 14:54:14 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=757122)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=756229)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['CA7kcMActorRolloutRefWorker_0:0', 'CA7kcMActorRolloutRefWorker_0:1', 'CA7kcMActorRolloutRefWorker_0:2', 'CA7kcMActorRolloutRefWorker_0:3', 'CA7kcMActorRolloutRefWorker_0:4', 'CA7kcMActorRolloutRefWorker_0:5', 'CA7kcMActorRolloutRefWorker_0:6', 'CA7kcMActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:54:26 metrics.py:345] Avg prompt throughput: 1684.6 tokens/s, Avg generation throughput: 669.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=757122)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:54:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2978.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:54:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2979.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:54:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2977.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:54:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2978.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:54:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3005.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:54:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3002.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:55:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3004.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:55:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3002.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:55:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2755.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:55:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2972.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:55:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2936.0 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:55:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2883.6 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757125)[0m INFO 03-21 14:55:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2960.6 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757125)[0m INFO 03-21 14:55:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2928.1 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:55:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2744.3 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:55:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2716.2 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:55:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2703.1 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:55:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2697.3 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:56:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2661.9 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:56:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2487.8 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:56:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2600.6 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:56:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2568.8 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:56:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2514.6 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:56:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2216.9 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:56:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2431.8 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:56:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2476.7 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 14:56:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2335.6 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 14:56:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2333.8 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 14:56:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2329.6 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 14:57:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2285.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:57:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2170.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:57:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2166.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:57:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2119.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:57:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2101.2 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:57:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2068.7 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:57:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2198.6 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:57:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2203.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:57:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2202.0 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 14:57:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2028.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:57:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2019.4 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:58:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2010.5 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:58:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2007.5 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:58:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1989.7 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:58:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1957.5 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:58:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1873.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:58:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1861.3 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:58:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1588.8 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:58:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1834.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:58:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1879.5 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 14:58:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1370.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 14:58:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1616.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 14:59:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1822.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 14:59:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1808.4 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 14:59:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1791.1 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 14:59:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1576.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:59:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1693.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 14:59:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1681.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:59:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1527.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 14:59:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1520.0 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 14:59:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1524.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 14:59:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1540.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 14:59:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1531.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:00:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1521.1 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:00:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1506.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:00:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1259.8 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:00:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1208.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:00:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1460.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:00:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1430.3 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:00:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1397.7 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:00:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1381.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757121)[0m INFO 03-21 15:00:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1181.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757121)[0m INFO 03-21 15:00:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1179.9 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:00:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1230.1 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:01:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1167.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757120)[0m INFO 03-21 15:01:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1079.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:01:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1236.7 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:01:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1105.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:01:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1090.9 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:01:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1133.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757121)[0m INFO 03-21 15:01:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1028.3 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757121)[0m INFO 03-21 15:01:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1024.0 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:01:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1105.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:01:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1102.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:01:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1093.9 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:02:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1082.1 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:02:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1066.5 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 15:02:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 739.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:02:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1020.6 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 15:02:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 639.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:02:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 985.0 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:02:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 983.6 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:02:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 764.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:02:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 761.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:02:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 749.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m INFO 03-21 15:02:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 749.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:03:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 759.5 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:03:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 702.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757126)[0m INFO 03-21 15:03:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 621.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757121)[0m INFO 03-21 15:03:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 579.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=757121)[0m INFO 03-21 15:03:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 580.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:03:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 864.3 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:03:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 801.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:03:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 778.7 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=756229)[0m INFO 03-21 15:03:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 755.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 15:03:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 459.0 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=757124)[0m INFO 03-21 15:03:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:03:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 793.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:04:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 754.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:04:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 753.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=757123)[0m INFO 03-21 15:04:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 751.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                             |
+======================+===================================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30 |
+----------------------+---------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                      |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@1               | 0.29375                                                                                           |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@16              | 0.6333333333333333                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| cons@16              | 0.5                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16459.702083333334                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| run_hours            | 0.17676074743270875                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=757122)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=757122)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 15:04:43,710	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=785393)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=785393)[0m No module named 'vllm._version'
[36m(pid=785393)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=786335)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=786335)[0m No module named 'vllm._version'
[36m(pid=786335)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=786338)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=786338)[0m No module named 'vllm._version'
[36m(pid=786338)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=785393)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=786341)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=786341)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=786341)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=786334)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=786341)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (32602 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=785393)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=785393)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60",
[36m(ActorRolloutRefWorker pid=785393)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=785393)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=785393)[0m   ],
[36m(ActorRolloutRefWorker pid=785393)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=785393)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=785393)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=785393)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=785393)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=785393)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=785393)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=785393)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=785393)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=785393)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=785393)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=785393)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=785393)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=785393)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=785393)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=785393)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=785393)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=785393)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=785393)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=785393)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=785393)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=785393)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=785393)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=785393)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=785393)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=785393)[0m }
[36m(ActorRolloutRefWorker pid=785393)[0m 
[36m(ActorRolloutRefWorker pid=785393)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=785393)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=785393)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x15238fe9bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=785393)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=786341)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14d445c77ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786338)[0m INFO 03-21 15:05:32 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=786338)[0m WARNING 03-21 15:05:32 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=786338)[0m local rank 0
[36m(ActorRolloutRefWorker pid=786334)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=785393)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=785393)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:05:34 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m WARNING 03-21 15:05:34 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=786341)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 500
wg.worker_names: ['wV5atkActorRolloutRefWorker_0:0', 'wV5atkActorRolloutRefWorker_0:1', 'wV5atkActorRolloutRefWorker_0:2', 'wV5atkActorRolloutRefWorker_0:3', 'wV5atkActorRolloutRefWorker_0:4', 'wV5atkActorRolloutRefWorker_0:5', 'wV5atkActorRolloutRefWorker_0:6', 'wV5atkActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
[36m(ActorRolloutRefWorker pid=785393)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=785393)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:05:45 metrics.py:345] Avg prompt throughput: 1097.9 tokens/s, Avg generation throughput: 439.8 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=785393)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:05:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3091.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786340)[0m INFO 03-21 15:05:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3115.6 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:06:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3101.8 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:06:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3103.5 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:06:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2992.7 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:06:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2896.7 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:06:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2764.7 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:06:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2311.8 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:06:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2087.3 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:06:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1716.5 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:06:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2014.1 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:06:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1950.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:06:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1923.1 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:06:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1873.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:07:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1240.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:07:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1031.6 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:07:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 825.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:07:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 743.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:07:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 920.8 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:07:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1234.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:07:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1115.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:07:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1019.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:07:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 803.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:07:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 579.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:07:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 580.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:08:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 580.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:08:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 673.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:08:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 674.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:08:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 674.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:08:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 673.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:08:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 672.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:08:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 691.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:08:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 649.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:08:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 629.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:08:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 644.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:08:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 394.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:09:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 394.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:09:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 361.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:09:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 333.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786338)[0m INFO 03-21 15:09:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 580.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786338)[0m INFO 03-21 15:09:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 535.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:09:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 413.2 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:09:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 413.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:09:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 413.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:09:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 413.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:09:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:09:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:10:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:10:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:10:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 396.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:10:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:10:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:10:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.4 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:10:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:10:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.0 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:10:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 457.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:10:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 202.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:10:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:11:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:11:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:11:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786338)[0m INFO 03-21 15:11:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 344.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:11:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 202.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:11:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 202.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:11:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 202.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:11:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 202.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:11:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:11:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786339)[0m INFO 03-21 15:11:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:11:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 333.0 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:12:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 333.1 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:12:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 332.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:12:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 291.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:12:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:12:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:12:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:12:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:12:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 212.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:12:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 212.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:12:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 212.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786338)[0m INFO 03-21 15:12:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 210.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:13:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:13:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:13:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:13:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:13:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:13:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:13:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:13:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m INFO 03-21 15:13:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=786334)[0m INFO 03-21 15:13:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=786338)[0m INFO 03-21 15:13:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 210.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=786338)[0m INFO 03-21 15:14:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 210.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:14:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=786335)[0m INFO 03-21 15:14:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=786341)[0m INFO 03-21 15:14:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                             |
+======================+===================================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 |
+----------------------+---------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                      |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@1               | 0.828                                                                                             |
+----------------------+---------------------------------------------------------------------------------------------------+
| cons@1               | 0.828                                                                                             |
+----------------------+---------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5562.54                                                                                           |
+----------------------+---------------------------------------------------------------------------------------------------+
| run_hours            | 0.16379033711221483                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=785393)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=785393)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 15:14:47,387	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=812401)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=812401)[0m No module named 'vllm._version'
[36m(pid=812401)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=813335)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=813335)[0m No module named 'vllm._version'
[36m(pid=813335)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=813339)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=813339)[0m No module named 'vllm._version'
[36m(pid=813339)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=813335)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=813337)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=813337)[0m   warnings.warn(
[36m(pid=813336)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=813336)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=813336)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=813336)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (21616 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=812401)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=812401)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60",
[36m(ActorRolloutRefWorker pid=812401)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=812401)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=812401)[0m   ],
[36m(ActorRolloutRefWorker pid=812401)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=812401)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=812401)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=812401)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=812401)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=812401)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=812401)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=812401)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=812401)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=812401)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=812401)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=812401)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=812401)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=812401)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=812401)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=812401)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=812401)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=812401)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=812401)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=812401)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=812401)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=812401)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=812401)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=812401)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=812401)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=812401)[0m }
[36m(ActorRolloutRefWorker pid=812401)[0m 
[36m(ActorRolloutRefWorker pid=812401)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=812401)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=812401)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x147c537d3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=812401)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:15:05 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=813335)[0m WARNING 03-21 15:15:05 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=813335)[0m local rank 0
[36m(ActorRolloutRefWorker pid=813336)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x15157869fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=813337)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=812401)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=812401)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:15:06 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m WARNING 03-21 15:15:06 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=813338)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=812401)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['Cj6kveActorRolloutRefWorker_0:0', 'Cj6kveActorRolloutRefWorker_0:1', 'Cj6kveActorRolloutRefWorker_0:2', 'Cj6kveActorRolloutRefWorker_0:3', 'Cj6kveActorRolloutRefWorker_0:4', 'Cj6kveActorRolloutRefWorker_0:5', 'Cj6kveActorRolloutRefWorker_0:6', 'Cj6kveActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:15:18 metrics.py:345] Avg prompt throughput: 1690.1 tokens/s, Avg generation throughput: 647.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=813338)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:15:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3007.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:15:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2990.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:15:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3029.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:15:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3001.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:15:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3000.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:15:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3005.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:15:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3013.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:15:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3014.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:16:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2753.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:16:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2999.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813336)[0m INFO 03-21 15:16:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2954.7 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:16:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2858.6 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:16:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2852.4 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:16:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2913.2 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:16:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2721.7 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:16:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2711.1 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:16:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2733.8 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:16:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2701.5 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:16:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2690.4 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:17:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2684.6 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:17:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2576.1 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:17:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2574.4 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:17:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2561.2 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:17:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2320.3 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:17:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2387.5 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:17:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2473.5 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:17:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2474.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:17:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2469.6 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:17:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2363.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:17:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2358.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:18:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2391.7 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:18:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2388.9 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:18:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2386.7 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:18:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2380.5 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:18:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2369.8 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:18:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2175.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:18:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2175.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:18:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2146.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:18:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2115.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:18:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2180.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:18:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2074.5 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:19:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2130.1 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:19:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2108.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:19:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2093.0 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:19:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1713.6 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:19:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1681.5 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:19:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1975.8 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:19:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1962.4 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:19:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1931.3 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:19:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1758.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:19:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1758.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:19:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1756.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:19:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1771.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:20:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1750.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:20:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1718.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:20:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1704.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:20:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1462.4 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:20:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1446.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:20:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1445.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:20:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1445.7 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:20:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1675.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:20:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1288.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:20:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1265.0 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:20:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1496.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:21:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1481.8 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:21:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1285.2 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:21:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1284.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:21:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1407.5 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:21:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1397.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:21:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1383.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:21:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1141.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:21:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1130.7 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:21:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1090.6 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:21:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1090.4 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:21:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1172.0 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:22:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1170.0 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:22:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1262.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:22:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1243.2 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:22:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1237.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:22:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1231.5 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:22:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 882.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:22:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 809.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:22:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 808.8 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:22:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 812.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:22:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 807.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:22:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 807.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:22:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1011.1 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:23:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 970.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:23:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 920.3 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:23:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 920.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:23:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 973.1 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:23:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 972.6 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:23:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 764.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:23:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 746.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:23:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 905.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:23:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 905.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:23:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 849.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:23:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 757.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:24:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 806.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:24:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 805.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813340)[0m INFO 03-21 15:24:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 642.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813334)[0m INFO 03-21 15:24:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 423.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m INFO 03-21 15:24:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 699.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813335)[0m INFO 03-21 15:24:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 525.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:24:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 686.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=813339)[0m INFO 03-21 15:24:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 685.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:24:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 700.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:24:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 699.3 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:24:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 577.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:25:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 575.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=813337)[0m INFO 03-21 15:25:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 556.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:25:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 644.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=812401)[0m INFO 03-21 15:25:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 630.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                             |
+======================+===================================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 |
+----------------------+---------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                      |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@1               | 0.2604166666666667                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@16              | 0.7                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
| cons@16              | 0.4567307692307692                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16850.677083333332                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| run_hours            | 0.18135687953895993                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=813338)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=813338)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 15:25:52,678	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=841851)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=841851)[0m No module named 'vllm._version'
[36m(pid=841851)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=842720)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=842720)[0m No module named 'vllm._version'
[36m(pid=842720)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=842719)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=842719)[0m No module named 'vllm._version'
[36m(pid=842719)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=841851)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=842718)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=842718)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=842718)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=842715)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=842718)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (18739 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=841851)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=841851)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90",
[36m(ActorRolloutRefWorker pid=841851)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=841851)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=841851)[0m   ],
[36m(ActorRolloutRefWorker pid=841851)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=841851)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=841851)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=841851)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=841851)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=841851)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=841851)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=841851)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=841851)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=841851)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=841851)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=841851)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=841851)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=841851)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=841851)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=841851)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=841851)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=841851)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=841851)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=841851)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=841851)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=841851)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=841851)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=841851)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=841851)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=841851)[0m }
[36m(ActorRolloutRefWorker pid=841851)[0m 
[36m(ActorRolloutRefWorker pid=841851)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=841851)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=841851)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x149ead543ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=841851)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=842718)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14465f0f3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:26:37 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=842717)[0m WARNING 03-21 15:26:37 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=842717)[0m local rank 0
[36m(ActorRolloutRefWorker pid=842715)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=841851)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=841851)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:26:39 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m WARNING 03-21 15:26:39 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=842719)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=841851)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
len(dataset): 500
wg.worker_names: ['sOvgymActorRolloutRefWorker_0:0', 'sOvgymActorRolloutRefWorker_0:1', 'sOvgymActorRolloutRefWorker_0:2', 'sOvgymActorRolloutRefWorker_0:3', 'sOvgymActorRolloutRefWorker_0:4', 'sOvgymActorRolloutRefWorker_0:5', 'sOvgymActorRolloutRefWorker_0:6', 'sOvgymActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:26:50 metrics.py:345] Avg prompt throughput: 1100.4 tokens/s, Avg generation throughput: 692.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=842719)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:26:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3163.9 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:27:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3165.2 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:27:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3163.3 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:27:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3057.2 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842718)[0m INFO 03-21 15:27:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2926.6 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:27:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2690.1 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:27:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2511.0 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:27:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2291.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:27:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2154.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:27:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1584.5 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:27:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1380.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:27:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1504.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:27:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1405.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:28:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1318.4 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:28:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1178.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:28:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1061.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:28:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 988.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:28:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 983.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:28:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 982.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:28:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 983.2 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:28:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 931.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:28:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1019.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:28:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 939.9 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:28:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 902.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842716)[0m INFO 03-21 15:29:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 887.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=842720)[0m INFO 03-21 15:29:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 509.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:29:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 848.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:29:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 848.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:29:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 847.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:29:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 598.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:29:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 537.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:29:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 471.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:29:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 674.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:29:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 673.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:29:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 672.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:30:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 672.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:30:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 658.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:30:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 657.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:30:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 658.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842720)[0m INFO 03-21 15:30:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 344.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:30:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 640.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:30:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 546.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:30:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 539.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:30:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 539.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:30:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 445.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:30:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:30:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m INFO 03-21 15:31:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 238.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:31:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 480.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:31:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 480.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842718)[0m INFO 03-21 15:31:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 338.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:31:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 467.4 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:31:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 409.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:31:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:31:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:31:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:31:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:31:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:32:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:32:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:32:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842723)[0m INFO 03-21 15:32:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 226.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842723)[0m INFO 03-21 15:32:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:32:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 383.0 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:32:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 335.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:32:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 282.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:32:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 280.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842718)[0m INFO 03-21 15:32:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842718)[0m INFO 03-21 15:32:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842718)[0m INFO 03-21 15:33:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:33:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 359.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:33:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 297.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:33:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:33:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:33:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:33:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842716)[0m INFO 03-21 15:33:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842723)[0m INFO 03-21 15:33:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 142.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842723)[0m INFO 03-21 15:33:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 142.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842723)[0m INFO 03-21 15:33:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 142.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:34:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 279.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:34:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 279.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:34:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 279.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842715)[0m INFO 03-21 15:34:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 279.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:34:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:34:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:34:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:34:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:34:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:34:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:34:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=841851)[0m INFO 03-21 15:34:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:35:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 258.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                             |
+======================+===================================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 |
+----------------------+---------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                      |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@1               | 0.834                                                                                             |
+----------------------+---------------------------------------------------------------------------------------------------+
| cons@1               | 0.834                                                                                             |
+----------------------+---------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5425.806                                                                                          |
+----------------------+---------------------------------------------------------------------------------------------------+
| run_hours            | 0.1596437790658739                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=842719)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842719)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=842717)[0m INFO 03-21 15:35:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 208.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 15:35:40,238	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=868683)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=868683)[0m No module named 'vllm._version'
[36m(pid=868683)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=869575)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=869575)[0m No module named 'vllm._version'
[36m(pid=869575)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=869571)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=869571)[0m No module named 'vllm._version'
[36m(pid=869571)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=869575)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=868683)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=868683)[0m   warnings.warn(
[36m(pid=869570)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=869570)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=869570)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (17021 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=868683)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=868683)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90",
[36m(ActorRolloutRefWorker pid=868683)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=868683)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=868683)[0m   ],
[36m(ActorRolloutRefWorker pid=868683)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=868683)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=868683)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=868683)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=868683)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=868683)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=868683)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=868683)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=868683)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=868683)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=868683)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=868683)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=868683)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=868683)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=868683)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=868683)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=868683)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=868683)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=868683)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=868683)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=868683)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=868683)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=868683)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=868683)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=868683)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=868683)[0m }
[36m(ActorRolloutRefWorker pid=868683)[0m 
[36m(ActorRolloutRefWorker pid=868683)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=868683)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=868683)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14e8c3ef7ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=868683)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:35:58 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=869570)[0m WARNING 03-21 15:35:58 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=869571)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x143fa6a53ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=869576)[0m local rank 0
[36m(ActorRolloutRefWorker pid=869572)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=868683)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=868683)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=868683)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=868683)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:35:58 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m WARNING 03-21 15:35:58 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=869571)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['RjCwwIActorRolloutRefWorker_0:0', 'RjCwwIActorRolloutRefWorker_0:1', 'RjCwwIActorRolloutRefWorker_0:2', 'RjCwwIActorRolloutRefWorker_0:3', 'RjCwwIActorRolloutRefWorker_0:4', 'RjCwwIActorRolloutRefWorker_0:5', 'RjCwwIActorRolloutRefWorker_0:6', 'RjCwwIActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:36:09 metrics.py:345] Avg prompt throughput: 1687.5 tokens/s, Avg generation throughput: 358.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=869576)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:36:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2991.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:36:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2995.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:36:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2992.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:36:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3015.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:36:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3008.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:36:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3010.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:36:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3012.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:36:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3005.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:36:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2756.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:37:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2989.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:37:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2949.5 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:37:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2930.7 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869571)[0m INFO 03-21 15:37:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2942.6 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:37:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2733.6 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:37:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2697.8 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:37:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2678.7 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:37:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2666.3 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:37:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2648.5 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:37:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2539.8 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:37:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2551.7 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:38:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2641.2 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:38:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2608.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:38:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2582.3 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:38:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2221.5 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:38:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2486.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869571)[0m INFO 03-21 15:38:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2489.8 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:38:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2348.5 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:38:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2345.8 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:38:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2345.7 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:38:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2360.7 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:38:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2301.3 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:38:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2300.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:39:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2209.5 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:39:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2188.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:39:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2164.6 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:39:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2112.8 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:39:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2259.3 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:39:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2166.2 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:39:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2137.3 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:39:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2131.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:39:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2075.3 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:39:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2057.2 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:39:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2037.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:40:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2016.9 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:40:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1998.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:40:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1990.5 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:40:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1792.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:40:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1651.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:40:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1588.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:40:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1341.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:40:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1587.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:40:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1824.4 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:40:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1636.9 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:40:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1583.0 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:41:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1654.6 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:41:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1618.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:41:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1574.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:41:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1678.1 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:41:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1665.8 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:41:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1623.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:41:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1603.3 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:41:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1578.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:41:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1541.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:41:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1528.6 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:41:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1346.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:42:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1317.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:42:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1362.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:42:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1353.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:42:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1279.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:42:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1143.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:42:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1032.2 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:42:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1032.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:42:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1202.0 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:42:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1185.2 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:42:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1185.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:42:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1303.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:42:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1289.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:43:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1279.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:43:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1054.3 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:43:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1001.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:43:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 967.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:43:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1112.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:43:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1078.2 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:43:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1079.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:43:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 910.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:43:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 910.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:43:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 881.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:43:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 880.8 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:44:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 707.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:44:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1138.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:44:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 688.3 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:44:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 687.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:44:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1000.3 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:44:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 993.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:44:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 988.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:44:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 714.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:44:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 693.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869572)[0m INFO 03-21 15:44:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 692.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:44:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 742.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869570)[0m INFO 03-21 15:45:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 643.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:45:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 641.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=869575)[0m INFO 03-21 15:45:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 644.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=868683)[0m INFO 03-21 15:45:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 922.6 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:45:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 511.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:45:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 511.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:45:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 814.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:45:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 813.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:45:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 395.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m INFO 03-21 15:45:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 478.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:45:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 738.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=869574)[0m INFO 03-21 15:46:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 712.2 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:46:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 812.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:46:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 811.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=869573)[0m INFO 03-21 15:46:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 808.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                             |
+======================+===================================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 |
+----------------------+---------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                      |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@1               | 0.3104166666666667                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| pass@16              | 0.7333333333333333                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| cons@16              | 0.6166666666666667                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16599.477083333335                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
| run_hours            | 0.1817007609208425                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=869576)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=869576)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 15:46:47,614	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=898229)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=898229)[0m No module named 'vllm._version'
[36m(pid=898229)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=899062)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=899062)[0m No module named 'vllm._version'
[36m(pid=899062)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=899060)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=899060)[0m No module named 'vllm._version'
[36m(pid=899060)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=898229)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=899061)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=899061)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=899061)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=899061)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=899059)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 116, in _wrapper
[36m(ActorRolloutRefWorker pid=899058)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=899058)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
[36m(ActorRolloutRefWorker pid=899058)[0m     output: SamplerOutput = self.model.sample(
[36m(ActorRolloutRefWorker pid=899058)[0m                             ^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
[36m(ActorRolloutRefWorker pid=899058)[0m     next_tokens = self.sampler(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=899058)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[36m(ActorRolloutRefWorker pid=899058)[0m     return self._call_impl(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=899058)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[36m(ActorRolloutRefWorker pid=899058)[0m     return forward_call(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=899058)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
[36m(ActorRolloutRefWorker pid=899058)[0m     self._init_sampling_tensors(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
[36m(ActorRolloutRefWorker pid=899058)[0m     do_min_p) = SamplingTensors.from_sampling_metadata(
[36m(ActorRolloutRefWorker pid=899058)[0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
[36m(ActorRolloutRefWorker pid=899058)[0m     sampling_tensors = SamplingTensors.from_lists(
[36m(ActorRolloutRefWorker pid=899058)[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
[36m(ActorRolloutRefWorker pid=899058)[0m     temperatures_t = torch.tensor(
[36m(ActorRolloutRefWorker pid=899058)[0m                      ^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m RuntimeError: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=899058)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=899058)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=899058)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=899058)[0m 
[36m(ActorRolloutRefWorker pid=899058)[0m 
[36m(ActorRolloutRefWorker pid=899058)[0m The above exception was the direct cause of the following exception:
[36m(ActorRolloutRefWorker pid=899058)[0m 
[36m(ActorRolloutRefWorker pid=899058)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
[36m(ActorRolloutRefWorker pid=899058)[0m     output = self.inference_engine.generate(
[36m(ActorRolloutRefWorker pid=899058)[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
[36m(ActorRolloutRefWorker pid=899058)[0m     return fn(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=899058)[0m            ^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
[36m(ActorRolloutRefWorker pid=899058)[0m     outputs = self._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=899058)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
[36m(ActorRolloutRefWorker pid=899058)[0m     outputs = super()._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=899058)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
[36m(ActorRolloutRefWorker pid=899058)[0m     step_outputs = self.llm_engine.step()
[36m(ActorRolloutRefWorker pid=899058)[0m                    ^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
[36m(ActorRolloutRefWorker pid=899058)[0m     outputs = self.model_executor.execute_model(
[36m(ActorRolloutRefWorker pid=899058)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
[36m(ActorRolloutRefWorker pid=899058)[0m     all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
[36m(ActorRolloutRefWorker pid=899058)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
[36m(ActorRolloutRefWorker pid=899058)[0m     return self.model_runner.execute_model(
[36m(ActorRolloutRefWorker pid=899058)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(ActorRolloutRefWorker pid=899058)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=899058)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=899058)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
[36m(ActorRolloutRefWorker pid=899058)[0m     raise type(err)(f"Error in model execution: "
[36m(ActorRolloutRefWorker pid=899058)[0m RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=899058)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=899058)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=899058)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=899058)[0m 
[36m(ActorRolloutRefWorker pid=899059)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=899059)[0m   warnings.warn([32m [repeated 7x across cluster][0m
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=898229)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=898229)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132",
[36m(ActorRolloutRefWorker pid=898229)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=898229)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=898229)[0m   ],
[36m(ActorRolloutRefWorker pid=898229)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=898229)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=898229)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=898229)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=898229)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=898229)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=898229)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=898229)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=898229)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=898229)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=898229)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=898229)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=898229)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=898229)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=898229)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=898229)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=898229)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=898229)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=898229)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=898229)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=898229)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=898229)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=898229)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=898229)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=898229)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=898229)[0m }
[36m(ActorRolloutRefWorker pid=898229)[0m 
[36m(ActorRolloutRefWorker pid=898229)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=898229)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=898229)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1443984f3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=898229)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=899059)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14c4fd03fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m INFO 03-21 15:47:24 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=899061)[0m WARNING 03-21 15:47:24 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=899061)[0m local rank 0
[36m(ActorRolloutRefWorker pid=899058)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=898229)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=898229)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:47:25 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m WARNING 03-21 15:47:25 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=899060)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=898229)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 500
wg.worker_names: ['EgchhXActorRolloutRefWorker_0:0', 'EgchhXActorRolloutRefWorker_0:1', 'EgchhXActorRolloutRefWorker_0:2', 'EgchhXActorRolloutRefWorker_0:3', 'EgchhXActorRolloutRefWorker_0:4', 'EgchhXActorRolloutRefWorker_0:5', 'EgchhXActorRolloutRefWorker_0:6', 'EgchhXActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=899061)[0m INFO 03-21 15:47:36 metrics.py:345] Avg prompt throughput: 1229.1 tokens/s, Avg generation throughput: 201.2 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=899059)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m INFO 03-21 15:47:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3133.4 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:47:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3043.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:47:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3042.6 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:47:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3022.2 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:48:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2926.3 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:48:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2811.0 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:48:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2175.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:48:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1895.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:48:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1705.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:48:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1634.1 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:48:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1526.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:48:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1539.4 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:48:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1358.3 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:48:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1685.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899059)[0m INFO 03-21 15:48:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1570.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899059)[0m INFO 03-21 15:48:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1513.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m INFO 03-21 15:49:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1186.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m INFO 03-21 15:49:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1170.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:49:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1000.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:49:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1187.9 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:49:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1187.2 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:49:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 652.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:49:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 786.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:49:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 739.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:49:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 724.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:49:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 921.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:49:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 853.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:50:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 840.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:50:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 840.8 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899059)[0m INFO 03-21 15:50:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 823.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m INFO 03-21 15:50:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 475.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:50:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 465.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:50:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 465.4 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:50:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 759.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:50:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 663.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:50:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:50:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:50:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 205.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899063)[0m INFO 03-21 15:51:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 473.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:51:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 472.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:51:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 473.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:51:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 473.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:51:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 530.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:51:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 530.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899059)[0m INFO 03-21 15:51:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 333.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899061)[0m INFO 03-21 15:51:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 210.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:51:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:51:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 408.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:51:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 408.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:52:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 408.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:52:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 408.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:52:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:52:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=898229)[0m INFO 03-21 15:52:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:52:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:52:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899062)[0m INFO 03-21 15:52:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=899060)[0m INFO 03-21 15:52:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 466.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=899058)[0m INFO 03-21 15:52:46 model_runner_base.py:120] Writing input of failed execution to /tmp/err_execute_model_input_20250321-155246.pkl...
[36m(ActorRolloutRefWorker pid=899058)[0m WARNING 03-21 15:52:46 model_runner_base.py:143] Failed to pickle inputs of failed execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=899058)[0m WARNING 03-21 15:52:46 model_runner_base.py:143] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=899058)[0m WARNING 03-21 15:52:46 model_runner_base.py:143] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=899058)[0m WARNING 03-21 15:52:46 model_runner_base.py:143] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=899058)[0m WARNING 03-21 15:52:46 model_runner_base.py:143] 
[36m(ActorRolloutRefWorker pid=899058)[0m Restarting vLLM due to error:  Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=899058)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=899058)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=899058)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=899058)[0m 
[36m(ActorRolloutRefWorker pid=899058)[0m Retrying...
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=1', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.95', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 147, in main
    output = wg.generate_sequences(data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=899058, ip=99.72.4.18, actor_id=755b17a67f4b7dbf10b0b2e001000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14d1e5b83a50>)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
    output: SamplerOutput = self.model.sample(
                            ^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
    next_tokens = self.sampler(logits, sampling_metadata)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
    self._init_sampling_tensors(logits, sampling_metadata)
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
    do_min_p) = SamplingTensors.from_sampling_metadata(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
    sampling_tensors = SamplingTensors.from_lists(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
    temperatures_t = torch.tensor(
                     ^^^^^^^^^^^^^
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=899058, ip=99.72.4.18, actor_id=755b17a67f4b7dbf10b0b2e001000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14d1e5b83a50>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
    output = self.inference_engine.generate(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
    outputs = self._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
    outputs = super()._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
    step_outputs = self.llm_engine.step()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
    outputs = self.model_executor.execute_model(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
    all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
    return self.model_runner.execute_model(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
    raise type(err)(f"Error in model execution: "
RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=899058, ip=99.72.4.18, actor_id=755b17a67f4b7dbf10b0b2e001000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14d1e5b83a50>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 447, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 276, in generate_sequences
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=899058, ip=99.72.4.18, actor_id=755b17a67f4b7dbf10b0b2e001000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14d1e5b83a50>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 439, in generate_sequences
    with self.rollout_sharding_manager:
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/sharding_manager/fsdp_vllm.py", line 105, in __exit__
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(ActorRolloutRefWorker pid=899064)[0m INFO 03-21 15:52:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 135.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 15:53:02,534	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=917050)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=917050)[0m No module named 'vllm._version'
[36m(pid=917050)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=917896)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=917896)[0m No module named 'vllm._version'
[36m(pid=917896)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=917895)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=917895)[0m No module named 'vllm._version'
[36m(pid=917895)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=917896)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=917896)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=917896)[0m   warnings.warn(
[36m(pid=917901)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=917901)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=917901)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (27648 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=917050)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=917050)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132",
[36m(ActorRolloutRefWorker pid=917050)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=917050)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=917050)[0m   ],
[36m(ActorRolloutRefWorker pid=917050)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=917050)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=917050)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=917050)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=917050)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=917050)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=917050)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=917050)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=917050)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=917050)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=917050)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=917050)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=917050)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=917050)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=917050)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=917050)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=917050)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=917050)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=917050)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=917050)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=917050)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=917050)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=917050)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=917050)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=917050)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=917050)[0m }
[36m(ActorRolloutRefWorker pid=917050)[0m 
[36m(ActorRolloutRefWorker pid=917050)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=917050)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=917050)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x150c3a64bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=917050)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:53:20 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=917896)[0m WARNING 03-21 15:53:20 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=917901)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x148eac3ffec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=917896)[0m local rank 0
[36m(ActorRolloutRefWorker pid=917895)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=917050)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=917050)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:53:21 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m WARNING 03-21 15:53:21 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=917901)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=917050)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['vM5NSGActorRolloutRefWorker_0:0', 'vM5NSGActorRolloutRefWorker_0:1', 'vM5NSGActorRolloutRefWorker_0:2', 'vM5NSGActorRolloutRefWorker_0:3', 'vM5NSGActorRolloutRefWorker_0:4', 'vM5NSGActorRolloutRefWorker_0:5', 'vM5NSGActorRolloutRefWorker_0:6', 'vM5NSGActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 15:53:32 metrics.py:345] Avg prompt throughput: 1637.8 tokens/s, Avg generation throughput: 11.6 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=917901)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:53:37 metrics.py:345] Avg prompt throughput: 52.3 tokens/s, Avg generation throughput: 3042.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:53:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3054.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 15:53:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3007.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:53:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3043.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:53:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3040.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:54:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3038.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:54:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3036.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:54:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2982.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:54:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2708.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:54:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2977.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:54:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3013.3 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:54:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2943.2 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:54:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2876.5 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 15:54:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2755.2 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 15:54:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2705.4 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:54:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2820.0 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:55:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2778.9 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:55:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2753.6 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 15:55:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2704.7 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:55:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2674.3 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:55:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2638.2 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:55:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2621.5 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:55:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2597.2 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:55:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2287.2 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:55:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2513.9 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:55:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2501.7 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:55:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2491.3 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:55:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2385.1 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:56:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2379.7 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:56:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2387.3 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:56:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2338.4 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:56:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2286.4 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:56:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2248.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:56:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2211.9 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 15:56:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2156.7 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:56:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2319.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:56:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2287.6 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:56:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2212.8 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 15:56:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2001.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:57:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1951.4 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:57:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1952.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:57:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1954.1 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:57:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1954.5 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:57:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1932.3 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:57:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1933.6 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:57:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1933.0 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:57:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1641.5 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:57:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1920.8 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917900)[0m INFO 03-21 15:57:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1876.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 15:57:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1466.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:58:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1817.8 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:58:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1800.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 15:58:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1784.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 15:58:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1824.6 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 15:58:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1785.8 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:58:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1608.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:58:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1598.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:58:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1538.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:58:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1507.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 15:58:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1408.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 15:58:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1489.9 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 15:58:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1468.6 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 15:59:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1416.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:59:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1283.6 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:59:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1258.0 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:59:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1224.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:59:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1157.3 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:59:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1155.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:59:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1155.9 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 15:59:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1153.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917900)[0m INFO 03-21 15:59:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1385.5 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917900)[0m INFO 03-21 15:59:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1376.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917900)[0m INFO 03-21 15:59:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1367.9 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 16:00:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1049.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 16:00:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1012.7 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:00:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1104.3 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:00:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1088.5 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:00:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1087.3 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 16:00:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1236.7 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 16:00:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 645.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 16:00:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 642.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 16:00:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 643.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 16:00:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 824.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 16:00:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 829.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917900)[0m INFO 03-21 16:01:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1124.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917900)[0m INFO 03-21 16:01:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1099.1 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 16:01:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 688.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 16:01:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 665.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 16:01:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 630.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:01:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 818.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:01:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 818.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:01:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 750.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 16:01:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 461.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 16:01:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 461.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917895)[0m INFO 03-21 16:01:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 454.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 16:01:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 697.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 16:02:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 646.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917897)[0m INFO 03-21 16:02:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 583.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:02:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1046.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:02:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1040.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:02:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1034.2 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 16:02:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 592.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 16:02:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 591.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m INFO 03-21 16:02:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 591.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917898)[0m INFO 03-21 16:02:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:02:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 575.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:02:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 575.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:03:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 576.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:03:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 548.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=917050)[0m INFO 03-21 16:03:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 517.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=917896)[0m INFO 03-21 16:03:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 528.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:03:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 821.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:03:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 805.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:03:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 802.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:03:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 802.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=917899)[0m INFO 03-21 16:03:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 794.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+----------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                              |
+======================+====================================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr8e-7-ep1-bs16-cutoff-16k-checkpoint-132 |
+----------------------+----------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                       |
+----------------------+----------------------------------------------------------------------------------------------------+
| pass@1               | 0.29583333333333334                                                                                |
+----------------------+----------------------------------------------------------------------------------------------------+
| pass@16              | 0.7                                                                                                |
+----------------------+----------------------------------------------------------------------------------------------------+
| cons@16              | 0.4562678062678062                                                                                 |
+----------------------+----------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                |
+----------------------+----------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16571.170833333334                                                                                 |
+----------------------+----------------------------------------------------------------------------------------------------+
| run_hours            | 0.18278749684492748                                                                                |
+----------------------+----------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=917901)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=917901)[0m   warnings.warn([32m [repeated 7x across cluster][0m
