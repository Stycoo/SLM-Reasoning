+ export VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ MODEL_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1
+ OUTPUT_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs
+ GPU_NUM=8
+ TP=1
+ TEMP=0.6
+ TOP_P=0.95
+ MAX_LEN=32768
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ DATATYPES=("math")
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ echo 'Datasets: math'
Datasets: math
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-18 10:35:06,307	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=827461)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=827461)[0m No module named 'vllm._version'
[36m(pid=827461)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=827884)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=827884)[0m No module named 'vllm._version'
[36m(pid=827884)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=827879)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=827879)[0m No module named 'vllm._version'
[36m(pid=827879)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=827461)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=827879)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(ActorRolloutRefWorker pid=827879)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.01s/it]
[36m(pid=827878)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=827878)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=827878)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.22s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.54s/it]
[36m(ActorRolloutRefWorker pid=827461)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=827461)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=827878)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:01,  1.96s/it][32m [repeated 23x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.57s/it][32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (25619 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=827461)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=827461)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=827461)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=827461)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=827461)[0m   ],
[36m(ActorRolloutRefWorker pid=827461)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=827461)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=827461)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=827461)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=827461)[0m   "hidden_size": 3584,
[36m(ActorRolloutRefWorker pid=827461)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=827461)[0m   "intermediate_size": 18944,
[36m(ActorRolloutRefWorker pid=827461)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=827461)[0m   "max_window_layers": 28,
[36m(ActorRolloutRefWorker pid=827461)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=827461)[0m   "num_attention_heads": 28,
[36m(ActorRolloutRefWorker pid=827461)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=827461)[0m   "num_key_value_heads": 4,
[36m(ActorRolloutRefWorker pid=827461)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=827461)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=827461)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=827461)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=827461)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=827461)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=827461)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=827461)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=827461)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=827461)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=827461)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=827461)[0m   "vocab_size": 152064
[36m(ActorRolloutRefWorker pid=827461)[0m }
[36m(ActorRolloutRefWorker pid=827461)[0m 
[36m(ActorRolloutRefWorker pid=827461)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=827461)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(ActorRolloutRefWorker pid=827461)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14cc708fbec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=827461)[0m Before building vllm rollout, memory allocated (GB): 1.7850494384765625, memory reserved (GB): 8.94921875
[36m(ActorRolloutRefWorker pid=827878)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14d62582bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:36:16 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=827878)[0m WARNING 03-18 10:36:16 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=827884)[0m local rank 0
[36m(ActorRolloutRefWorker pid=827884)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:36:19 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m WARNING 03-18 10:36:19 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m before init cache memory allocated: 17.248843776GB, reserved: 17.318281216GB
[36m(ActorRolloutRefWorker pid=827461)[0m after init cache memory allocated: 72.622045184GB, reserved: 72.691482624GB
[36m(ActorRolloutRefWorker pid=827461)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=827461)[0m After building vllm rollout, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
[36m(ActorRolloutRefWorker pid=827878)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m After building sharding manager, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
len(dataset): 500
wg.worker_names: ['imZk7hActorRolloutRefWorker_0:0', 'imZk7hActorRolloutRefWorker_0:1', 'imZk7hActorRolloutRefWorker_0:2', 'imZk7hActorRolloutRefWorker_0:3', 'imZk7hActorRolloutRefWorker_0:4', 'imZk7hActorRolloutRefWorker_0:5', 'imZk7hActorRolloutRefWorker_0:6', 'imZk7hActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:36:43 metrics.py:345] Avg prompt throughput: 387.9 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=827881)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:36:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2888.4 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:36:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2848.1 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:36:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2692.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:37:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2410.2 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:37:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2497.4 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:37:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2325.1 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:37:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2172.9 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:37:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2271.2 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:37:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1863.4 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:37:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1761.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:37:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1757.0 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:37:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1662.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:37:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1398.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:38:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1226.8 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:38:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1168.8 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:38:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1130.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:38:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1097.4 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:38:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1033.9 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:38:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 690.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:38:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 914.9 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:38:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 856.5 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:38:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 680.8 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:38:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 633.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:38:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 623.4 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:39:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 616.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:39:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 751.5 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:39:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 744.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:39:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 710.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:39:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 567.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:39:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 476.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:39:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 432.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:39:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 428.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:39:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 426.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:39:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 423.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:39:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 507.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:40:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 504.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:40:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 389.6 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:40:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 365.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:40:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:40:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 455.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:40:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 453.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:40:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 359.2 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:40:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 201.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:40:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 200.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:40:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 306.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:40:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 305.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:41:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 305.6 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:41:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 253.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:41:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 300.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:41:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 308.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:41:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 307.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:41:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 297.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:41:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:41:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:41:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 195.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:41:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 295.6 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:41:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 193.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:42:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 244.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:42:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 243.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:42:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 297.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:42:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 134.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:42:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 134.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:42:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:42:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:42:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 285.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:42:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 189.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:42:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 237.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:42:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 236.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:43:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 242.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:43:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 67.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827878)[0m INFO 03-18 10:43:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 67.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:43:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:43:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827461)[0m INFO 03-18 10:43:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:43:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 131.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:43:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 233.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:43:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 232.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:43:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 230.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:43:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 229.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:44:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 235.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:44:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:44:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 130.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:44:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 129.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:44:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 227.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:44:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 227.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:44:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 151.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:44:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 183.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:44:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:44:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 224.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:45:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 224.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827883)[0m INFO 03-18 10:45:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 127.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:45:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 130.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827882)[0m INFO 03-18 10:45:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m INFO 03-18 10:45:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:45:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 177.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:45:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 177.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:45:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 129.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:45:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 128.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:45:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 176.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:46:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 175.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=827880)[0m INFO 03-18 10:46:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 124.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:46:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 129.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:46:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 126.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=827884)[0m INFO 03-18 10:46:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 125.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                        |
+======================+==============================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k |
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                                                 |
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.926                                                                                                                        |
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
| cons@1               | 0.926                                                                                                                        |
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                          |
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5064.096                                                                                                                     |
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.1959266945388582                                                                                                           |
+----------------------+------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=827881)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=827881)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ MODEL_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ echo 'Datasets: math'
Datasets: math
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-18 10:46:59,679	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=858267)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=858267)[0m No module named 'vllm._version'
[36m(pid=858267)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=859148)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=859148)[0m No module named 'vllm._version'
[36m(pid=859148)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=859149)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=859149)[0m No module named 'vllm._version'
[36m(pid=859149)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=858267)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=858267)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(ActorRolloutRefWorker pid=858267)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:08,  2.76s/it]
[36m(pid=859152)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=859152)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=859152)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=859152)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859152)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:08<00:02,  2.77s/it][32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  1.78s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.22s/it]
[36m(ActorRolloutRefWorker pid=858267)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=858267)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=859152)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:08<00:02,  2.78s/it][32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859153)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  1.80s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.24s/it][32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (22536 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=858267)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=858267)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20",
[36m(ActorRolloutRefWorker pid=858267)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=858267)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=858267)[0m   ],
[36m(ActorRolloutRefWorker pid=858267)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=858267)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=858267)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=858267)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=858267)[0m   "hidden_size": 3584,
[36m(ActorRolloutRefWorker pid=858267)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=858267)[0m   "intermediate_size": 18944,
[36m(ActorRolloutRefWorker pid=858267)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=858267)[0m   "max_window_layers": 28,
[36m(ActorRolloutRefWorker pid=858267)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=858267)[0m   "num_attention_heads": 28,
[36m(ActorRolloutRefWorker pid=858267)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=858267)[0m   "num_key_value_heads": 4,
[36m(ActorRolloutRefWorker pid=858267)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=858267)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=858267)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=858267)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=858267)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=858267)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=858267)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=858267)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=858267)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=858267)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=858267)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=858267)[0m   "vocab_size": 152064
[36m(ActorRolloutRefWorker pid=858267)[0m }
[36m(ActorRolloutRefWorker pid=858267)[0m 
[36m(ActorRolloutRefWorker pid=858267)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=858267)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(ActorRolloutRefWorker pid=859151)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14f6ce8bbec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:48:13 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=859151)[0m WARNING 03-18 10:48:13 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=858267)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14d3930efec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m local rank 0
[36m(ActorRolloutRefWorker pid=858267)[0m Before building vllm rollout, memory allocated (GB): 1.7850494384765625, memory reserved (GB): 8.94921875
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:48:19 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m WARNING 03-18 10:48:19 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m local rank 0[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=858267)[0m before init cache memory allocated: 17.248843776GB, reserved: 17.318281216GB
[36m(ActorRolloutRefWorker pid=858267)[0m after init cache memory allocated: 72.622045184GB, reserved: 72.691482624GB
[36m(ActorRolloutRefWorker pid=858267)[0m local rank 0
[36m(ActorRolloutRefWorker pid=858267)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=858267)[0m After building vllm rollout, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
[36m(ActorRolloutRefWorker pid=858267)[0m After building sharding manager, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
len(dataset): 500
wg.worker_names: ['5gFHBiActorRolloutRefWorker_0:0', '5gFHBiActorRolloutRefWorker_0:1', '5gFHBiActorRolloutRefWorker_0:2', '5gFHBiActorRolloutRefWorker_0:3', '5gFHBiActorRolloutRefWorker_0:4', '5gFHBiActorRolloutRefWorker_0:5', '5gFHBiActorRolloutRefWorker_0:6', '5gFHBiActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:48:37 metrics.py:345] Avg prompt throughput: 503.3 tokens/s, Avg generation throughput: 5.1 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=859153)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:48:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2889.0 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:48:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2809.8 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:48:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2743.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:48:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2543.6 tokens/s, Running: 61 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:49:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2553.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:49:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2517.7 tokens/s, Running: 61 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:49:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2264.1 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:49:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2163.3 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:49:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2012.4 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:49:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1835.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:49:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1651.7 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:49:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1505.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:49:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1352.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:49:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1450.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:50:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1338.3 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:50:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1098.0 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:50:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1054.5 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:50:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1110.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:50:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 733.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:50:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 692.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:50:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1074.6 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:50:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 601.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:50:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 589.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:50:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 749.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:50:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 719.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:51:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 714.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859153)[0m INFO 03-18 10:51:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 616.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:51:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 639.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:51:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 609.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:51:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 572.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:51:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 514.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859152)[0m INFO 03-18 10:51:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 264.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:51:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 594.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:51:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 537.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:51:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 418.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:51:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 417.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:52:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 472.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:52:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 409.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:52:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 452.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:52:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 450.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:52:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 364.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:52:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 357.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:52:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 366.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:52:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 365.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:52:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 255.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:52:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 361.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:52:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 304.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:53:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 303.1 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:53:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 302.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:53:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 346.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:53:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 306.1 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:53:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 273.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:53:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 201.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:53:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 245.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:53:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 198.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:53:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 246.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:53:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 135.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:53:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 135.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:54:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 290.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:54:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 289.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:54:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 247.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:54:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 247.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:54:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:54:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 174.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:54:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:54:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 189.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:54:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 133.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:54:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 281.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:55:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 280.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:55:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:55:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:55:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 132.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:55:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 189.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:55:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 188.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:55:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 128.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:55:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 184.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:55:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=859154)[0m INFO 03-18 10:55:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:55:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 132.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:56:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m INFO 03-18 10:56:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859152)[0m INFO 03-18 10:56:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:56:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 129.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=858267)[0m INFO 03-18 10:56:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 129.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:56:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:56:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:56:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 131.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:56:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 128.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:56:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:57:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=859152)[0m INFO 03-18 10:57:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:57:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 127.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:57:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:57:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:57:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:57:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=859150)[0m INFO 03-18 10:57:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=859148)[0m INFO 03-18 10:57:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 126.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                                               |
+======================+=====================================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                                                                                                                                                                                        |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.93                                                                                                                                                                                                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@1               | 0.93                                                                                                                                                                                                                                                                |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                                                 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5063.77                                                                                                                                                                                                                                                             |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.18519506242540149                                                                                                                                                                                                                                                 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=859151)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859151)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=859149)[0m INFO 03-18 10:57:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 68.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ echo 'Datasets: math'
Datasets: math
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-18 10:58:19,175	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=888176)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=888176)[0m No module named 'vllm._version'
[36m(pid=888176)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=889057)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=889057)[0m No module named 'vllm._version'
[36m(pid=889057)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=889063)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=889063)[0m No module named 'vllm._version'
[36m(pid=889063)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=888176)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=889058)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(ActorRolloutRefWorker pid=888176)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.13s/it]
[36m(pid=889059)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=889059)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=889059)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.49s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.77s/it]
[36m(ActorRolloutRefWorker pid=889057)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=889057)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=889060)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.33s/it][32m [repeated 23x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.49s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.77s/it][32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (32602 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=888176)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=888176)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40",
[36m(ActorRolloutRefWorker pid=888176)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=888176)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=888176)[0m   ],
[36m(ActorRolloutRefWorker pid=888176)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=888176)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=888176)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=888176)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=888176)[0m   "hidden_size": 3584,
[36m(ActorRolloutRefWorker pid=888176)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=888176)[0m   "intermediate_size": 18944,
[36m(ActorRolloutRefWorker pid=888176)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=888176)[0m   "max_window_layers": 28,
[36m(ActorRolloutRefWorker pid=888176)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=888176)[0m   "num_attention_heads": 28,
[36m(ActorRolloutRefWorker pid=888176)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=888176)[0m   "num_key_value_heads": 4,
[36m(ActorRolloutRefWorker pid=888176)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=888176)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=888176)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=888176)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=888176)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=888176)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=888176)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=888176)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=888176)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=888176)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=888176)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=888176)[0m   "vocab_size": 152064
[36m(ActorRolloutRefWorker pid=888176)[0m }
[36m(ActorRolloutRefWorker pid=888176)[0m 
[36m(ActorRolloutRefWorker pid=888176)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=888176)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(ActorRolloutRefWorker pid=888176)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1425d3517ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 10:59:22 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=889060)[0m WARNING 03-18 10:59:22 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=889059)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14e0c4edbec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m local rank 0
[36m(ActorRolloutRefWorker pid=888176)[0m Before building vllm rollout, memory allocated (GB): 1.7850494384765625, memory reserved (GB): 8.94921875
[36m(ActorRolloutRefWorker pid=889057)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 10:59:27 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m WARNING 03-18 10:59:27 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m before init cache memory allocated: 17.248843776GB, reserved: 17.318281216GB
[36m(ActorRolloutRefWorker pid=888176)[0m after init cache memory allocated: 72.622045184GB, reserved: 72.691482624GB
[36m(ActorRolloutRefWorker pid=889057)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=888176)[0m After building vllm rollout, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
[36m(ActorRolloutRefWorker pid=888176)[0m After building sharding manager, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
len(dataset): 500
wg.worker_names: ['mMvT2SActorRolloutRefWorker_0:0', 'mMvT2SActorRolloutRefWorker_0:1', 'mMvT2SActorRolloutRefWorker_0:2', 'mMvT2SActorRolloutRefWorker_0:3', 'mMvT2SActorRolloutRefWorker_0:4', 'mMvT2SActorRolloutRefWorker_0:5', 'mMvT2SActorRolloutRefWorker_0:6', 'mMvT2SActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 10:59:46 metrics.py:345] Avg prompt throughput: 392.7 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=889058)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 10:59:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2879.9 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 10:59:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2854.0 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:00:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2773.9 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:00:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2524.6 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m INFO 03-18 11:00:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2590.6 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m INFO 03-18 11:00:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2483.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:00:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2332.0 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:00:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2272.4 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:00:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2232.3 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:00:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1676.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:00:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1532.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:00:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1434.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:00:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1534.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:01:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1410.6 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:01:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1119.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:01:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1138.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:01:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1173.1 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m INFO 03-18 11:01:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1288.2 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:01:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1173.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:01:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1054.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:01:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 922.1 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:01:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 792.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:01:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 589.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:01:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 748.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:02:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 715.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:02:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 670.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:02:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 529.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:02:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 702.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:02:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 614.3 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:02:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 600.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:02:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 469.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:02:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 515.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:02:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 513.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:02:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 509.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:02:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 372.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:03:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 371.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:03:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 314.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:03:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 313.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:03:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 414.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:03:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 451.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:03:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 405.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:03:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 486.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:03:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 232.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:03:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 200.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:03:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 254.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:03:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 253.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:04:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 350.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:04:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 305.1 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:04:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 301.1 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:04:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 427.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:04:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 425.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:04:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 196.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:04:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 194.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:04:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 194.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:04:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 133.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:04:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 296.0 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:05:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 244.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:05:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 305.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:05:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 135.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:05:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 135.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:05:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:05:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:05:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 133.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:05:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 191.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:05:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 238.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:05:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 238.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:05:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:06:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 190.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:06:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 133.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m INFO 03-18 11:06:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 287.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:06:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 131.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:06:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 131.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m INFO 03-18 11:06:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 134.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:06:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 186.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:06:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 184.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889060)[0m INFO 03-18 11:06:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 167.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:06:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889062)[0m INFO 03-18 11:06:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 130.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:07:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 130.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m INFO 03-18 11:07:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 131.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:07:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 183.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:07:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 181.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:07:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 181.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:07:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=889061)[0m INFO 03-18 11:07:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m INFO 03-18 11:07:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 231.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:07:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 128.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m INFO 03-18 11:07:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 93.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m INFO 03-18 11:07:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:08:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 179.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:08:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 177.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:08:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 160.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:08:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 177.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m INFO 03-18 11:08:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 227.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889057)[0m INFO 03-18 11:08:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 127.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:08:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 176.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:08:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 176.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:08:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 175.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=888176)[0m INFO 03-18 11:08:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 174.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:09:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 174.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=889063)[0m INFO 03-18 11:09:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 174.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m INFO 03-18 11:09:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 221.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m INFO 03-18 11:09:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 221.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=889059)[0m INFO 03-18 11:09:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 220.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                                               |
+======================+=====================================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                                                                                                                                                                                        |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.918                                                                                                                                                                                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@1               | 0.918                                                                                                                                                                                                                                                               |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                                                 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5221.534                                                                                                                                                                                                                                                            |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.1904727118545108                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=889058)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=889058)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ echo 'Datasets: math'
Datasets: math
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=1', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.85', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/GLOBALFS/gznwp_3/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 55, in main
    tokenizer = hf_tokenizer(local_path)
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/utils/tokenizer.py", line 55, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 844, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 676, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'. Please provide either the path to a local folder or the repo_id of a model on the Hub.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ DATATYPES=("aime")
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ echo 'Datasets: aime'
Datasets: aime
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.85', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/GLOBALFS/gznwp_3/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 55, in main
    tokenizer = hf_tokenizer(local_path)
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/utils/tokenizer.py", line 55, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 844, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 676, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-s1k-math-qwq-bs16-ep5-lr1e-5-cutoff-16k'. Please provide either the path to a local folder or the repo_id of a model on the Hub.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
+ MODEL_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ echo 'Datasets: aime'
Datasets: aime
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-18 11:10:17,583	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=919802)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=919802)[0m No module named 'vllm._version'
[36m(pid=919802)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=920638)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=920638)[0m No module named 'vllm._version'
[36m(pid=920638)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=920639)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=920639)[0m No module named 'vllm._version'
[36m(pid=920639)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=920638)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=920638)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(ActorRolloutRefWorker pid=920638)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.52it/s]
[36m(ActorRolloutRefWorker pid=920638)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.69it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.62it/s]
[36m(ActorRolloutRefWorker pid=920637)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=920637)[0m   warnings.warn(
[36m(pid=920640)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=920640)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=920640)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.55it/s][32m [repeated 23x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.91it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.73it/s][32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (16708 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=919802)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=919802)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20",
[36m(ActorRolloutRefWorker pid=919802)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=919802)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=919802)[0m   ],
[36m(ActorRolloutRefWorker pid=919802)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=919802)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=919802)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=919802)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=919802)[0m   "hidden_size": 3584,
[36m(ActorRolloutRefWorker pid=919802)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=919802)[0m   "intermediate_size": 18944,
[36m(ActorRolloutRefWorker pid=919802)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=919802)[0m   "max_window_layers": 28,
[36m(ActorRolloutRefWorker pid=919802)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=919802)[0m   "num_attention_heads": 28,
[36m(ActorRolloutRefWorker pid=919802)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=919802)[0m   "num_key_value_heads": 4,
[36m(ActorRolloutRefWorker pid=919802)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=919802)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=919802)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=919802)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=919802)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=919802)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=919802)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=919802)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=919802)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=919802)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=919802)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=919802)[0m   "vocab_size": 152064
[36m(ActorRolloutRefWorker pid=919802)[0m }
[36m(ActorRolloutRefWorker pid=919802)[0m 
[36m(ActorRolloutRefWorker pid=919802)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=919802)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(ActorRolloutRefWorker pid=919802)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x144a43bc7ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=919802)[0m Before building vllm rollout, memory allocated (GB): 1.7850494384765625, memory reserved (GB): 8.94921875
[36m(ActorRolloutRefWorker pid=920641)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14fd87adfec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:10:40 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=920640)[0m WARNING 03-18 11:10:40 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=920640)[0m local rank 0
[36m(ActorRolloutRefWorker pid=920637)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=919802)[0m before init cache memory allocated: 17.248843776GB, reserved: 17.318281216GB
[36m(ActorRolloutRefWorker pid=920637)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:10:42 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m WARNING 03-18 11:10:42 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m after init cache memory allocated: 72.622045184GB, reserved: 72.691482624GB
[36m(ActorRolloutRefWorker pid=919802)[0m After building vllm rollout, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
[36m(ActorRolloutRefWorker pid=919802)[0m After building sharding manager, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
len(dataset): 30
wg.worker_names: ['pkRutfActorRolloutRefWorker_0:0', 'pkRutfActorRolloutRefWorker_0:1', 'pkRutfActorRolloutRefWorker_0:2', 'pkRutfActorRolloutRefWorker_0:3', 'pkRutfActorRolloutRefWorker_0:4', 'pkRutfActorRolloutRefWorker_0:5', 'pkRutfActorRolloutRefWorker_0:6', 'pkRutfActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:11:01 metrics.py:345] Avg prompt throughput: 617.4 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=920640)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:11:06 metrics.py:345] Avg prompt throughput: 52.2 tokens/s, Avg generation throughput: 2775.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:11:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2732.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:11:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2654.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:11:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2457.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:11:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2528.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:11:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2461.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:11:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2469.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:11:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2285.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:11:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2238.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:11:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2201.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:12:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2152.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:12:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2112.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:12:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1946.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:12:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2038.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:12:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2007.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:12:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1930.8 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:12:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1959.0 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:12:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1865.0 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:12:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1821.4 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:12:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1778.7 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:12:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1752.4 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:13:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1733.7 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:13:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1707.6 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:13:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1684.5 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:13:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1663.8 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:13:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1642.1 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:13:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1508.4 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:13:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1728.3 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:13:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1695.2 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:13:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1690.0 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:13:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1640.5 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:13:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1612.1 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:14:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1538.0 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:14:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1512.1 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:14:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1496.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:14:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1536.7 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:14:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1511.0 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:14:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1494.1 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:14:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1422.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 34.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:14:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1404.8 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:14:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1427.0 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:14:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1405.0 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:14:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1283.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:15:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1234.5 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:15:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1264.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:15:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1284.6 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:15:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1151.8 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:15:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1156.4 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:15:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1224.4 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:15:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1239.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:15:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1249.2 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:15:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1217.0 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:15:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1095.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 34.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:15:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1136.3 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:16:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1118.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:16:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1122.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:16:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1160.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:16:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1153.6 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:16:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1144.3 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:16:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1118.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:16:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1090.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:16:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1085.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:16:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1055.1 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:16:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1033.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:16:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 972.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:17:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 965.6 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:17:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1006.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:17:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1000.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:17:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1014.5 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:17:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 983.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:17:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 979.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:17:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 980.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:17:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 964.6 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:17:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 959.8 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:17:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 957.0 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:17:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 884.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:18:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 919.5 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:18:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 930.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:18:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 882.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:18:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 877.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:18:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 883.6 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:18:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 874.3 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:18:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 887.9 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:18:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 878.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:18:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 871.0 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:18:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 752.3 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:18:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 786.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:19:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 831.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:19:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 828.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:19:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 848.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:19:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 846.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:19:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 823.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:19:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 773.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:19:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 814.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:19:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 822.4 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:19:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 736.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:19:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 724.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:19:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 816.3 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 51.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:20:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 754.9 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:20:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 704.2 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:20:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 745.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:20:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 741.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:20:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 776.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 48.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:20:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 699.5 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:20:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 678.8 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:20:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 666.9 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:20:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 763.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 51.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:20:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 636.1 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:21:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 632.9 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:21:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 687.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:21:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 685.6 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:21:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 718.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 48.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:21:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 647.2 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:21:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 630.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:21:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 711.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 49.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:21:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 699.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 49.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:21:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 609.1 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:21:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 665.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:21:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 650.2 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:22:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 673.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:22:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 669.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 48.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:22:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 578.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:22:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 592.1 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:22:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 639.6 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:22:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 552.2 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:22:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 570.6 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:22:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 641.2 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 50.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:22:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 639.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 50.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:22:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 621.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:22:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 620.2 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:23:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 529.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:23:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 524.6 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:23:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 569.6 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:23:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 615.3 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 50.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:23:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 532.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:23:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 618.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:23:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 617.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:23:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 587.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:23:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 584.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:23:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 435.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:23:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 434.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:24:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 517.8 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:24:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 571.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 48.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:24:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 485.1 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:24:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 484.1 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:24:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 575.1 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 51.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:24:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 568.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 50.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:24:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 423.2 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:24:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 421.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:24:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 490.3 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:24:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 513.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:25:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 511.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:25:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 455.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:25:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 441.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 34.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:25:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 534.2 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 49.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:25:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 504.1 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:25:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 494.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:25:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 510.8 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:25:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 392.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:25:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 384.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:25:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 431.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:25:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 425.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:26:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 451.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:26:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:26:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 401.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 34.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:26:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 503.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 50.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:26:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 486.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:26:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 481.2 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:26:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920637)[0m INFO 03-18 11:26:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 303.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:26:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 413.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:26:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 403.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:26:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 385.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=919802)[0m INFO 03-18 11:27:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 375.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:27:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 462.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:27:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 445.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:27:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 423.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:27:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 421.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:27:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 430.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920635)[0m INFO 03-18 11:27:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 378.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:27:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 374.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m INFO 03-18 11:27:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 384.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.3%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:27:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 439.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.5%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=920636)[0m INFO 03-18 11:27:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 379.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:28:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 388.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.1%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=920641)[0m INFO 03-18 11:28:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 306.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:28:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 403.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.1%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=920638)[0m INFO 03-18 11:28:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 351.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=920639)[0m INFO 03-18 11:28:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 368.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.9%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                                               |
+======================+=====================================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                                                                                                                                                                                        |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.6125                                                                                                                                                                                                                                                              |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@16              | 0.8666666666666667                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@16              | 0.8666666666666667                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                                                 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16620.689583333333                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.3084914489587148                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=920640)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=920640)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ echo 'Datasets: aime'
Datasets: aime
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-18 11:29:01,959	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=965677)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=965677)[0m No module named 'vllm._version'
[36m(pid=965677)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=966563)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=966563)[0m No module named 'vllm._version'
[36m(pid=966563)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=966567)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=966567)[0m No module named 'vllm._version'
[36m(pid=966567)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=966563)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=966562)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(ActorRolloutRefWorker pid=966562)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.03it/s]
[36m(ActorRolloutRefWorker pid=966562)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.20it/s]
[36m(ActorRolloutRefWorker pid=966562)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=966562)[0m   warnings.warn(
[36m(pid=966568)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=966568)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=966568)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.64it/s][32m [repeated 23x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.96it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.82it/s][32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (18911 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=965677)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=965677)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40",
[36m(ActorRolloutRefWorker pid=965677)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=965677)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=965677)[0m   ],
[36m(ActorRolloutRefWorker pid=965677)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=965677)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=965677)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=965677)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=965677)[0m   "hidden_size": 3584,
[36m(ActorRolloutRefWorker pid=965677)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=965677)[0m   "intermediate_size": 18944,
[36m(ActorRolloutRefWorker pid=965677)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=965677)[0m   "max_window_layers": 28,
[36m(ActorRolloutRefWorker pid=965677)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=965677)[0m   "num_attention_heads": 28,
[36m(ActorRolloutRefWorker pid=965677)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=965677)[0m   "num_key_value_heads": 4,
[36m(ActorRolloutRefWorker pid=965677)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=965677)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=965677)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=965677)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=965677)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=965677)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=965677)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=965677)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=965677)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=965677)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=965677)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=965677)[0m   "vocab_size": 152064
[36m(ActorRolloutRefWorker pid=965677)[0m }
[36m(ActorRolloutRefWorker pid=965677)[0m 
[36m(ActorRolloutRefWorker pid=965677)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=965677)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(ActorRolloutRefWorker pid=965677)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14796c8efec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=965677)[0m Before building vllm rollout, memory allocated (GB): 1.7850494384765625, memory reserved (GB): 8.94921875
[36m(ActorRolloutRefWorker pid=966566)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14b6ccce3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:29:25 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=966562)[0m WARNING 03-18 11:29:25 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=966562)[0m local rank 0
[36m(ActorRolloutRefWorker pid=966562)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=965677)[0m before init cache memory allocated: 17.248843776GB, reserved: 17.318281216GB
[36m(ActorRolloutRefWorker pid=965677)[0m after init cache memory allocated: 72.622045184GB, reserved: 72.691482624GB
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:29:26 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m WARNING 03-18 11:29:26 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=965677)[0m After building vllm rollout, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
[36m(ActorRolloutRefWorker pid=965677)[0m After building sharding manager, memory allocated (GB): 53.39455032348633, memory reserved (GB): 67.69921875
len(dataset): 30
wg.worker_names: ['H0k4CNActorRolloutRefWorker_0:0', 'H0k4CNActorRolloutRefWorker_0:1', 'H0k4CNActorRolloutRefWorker_0:2', 'H0k4CNActorRolloutRefWorker_0:3', 'H0k4CNActorRolloutRefWorker_0:4', 'H0k4CNActorRolloutRefWorker_0:5', 'H0k4CNActorRolloutRefWorker_0:6', 'H0k4CNActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:29:46 metrics.py:345] Avg prompt throughput: 612.4 tokens/s, Avg generation throughput: 4.3 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=966565)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:29:51 metrics.py:345] Avg prompt throughput: 52.2 tokens/s, Avg generation throughput: 2784.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:29:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2732.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966566)[0m INFO 03-18 11:30:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2657.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:30:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2444.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:30:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2520.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:30:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2456.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:30:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2399.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:30:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2340.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:30:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2242.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:30:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2196.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:30:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2160.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:30:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2117.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966566)[0m INFO 03-18 11:30:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1948.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:31:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2034.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:31:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1982.4 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:31:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1955.5 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:31:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1891.8 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:31:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1852.4 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:31:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1813.1 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:31:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1793.4 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:31:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1771.8 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:31:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1748.4 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:31:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1730.5 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:31:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1695.8 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:32:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1665.5 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:32:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1572.0 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:32:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1676.7 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:32:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1602.9 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:32:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1586.9 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:32:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1630.1 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966566)[0m INFO 03-18 11:32:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1593.1 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:32:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1604.1 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:32:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1567.6 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:32:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1624.0 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:32:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1577.7 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:33:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1542.5 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:33:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1458.0 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:33:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1436.0 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:33:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1472.2 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:33:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1446.5 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:33:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1382.6 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:33:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1329.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966566)[0m INFO 03-18 11:33:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1342.0 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:33:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1292.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:33:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1263.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 34.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:33:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1342.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:34:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1328.9 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:34:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1228.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:34:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1222.2 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:34:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1260.3 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:34:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1176.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:34:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1165.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966566)[0m INFO 03-18 11:34:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1191.1 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:34:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1104.7 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:34:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1087.5 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:34:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1180.3 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:34:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1105.3 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:35:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1133.3 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:35:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1073.3 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:35:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1080.9 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:35:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1075.2 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:35:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1006.4 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 35.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:35:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1012.7 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:35:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1071.2 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:35:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1064.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:35:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 989.3 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:35:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1015.7 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:35:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1010.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:36:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 960.5 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:36:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 954.8 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:36:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 981.1 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:36:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 927.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966566)[0m INFO 03-18 11:36:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 937.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:36:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 913.9 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:36:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 907.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:36:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 949.2 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:36:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 888.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:36:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 908.0 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:36:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 904.7 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:37:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 863.1 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:37:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 944.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:37:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 928.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:37:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 841.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966566)[0m INFO 03-18 11:37:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 854.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:37:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 817.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:37:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 837.4 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:37:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 714.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:37:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 827.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:37:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 835.9 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:37:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 832.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:38:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 828.1 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:38:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 767.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:38:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 764.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:38:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 872.4 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 52.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:38:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 868.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:38:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 706.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:38:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 732.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:38:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 776.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:38:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 717.7 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:38:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 751.1 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:39:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 747.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:39:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 691.4 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:39:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 687.1 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:39:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 808.3 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:39:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 669.4 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:39:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 659.8 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:39:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 686.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:39:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 715.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 47.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:39:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 652.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:39:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 701.5 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:39:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 646.9 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:40:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 264.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:40:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 642.2 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:40:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 755.5 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 52.4%, CPU KV cache usage: 0.0%.[32m [repeated 15x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:40:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 623.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.6%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:40:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 605.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.5%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:40:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 617.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:40:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 613.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 41.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:40:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 599.3 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:40:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 594.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.6%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:41:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 584.3 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:41:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 574.2 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:41:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 625.4 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:41:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 568.5 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:41:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 231.9 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:41:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 512.0 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:41:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 540.1 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 37.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:41:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 682.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.8%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:41:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 597.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:41:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 496.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:42:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 672.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 55.2%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:42:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 514.6 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 34.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:42:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 576.5 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:42:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 574.6 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:42:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:42:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 456.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:42:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 541.1 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:42:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 637.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:42:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 632.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:42:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 630.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 53.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:42:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 543.7 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:43:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 542.2 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:43:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 425.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:43:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 526.1 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:43:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 495.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:43:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 155.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 48.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:43:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:43:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 529.1 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:43:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 528.0 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:43:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 395.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:43:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 394.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:44:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 484.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:44:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 482.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 43.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:44:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 485.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:44:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 554.8 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 48.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:44:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 553.4 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 49.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:44:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 434.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:44:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 431.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 36.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:44:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 494.9 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:44:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 362.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:44:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 441.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 39.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:44:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 472.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:45:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 439.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:45:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 437.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:45:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 435.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 40.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:45:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 520.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 49.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966563)[0m INFO 03-18 11:45:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 420.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 38.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:45:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 469.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:45:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:45:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 464.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=965677)[0m INFO 03-18 11:45:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:45:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 426.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966568)[0m INFO 03-18 11:45:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 443.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 44.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:46:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 481.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:46:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 479.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:46:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 422.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:46:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 421.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 42.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:46:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 442.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 45.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966562)[0m INFO 03-18 11:46:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 351.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:46:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 393.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.6%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:46:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 387.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m INFO 03-18 11:46:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 381.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:46:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 434.3 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:47:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 433.8 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.6%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=966567)[0m INFO 03-18 11:47:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 432.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 46.8%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:47:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 372.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.7%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:47:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 360.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.9%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:47:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 359.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.1%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=966564)[0m INFO 03-18 11:47:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 355.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                                               |
+======================+=====================================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                                                                                                                                                                                        |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.6166666666666667                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@16              | 0.8333333333333334                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@16              | 0.8                                                                                                                                                                                                                                                                 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                                                 |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16581.9875                                                                                                                                                                                                                                                          |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.3137760023276011                                                                                                                                                                                                                                                  |
+----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=966565)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=966565)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt20 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt40 DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ echo 'Datasets: aime'
Datasets: aime
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47
+ for DATA_TYPE in "${DATATYPES[@]}"
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.85 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.85,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.85', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/GLOBALFS/gznwp_3/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 55, in main
    tokenizer = hf_tokenizer(local_path)
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/utils/tokenizer.py", line 55, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 844, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 676, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-7B-fuserl-sft-v3-fuserl-pref-v3.3-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-ckpt47'. Please provide either the path to a local folder or the repo_id of a model on the Hub.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
