+ export VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ MODEL_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1
+ OUTPUT_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs
+ GPU_NUM=8
+ TP=1
+ TEMP=0.6
+ TOP_P=0.95
+ MAX_LEN=32768
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 15:55:42,307	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1610964)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1610964)[0m No module named 'vllm._version'
[36m(pid=1610964)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1611321)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1611321)[0m No module named 'vllm._version'
[36m(pid=1611321)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1611316)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1611316)[0m No module named 'vllm._version'
[36m(pid=1611316)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1610964)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=1611318)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=1611318)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1611318)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1610964)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=1611319)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (17159 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1610964)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1610964)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1610964)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1610964)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1610964)[0m   ],
[36m(ActorRolloutRefWorker pid=1610964)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1610964)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1610964)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1610964)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1610964)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1610964)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1610964)[0m }
[36m(ActorRolloutRefWorker pid=1610964)[0m 
[36m(ActorRolloutRefWorker pid=1610964)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1610964)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1610964)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14906c02bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1610964)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1611319)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14d876127ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611319)[0m INFO 03-22 15:56:39 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1611319)[0m WARNING 03-22 15:56:39 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1610964)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1611316)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 15:56:39 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m WARNING 03-22 15:56:39 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1611319)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1610964)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1610964)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1611319)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 30
wg.worker_names: ['QXz98PActorRolloutRefWorker_0:0', 'QXz98PActorRolloutRefWorker_0:1', 'QXz98PActorRolloutRefWorker_0:2', 'QXz98PActorRolloutRefWorker_0:3', 'QXz98PActorRolloutRefWorker_0:4', 'QXz98PActorRolloutRefWorker_0:5', 'QXz98PActorRolloutRefWorker_0:6', 'QXz98PActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
[36m(ActorRolloutRefWorker pid=1610964)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:56:58 metrics.py:345] Avg prompt throughput: 1684.9 tokens/s, Avg generation throughput: 226.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1611319)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3032.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611321)[0m INFO 03-22 15:57:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3036.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3029.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3027.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3023.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3021.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3020.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2768.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3013.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:57:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3006.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611321)[0m INFO 03-22 15:57:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2998.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 15:58:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2873.6 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2917.1 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2894.0 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2841.6 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2794.4 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2782.2 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 15:58:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2741.0 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2728.3 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2699.1 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:58:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2420.4 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2634.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2576.4 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2577.7 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 15:59:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2611.2 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 15x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 15:59:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2582.3 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 15:59:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2563.1 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2509.9 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2485.6 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2474.4 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2437.1 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 15:59:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2398.4 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:00:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2381.8 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:00:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2318.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:00:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2288.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:00:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2269.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:00:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2320.5 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:00:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2295.5 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611316)[0m INFO 03-22 16:00:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2034.0 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611316)[0m INFO 03-22 16:00:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2019.8 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:00:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2117.5 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:00:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1833.6 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:00:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2057.5 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:01:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2045.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:01:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2030.6 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:01:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1988.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:01:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1959.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:01:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1946.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:01:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1940.4 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611321)[0m INFO 03-22 16:01:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1851.9 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:01:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1876.5 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:01:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1848.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:01:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1819.1 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:01:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1896.4 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:01:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1882.1 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:02:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1718.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:02:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1701.1 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:02:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1684.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:02:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1670.8 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:02:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1626.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:02:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1595.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611320)[0m INFO 03-22 16:02:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1618.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611320)[0m INFO 03-22 16:02:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1588.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:02:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1620.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:02:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1557.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:02:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1635.4 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611316)[0m INFO 03-22 16:03:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1454.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:03:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1422.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:03:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1400.9 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:03:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1390.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:03:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1381.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:03:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1349.6 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611320)[0m INFO 03-22 16:03:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1178.3 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611320)[0m INFO 03-22 16:03:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1145.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611320)[0m INFO 03-22 16:03:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1148.0 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:03:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1345.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:03:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1331.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:04:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1297.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:04:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1347.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:04:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1337.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:04:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1327.5 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:04:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1296.6 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611316)[0m INFO 03-22 16:04:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 755.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611316)[0m INFO 03-22 16:04:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 748.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611316)[0m INFO 03-22 16:04:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 732.2 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:04:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 878.3 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:04:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 877.8 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:04:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 876.9 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:05:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 876.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:05:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 876.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:05:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1150.0 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:05:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1032.7 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:05:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 987.9 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:05:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1065.6 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:05:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1060.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:05:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1027.0 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611320)[0m INFO 03-22 16:05:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611320)[0m INFO 03-22 16:05:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611316)[0m INFO 03-22 16:05:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 640.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:06:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 645.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:06:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 644.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:06:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 542.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1610964)[0m INFO 03-22 16:06:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 464.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:06:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 816.8 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:06:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 789.5 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:06:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 751.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:06:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 591.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611318)[0m INFO 03-22 16:06:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 591.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:06:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 635.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:06:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 636.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:07:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 594.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611322)[0m INFO 03-22 16:07:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 579.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:07:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 516.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:07:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 517.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:07:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 517.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:07:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 517.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:07:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 517.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611317)[0m INFO 03-22 16:07:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 431.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-----------------------------------------------------------------------------------------+
| Metric               | Value                                                                                   |
+======================+=========================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k |
+----------------------+-----------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                            |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@1               | 0.3229166666666667                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@16              | 0.7333333333333333                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cons@16              | 0.5583333333333333                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| mean_response_tokens | 17835.272916666665                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| run_hours            | 0.2060667900244395                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1611319)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1611319)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime25
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 16:08:08,502	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1642280)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1642280)[0m No module named 'vllm._version'
[36m(pid=1642280)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1643182)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1643182)[0m No module named 'vllm._version'
[36m(pid=1643182)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1643167)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1643167)[0m No module named 'vllm._version'
[36m(pid=1643167)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1642280)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1643187)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1643187)[0m   warnings.warn(
[36m(pid=1643189)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1643189)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1643189)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643189)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (22709 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1642280)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1642280)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1642280)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1642280)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1642280)[0m   ],
[36m(ActorRolloutRefWorker pid=1642280)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1642280)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1642280)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1642280)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1642280)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1642280)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1642280)[0m }
[36m(ActorRolloutRefWorker pid=1642280)[0m 
[36m(ActorRolloutRefWorker pid=1642280)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1642280)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1642280)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14c9d811fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1642280)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:08:27 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1643187)[0m WARNING 03-22 16:08:27 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1643189)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14cb4c70fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1643182)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1643182)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1642280)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1642280)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:08:27 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m WARNING 03-22 16:08:27 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1643189)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1642280)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['jszP0TActorRolloutRefWorker_0:0', 'jszP0TActorRolloutRefWorker_0:1', 'jszP0TActorRolloutRefWorker_0:2', 'jszP0TActorRolloutRefWorker_0:3', 'jszP0TActorRolloutRefWorker_0:4', 'jszP0TActorRolloutRefWorker_0:5', 'jszP0TActorRolloutRefWorker_0:6', 'jszP0TActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'In $\\triangle ABC$ points $D$ and $E$ lie on $\\overline{AB}$ '
              'so that $AD < AE < AB$, while points $F$ and $G$ lie on '
              '$\\overline{AC}$ so that $AF < AG < AC$. Suppose $AD = 4$, $DE '
              '= 16$, $EB = 8$, $AF = 13$, $FG = 52$, and $GC = 26$. Let $M$ '
              'be the reflection of $D$ through $F$, and let $N$ be the '
              'reflection of $G$ through $E$. The area of quadrilateral $DEGF$ '
              "is $288$. Find the area of heptagon $AFNBCEM$. Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'The $9$ members of a baseball team went to an ice-cream parlor '
              'after their game. Each player had a single scoop cone of '
              'chocolate, vanilla, or strawberry ice cream. At least one '
              'player chose each flavor, and the number of players who chose '
              'chocolate was greater than the number of players who chose '
              'vanilla, which was greater than the number of players who chose '
              'strawberry. Let $N$ be the number of different assignments of '
              'flavors to players that meet these conditions. Find the '
              "remainder when $N$ is divided by $1000.$ Let's think step by "
              'step and output the final answer within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 848]), content: tensor([[  369,   892,   400,    16,    22,   880],
        [   23,    23, 12947,  7379,   279,  3082],
        [ 7379,   279, 26313,   979,   400,    45],
        ...,
        [  279, 26313,   979,   400,    76, 38334],
        [   77,    59, 26888,    18,     3,   369],
        [ 2750,   315,   400,    87, 12947,  7379]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:08:39 metrics.py:345] Avg prompt throughput: 2304.4 tokens/s, Avg generation throughput: 740.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1643191)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:08:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3004.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:08:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3009.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:08:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3008.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:08:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3008.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:09:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2980.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:09:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2973.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:09:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2975.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:09:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3015.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:09:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2764.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:09:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3004.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:09:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2946.0 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:09:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2942.5 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:09:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2898.3 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:09:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2850.9 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:09:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2822.7 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:09:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2820.9 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:10:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2578.4 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:10:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2575.7 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:10:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2520.1 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:10:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2475.2 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:10:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2475.2 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:10:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2466.1 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:10:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2419.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:10:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2113.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:10:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2352.4 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:10:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2338.5 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:10:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2497.1 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:11:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2483.4 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:11:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2444.9 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:11:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2443.6 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m INFO 03-22 16:11:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2341.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m INFO 03-22 16:11:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2310.5 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m INFO 03-22 16:11:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2313.3 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:11:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2234.5 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:11:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2200.9 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:11:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2197.9 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:11:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2203.9 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:11:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2076.0 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:12:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2070.8 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:12:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2061.7 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:12:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2018.1 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:12:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2015.4 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:12:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2091.5 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:12:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2079.3 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:12:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2062.8 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:12:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1763.8 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:12:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2034.3 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:12:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1981.1 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:12:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1958.3 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m INFO 03-22 16:13:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1875.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:13:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1958.1 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:13:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1913.3 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:13:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1892.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:13:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1861.4 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:13:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1882.4 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:13:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1835.1 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:13:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1816.4 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:13:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1677.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:13:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1661.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:13:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1636.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:13:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1662.8 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:14:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1643.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:14:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1625.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:14:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1650.2 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:14:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1620.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:14:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1541.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:14:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1532.2 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:14:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1519.5 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:14:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1503.0 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:14:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1476.3 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:14:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1459.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:14:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1431.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m INFO 03-22 16:15:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1403.4 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:15:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1466.0 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:15:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1442.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:15:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1415.1 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:15:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1394.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:15:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1258.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:15:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1243.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:15:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1225.5 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:15:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1294.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:15:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1270.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:15:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1241.9 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:16:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 978.6 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:16:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 940.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:16:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 879.5 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:16:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 876.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m INFO 03-22 16:16:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 919.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:16:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1163.1 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:16:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1153.6 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:16:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 576.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:16:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 707.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:16:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 707.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:16:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 706.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:17:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 362.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:17:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 343.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:17:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 343.1 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:17:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 763.8 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m INFO 03-22 16:17:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 517.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:17:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 696.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:17:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 619.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:17:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 578.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643189)[0m INFO 03-22 16:17:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 280.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:17:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1642280)[0m INFO 03-22 16:17:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:17:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 703.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:18:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 677.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643188)[0m INFO 03-22 16:18:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 614.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:18:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 309.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643187)[0m INFO 03-22 16:18:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:18:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 272.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:18:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 273.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643167)[0m INFO 03-22 16:18:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 257.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:18:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 342.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643182)[0m INFO 03-22 16:18:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 225.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:18:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 264.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643190)[0m INFO 03-22 16:18:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-----------------------------------------------------------------------------------------+
| Metric               | Value                                                                                   |
+======================+=========================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k |
+----------------------+-----------------------------------------------------------------------------------------+
| dataset              | aime25.parquet                                                                          |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@1               | 0.2708333333333333                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@16              | 0.5333333333333333                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cons@16              | 0.38571428571428573                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| mean_response_tokens | 17085.685416666667                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| run_hours            | 0.1844906895690494                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1643191)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1643191)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 16:19:26,147	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1671857)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1671857)[0m No module named 'vllm._version'
[36m(pid=1671857)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1672813)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1672813)[0m No module named 'vllm._version'
[36m(pid=1672813)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1672817)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1672817)[0m No module named 'vllm._version'
[36m(pid=1672817)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1671857)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=1672818)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=1672818)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1672818)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1672814)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=1672814)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (30445 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1671857)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1671857)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1671857)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1671857)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1671857)[0m   ],
[36m(ActorRolloutRefWorker pid=1671857)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1671857)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1671857)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1671857)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1671857)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1671857)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1671857)[0m }
[36m(ActorRolloutRefWorker pid=1671857)[0m 
[36m(ActorRolloutRefWorker pid=1671857)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1671857)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1671857)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1437a9a3bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1671857)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1672814)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1434b0ee3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:20:11 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1672816)[0m WARNING 03-22 16:20:11 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1672816)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1672813)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1671857)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1671857)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:20:13 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m WARNING 03-22 16:20:13 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1672815)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 30
wg.worker_names: ['7wjK5zActorRolloutRefWorker_0:0', '7wjK5zActorRolloutRefWorker_0:1', '7wjK5zActorRolloutRefWorker_0:2', '7wjK5zActorRolloutRefWorker_0:3', '7wjK5zActorRolloutRefWorker_0:4', '7wjK5zActorRolloutRefWorker_0:5', '7wjK5zActorRolloutRefWorker_0:6', '7wjK5zActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
[36m(ActorRolloutRefWorker pid=1671857)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1671857)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:20:24 metrics.py:345] Avg prompt throughput: 1688.7 tokens/s, Avg generation throughput: 682.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1672815)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:20:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3055.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:20:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2998.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:20:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2975.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:20:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2975.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:20:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2971.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:20:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2971.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672812)[0m INFO 03-22 16:20:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3010.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:21:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2969.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:21:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2715.1 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:21:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2921.9 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:21:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2913.1 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:21:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2946.4 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:21:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2888.7 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:21:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2865.8 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:21:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2860.9 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:21:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2750.7 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:21:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2746.5 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:21:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2742.4 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:22:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2616.3 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:22:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2580.2 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672812)[0m INFO 03-22 16:22:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2674.5 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672812)[0m INFO 03-22 16:22:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2651.0 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:22:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2632.0 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:22:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2334.0 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:22:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2611.3 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:22:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2583.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:22:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2509.2 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:22:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2352.8 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:22:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2350.3 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:23:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2463.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:23:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2239.2 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:23:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2471.5 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:23:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2405.9 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:23:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2403.8 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:23:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2300.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:23:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2296.3 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:23:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2286.0 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:23:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2261.8 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:23:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2168.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:23:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2148.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:24:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2022.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:24:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2018.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:24:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2134.5 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:24:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2027.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:24:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1969.2 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:24:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2072.9 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:24:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2036.1 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:24:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2006.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:24:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1987.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:24:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1857.1 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:24:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1863.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:25:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1850.4 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:25:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1832.6 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:25:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1815.6 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:25:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1700.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:25:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1783.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672812)[0m INFO 03-22 16:25:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1767.8 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:25:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1752.4 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:25:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1719.3 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:25:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1742.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:25:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1720.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:25:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1703.0 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:26:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1691.7 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:26:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1661.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:26:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1523.0 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:26:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1495.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:26:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1485.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:26:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1519.9 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:26:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1494.8 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:26:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1483.3 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:26:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1359.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:26:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1320.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:26:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1290.6 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672813)[0m INFO 03-22 16:27:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1277.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:27:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1339.0 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:27:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1324.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:27:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1303.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672815)[0m INFO 03-22 16:27:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1170.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:27:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1272.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:27:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1245.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:27:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1186.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:27:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1204.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:27:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1164.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:27:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1124.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:27:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 932.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:28:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1157.5 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:28:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1141.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:28:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1118.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:28:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 702.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:28:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1093.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:28:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1086.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672815)[0m INFO 03-22 16:28:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 597.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672815)[0m INFO 03-22 16:28:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 573.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:28:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 999.0 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:28:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 638.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:28:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 638.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:29:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 527.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:29:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 400.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:29:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 400.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:29:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 400.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672818)[0m INFO 03-22 16:29:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 400.3 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:29:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 746.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:29:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 705.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:29:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 689.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672815)[0m INFO 03-22 16:29:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 514.9 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672815)[0m INFO 03-22 16:29:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 473.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:29:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 703.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672816)[0m INFO 03-22 16:30:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 703.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:30:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 457.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:30:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 412.3 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:30:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672817)[0m INFO 03-22 16:30:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 372.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:30:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 471.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672814)[0m INFO 03-22 16:30:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 469.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1671857)[0m INFO 03-22 16:30:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 421.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-----------------------------------------------------------------------------------------+
| Metric               | Value                                                                                   |
+======================+=========================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k |
+----------------------+-----------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                            |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@1               | 0.3375                                                                                  |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@16              | 0.6666666666666666                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cons@16              | 0.5166666666666667                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| mean_response_tokens | 17394.847916666666                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| run_hours            | 0.19210904955863953                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1672815)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1672815)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime25
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 16:31:10,819	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1702498)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1702498)[0m No module named 'vllm._version'
[36m(pid=1702498)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1703436)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1703436)[0m No module named 'vllm._version'
[36m(pid=1703436)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1703439)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1703439)[0m No module named 'vllm._version'
[36m(pid=1703439)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1703439)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1702498)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1702498)[0m   warnings.warn(
[36m(pid=1703438)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1703438)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1703438)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703438)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (17265 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1702498)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1702498)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1702498)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1702498)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1702498)[0m   ],
[36m(ActorRolloutRefWorker pid=1702498)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1702498)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1702498)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1702498)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1702498)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1702498)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1702498)[0m }
[36m(ActorRolloutRefWorker pid=1702498)[0m 
[36m(ActorRolloutRefWorker pid=1702498)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1702498)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1702498)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x15045d1c7ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1702498)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:31:29 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1703437)[0m WARNING 03-22 16:31:29 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1703442)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14c01e4b7ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1703437)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1703437)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1702498)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1702498)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:31:29 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m WARNING 03-22 16:31:29 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1702498)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1702498)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1703442)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 30
wg.worker_names: ['l7h7PsActorRolloutRefWorker_0:0', 'l7h7PsActorRolloutRefWorker_0:1', 'l7h7PsActorRolloutRefWorker_0:2', 'l7h7PsActorRolloutRefWorker_0:3', 'l7h7PsActorRolloutRefWorker_0:4', 'l7h7PsActorRolloutRefWorker_0:5', 'l7h7PsActorRolloutRefWorker_0:6', 'l7h7PsActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'In $\\triangle ABC$ points $D$ and $E$ lie on $\\overline{AB}$ '
              'so that $AD < AE < AB$, while points $F$ and $G$ lie on '
              '$\\overline{AC}$ so that $AF < AG < AC$. Suppose $AD = 4$, $DE '
              '= 16$, $EB = 8$, $AF = 13$, $FG = 52$, and $GC = 26$. Let $M$ '
              'be the reflection of $D$ through $F$, and let $N$ be the '
              'reflection of $G$ through $E$. The area of quadrilateral $DEGF$ '
              "is $288$. Find the area of heptagon $AFNBCEM$. Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'The $9$ members of a baseball team went to an ice-cream parlor '
              'after their game. Each player had a single scoop cone of '
              'chocolate, vanilla, or strawberry ice cream. At least one '
              'player chose each flavor, and the number of players who chose '
              'chocolate was greater than the number of players who chose '
              'vanilla, which was greater than the number of players who chose '
              'strawberry. Let $N$ be the number of different assignments of '
              'flavors to players that meet these conditions. Find the '
              "remainder when $N$ is divided by $1000.$ Let's think step by "
              'step and output the final answer within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 848]), content: tensor([[  369,   892,   400,    16,    22,   880],
        [   23,    23, 12947,  7379,   279,  3082],
        [ 7379,   279, 26313,   979,   400,    45],
        ...,
        [  279, 26313,   979,   400,    76, 38334],
        [   77,    59, 26888,    18,     3,   369],
        [ 2750,   315,   400,    87, 12947,  7379]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:31:40 metrics.py:345] Avg prompt throughput: 2295.5 tokens/s, Avg generation throughput: 558.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1703442)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:31:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2999.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:31:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3002.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:31:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3039.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:32:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3038.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:32:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3034.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:32:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3029.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:32:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2919.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:32:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2917.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:32:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2654.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:32:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2868.8 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:32:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3029.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:32:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2983.7 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:32:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2944.8 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:32:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2903.2 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:33:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2715.5 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:33:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2710.7 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:33:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2769.8 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:33:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2739.6 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:33:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2665.6 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:33:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2537.8 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:33:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2537.3 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:33:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2518.2 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:33:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2477.9 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:33:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2421.7 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:33:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2144.9 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:33:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2477.9 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:34:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2352.0 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:34:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2316.4 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:34:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2310.8 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:34:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2271.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:34:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2258.0 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:34:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2231.5 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:34:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2223.6 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:34:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2240.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:34:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2233.9 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:34:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2232.4 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:34:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2154.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:35:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2111.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:35:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2074.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:35:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2159.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:35:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2139.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:35:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2038.5 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:35:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2016.8 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:35:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1993.2 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:35:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1962.7 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:35:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1939.5 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:35:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1629.0 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:35:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1880.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:36:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1668.7 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:36:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1929.0 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:36:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1905.3 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:36:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1884.9 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:36:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1869.0 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:36:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1843.1 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:36:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1793.1 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:36:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1782.3 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:36:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1697.0 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:36:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1645.4 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:36:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1627.7 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:37:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1658.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:37:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1625.5 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:37:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1634.5 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:37:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1621.7 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:37:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1610.8 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:37:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1532.2 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:37:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1515.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:37:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1498.4 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:37:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1465.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:37:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1463.0 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:37:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1510.3 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:37:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1479.2 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:38:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1465.8 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:38:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1380.3 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:38:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1370.3 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:38:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1344.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:38:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1331.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:38:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1302.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:38:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1294.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:38:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1284.9 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:38:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1258.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:38:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1300.3 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:38:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1286.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:39:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1234.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:39:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1211.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:39:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 654.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703437)[0m INFO 03-22 16:39:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 595.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:39:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 942.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:39:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 949.9 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:39:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 941.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:39:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 930.6 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:39:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 921.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:39:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 921.5 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:39:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 937.8 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:39:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 883.8 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:40:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 805.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:40:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 770.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:40:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 751.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703440)[0m INFO 03-22 16:40:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 405.2 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:40:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 959.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:40:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 925.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:40:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 514.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:40:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 491.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:40:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 524.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:40:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 523.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:40:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 524.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m INFO 03-22 16:41:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 408.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703439)[0m INFO 03-22 16:41:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 339.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703440)[0m INFO 03-22 16:41:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 270.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703440)[0m INFO 03-22 16:41:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:41:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 585.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:41:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 585.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:41:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 192.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703436)[0m INFO 03-22 16:41:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703441)[0m INFO 03-22 16:41:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 143.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1702498)[0m INFO 03-22 16:41:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 320.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-----------------------------------------------------------------------------------------+
| Metric               | Value                                                                                   |
+======================+=========================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k |
+----------------------+-----------------------------------------------------------------------------------------+
| dataset              | aime25.parquet                                                                          |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@1               | 0.25416666666666665                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@16              | 0.5                                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| cons@16              | 0.37126984126984125                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| mean_response_tokens | 17138.058333333334                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| run_hours            | 0.18363827241791617                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1703442)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1703442)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.2-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 16:42:51,119	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1733068)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1733068)[0m No module named 'vllm._version'
[36m(pid=1733068)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1733928)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1733928)[0m No module named 'vllm._version'
[36m(pid=1733928)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1733922)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1733922)[0m No module named 'vllm._version'
[36m(pid=1733922)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1733068)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=1733927)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=1733927)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1733927)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1733925)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=1733927)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (20031 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1733068)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1733068)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1733068)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1733068)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1733068)[0m   ],
[36m(ActorRolloutRefWorker pid=1733068)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1733068)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1733068)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1733068)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1733068)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1733068)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1733068)[0m }
[36m(ActorRolloutRefWorker pid=1733068)[0m 
[36m(ActorRolloutRefWorker pid=1733068)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1733068)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1733068)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x147bc3b2fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1733068)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=1733927)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x146792a37ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:43:58 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1733925)[0m WARNING 03-22 16:43:58 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1733925)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1733925)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1733068)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=1733068)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:44:01 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m WARNING 03-22 16:44:01 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1733926)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=1733068)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
len(dataset): 30
wg.worker_names: ['Q7ZhfUActorRolloutRefWorker_0:0', 'Q7ZhfUActorRolloutRefWorker_0:1', 'Q7ZhfUActorRolloutRefWorker_0:2', 'Q7ZhfUActorRolloutRefWorker_0:3', 'Q7ZhfUActorRolloutRefWorker_0:4', 'Q7ZhfUActorRolloutRefWorker_0:5', 'Q7ZhfUActorRolloutRefWorker_0:6', 'Q7ZhfUActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:44:12 metrics.py:345] Avg prompt throughput: 1687.4 tokens/s, Avg generation throughput: 466.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1733924)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:44:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3042.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:44:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2982.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:44:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2977.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:44:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2975.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:44:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2978.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:44:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3029.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:44:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2973.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:44:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2971.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:44:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2718.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:45:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2953.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:45:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2932.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:45:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2914.6 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:45:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2842.5 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:45:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2838.7 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:45:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2782.6 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733923)[0m INFO 03-22 16:45:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2790.7 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:45:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2729.1 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:45:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2723.9 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:45:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2667.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:45:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2739.0 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:46:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2700.5 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:46:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2623.6 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:46:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2608.8 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:46:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2315.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:46:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2558.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:46:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2540.4 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:46:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2462.1 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:46:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2457.9 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:46:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2327.5 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:46:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2302.6 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:46:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2285.2 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:47:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2261.6 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:47:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2245.8 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:47:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2298.3 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:47:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2282.2 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:47:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2054.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:47:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2044.5 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:47:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2018.4 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:47:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1995.5 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:47:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1994.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:47:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2174.1 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:47:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2134.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:47:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2118.8 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:48:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2090.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:48:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2048.6 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:48:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1725.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:48:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1989.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:48:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1699.6 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:48:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1912.7 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:48:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1902.7 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:48:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1886.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:48:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1868.4 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:48:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1853.6 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:48:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1644.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:49:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1799.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:49:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1784.1 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:49:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1878.6 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:49:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1867.2 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:49:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1847.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:49:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1832.9 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:49:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1646.6 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:49:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1631.3 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:49:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1541.6 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:49:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1526.7 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:49:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1507.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:49:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1484.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:50:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1485.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733923)[0m INFO 03-22 16:50:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1503.7 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:50:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1208.4 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:50:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1159.1 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:50:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1046.1 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:50:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1257.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:50:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1255.6 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:50:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1229.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:50:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1487.0 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:50:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1302.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:50:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1293.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:51:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1284.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:51:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1213.9 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:51:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1206.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:51:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1198.5 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:51:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 884.1 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:51:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 595.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:51:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 598.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:51:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 550.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:51:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 687.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:51:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 690.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:51:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 691.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:52:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1200.8 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:52:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1195.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733927)[0m INFO 03-22 16:52:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 696.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733927)[0m INFO 03-22 16:52:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 478.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733923)[0m INFO 03-22 16:52:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 875.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733923)[0m INFO 03-22 16:52:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 834.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:52:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1008.8 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:52:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 944.6 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:52:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 797.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:52:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 528.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733925)[0m INFO 03-22 16:52:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 666.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:53:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:53:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 212.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733922)[0m INFO 03-22 16:53:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 211.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733068)[0m INFO 03-22 16:53:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 514.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:53:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 913.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733927)[0m INFO 03-22 16:53:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 461.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733927)[0m INFO 03-22 16:53:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 461.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733923)[0m INFO 03-22 16:53:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 526.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733923)[0m INFO 03-22 16:53:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 526.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733923)[0m INFO 03-22 16:53:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 526.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:53:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 449.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:53:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733928)[0m INFO 03-22 16:54:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 398.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:54:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 682.9 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m INFO 03-22 16:54:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 648.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:54:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 604.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:54:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 576.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:54:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 518.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1733926)[0m INFO 03-22 16:54:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 491.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-----------------------------------------------------------------------------------------+
| Metric               | Value                                                                                   |
+======================+=========================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k |
+----------------------+-----------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                            |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@1               | 0.3625                                                                                  |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@16              | 0.8333333333333334                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cons@16              | 0.6700396825396825                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| mean_response_tokens | 17112.7375                                                                              |
+----------------------+-----------------------------------------------------------------------------------------+
| run_hours            | 0.20055568350685968                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1733924)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1733924)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime25
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 16:55:07,071	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1764950)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1764950)[0m No module named 'vllm._version'
[36m(pid=1764950)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1765785)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1765785)[0m No module named 'vllm._version'
[36m(pid=1765785)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1765788)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1765788)[0m No module named 'vllm._version'
[36m(pid=1765788)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1765785)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1765784)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1765784)[0m   warnings.warn(
[36m(pid=1765787)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1765787)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1765787)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765786)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (22278 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1764950)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1764950)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1764950)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1764950)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1764950)[0m   ],
[36m(ActorRolloutRefWorker pid=1764950)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1764950)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1764950)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1764950)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1764950)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1764950)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1764950)[0m }
[36m(ActorRolloutRefWorker pid=1764950)[0m 
[36m(ActorRolloutRefWorker pid=1764950)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1764950)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1764950)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14e42ce43ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1764950)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:55:25 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1765783)[0m WARNING 03-22 16:55:25 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1765787)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14d4c680fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1765783)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1765787)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1764950)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1764950)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:55:25 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m WARNING 03-22 16:55:25 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765787)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1765788)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1764950)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['VaJnojActorRolloutRefWorker_0:0', 'VaJnojActorRolloutRefWorker_0:1', 'VaJnojActorRolloutRefWorker_0:2', 'VaJnojActorRolloutRefWorker_0:3', 'VaJnojActorRolloutRefWorker_0:4', 'VaJnojActorRolloutRefWorker_0:5', 'VaJnojActorRolloutRefWorker_0:6', 'VaJnojActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'In $\\triangle ABC$ points $D$ and $E$ lie on $\\overline{AB}$ '
              'so that $AD < AE < AB$, while points $F$ and $G$ lie on '
              '$\\overline{AC}$ so that $AF < AG < AC$. Suppose $AD = 4$, $DE '
              '= 16$, $EB = 8$, $AF = 13$, $FG = 52$, and $GC = 26$. Let $M$ '
              'be the reflection of $D$ through $F$, and let $N$ be the '
              'reflection of $G$ through $E$. The area of quadrilateral $DEGF$ '
              "is $288$. Find the area of heptagon $AFNBCEM$. Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'The $9$ members of a baseball team went to an ice-cream parlor '
              'after their game. Each player had a single scoop cone of '
              'chocolate, vanilla, or strawberry ice cream. At least one '
              'player chose each flavor, and the number of players who chose '
              'chocolate was greater than the number of players who chose '
              'vanilla, which was greater than the number of players who chose '
              'strawberry. Let $N$ be the number of different assignments of '
              'flavors to players that meet these conditions. Find the '
              "remainder when $N$ is divided by $1000.$ Let's think step by "
              'step and output the final answer within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 848]), content: tensor([[  369,   892,   400,    16,    22,   880],
        [   23,    23, 12947,  7379,   279,  3082],
        [ 7379,   279, 26313,   979,   400,    45],
        ...,
        [  279, 26313,   979,   400,    76, 38334],
        [   77,    59, 26888,    18,     3,   369],
        [ 2750,   315,   400,    87, 12947,  7379]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:55:36 metrics.py:345] Avg prompt throughput: 2300.5 tokens/s, Avg generation throughput: 547.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1765785)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:55:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3008.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:55:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3016.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:55:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2979.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:55:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2981.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:56:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2999.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:56:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2997.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 16:56:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3023.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 16:56:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2985.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:56:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2683.4 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:56:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2928.7 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:56:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2920.7 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:56:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2916.0 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:56:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2917.9 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:56:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2703.4 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:56:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2619.5 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:57:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2573.4 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765787)[0m INFO 03-22 16:57:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2716.3 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765787)[0m INFO 03-22 16:57:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2682.4 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:57:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2580.5 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:57:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2574.8 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:57:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2571.1 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:57:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2531.4 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 16:57:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2459.7 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 16:57:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2121.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 16:57:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2345.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 16:57:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2340.9 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 16:57:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2338.9 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:58:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2425.8 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:58:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2390.4 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:58:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2414.5 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:58:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2423.8 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:58:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2370.9 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:58:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2295.0 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:58:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2246.4 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 16:58:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2163.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 16:58:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2149.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 16:58:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2153.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:58:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2187.7 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 16:59:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2183.9 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:59:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2125.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:59:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2108.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 16:59:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2084.0 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 16:59:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2034.9 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:59:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2081.0 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 16:59:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2056.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 16:59:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1947.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 16:59:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1892.6 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 16:59:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1614.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 16:59:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1875.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:00:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1983.7 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:00:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1960.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:00:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1951.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 17:00:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1676.1 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 17:00:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1660.0 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:00:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1730.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:00:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1695.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:00:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1668.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:00:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1636.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:00:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1720.3 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:00:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1704.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:01:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1690.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:01:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1679.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 17:01:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1530.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 17:01:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1508.1 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 17:01:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1525.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:01:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1646.3 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:01:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1635.3 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:01:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1622.5 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:01:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1372.1 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:01:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1319.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:01:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1232.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:02:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1258.8 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765786)[0m INFO 03-22 17:02:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1419.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765786)[0m INFO 03-22 17:02:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1406.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765786)[0m INFO 03-22 17:02:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1398.2 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:02:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1405.6 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:02:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1394.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:02:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1383.2 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:02:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1350.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765782)[0m INFO 03-22 17:02:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 926.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 17:02:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 898.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 17:02:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 836.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:02:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1359.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:03:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1020.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:03:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1280.9 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:03:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1261.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 17:03:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 908.6 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 17:03:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 908.6 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:03:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 529.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:03:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 506.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765786)[0m INFO 03-22 17:03:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 975.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:03:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 810.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:03:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 772.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:03:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 754.5 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 17:04:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 449.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:04:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 731.3 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:04:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 697.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 17:04:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 627.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 17:04:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 574.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:04:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 400.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765784)[0m INFO 03-22 17:04:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 294.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:04:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 430.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:04:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 392.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:04:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 337.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765788)[0m INFO 03-22 17:04:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:05:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:05:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 398.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765783)[0m INFO 03-22 17:05:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:05:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 339.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:05:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 338.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:05:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 306.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1764950)[0m INFO 03-22 17:05:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 170.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:05:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 336.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:05:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 288.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m INFO 03-22 17:05:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-----------------------------------------------------------------------------------------+
| Metric               | Value                                                                                   |
+======================+=========================================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-pref-v3.3.3-dpo-beta0.3-lr3e-7-ep1-bs16-cutoff-16k |
+----------------------+-----------------------------------------------------------------------------------------+
| dataset              | aime25.parquet                                                                          |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@1               | 0.27291666666666664                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| pass@16              | 0.5666666666666667                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cons@16              | 0.3854166666666667                                                                      |
+----------------------+-----------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
| mean_response_tokens | 16863.21875                                                                             |
+----------------------+-----------------------------------------------------------------------------------------+
| run_hours            | 0.18410203165478176                                                                     |
+----------------------+-----------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1765785)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1765785)[0m   warnings.warn([32m [repeated 7x across cluster][0m
