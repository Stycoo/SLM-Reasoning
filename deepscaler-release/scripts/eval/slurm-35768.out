+ export VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ MODEL_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1
+ OUTPUT_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs
+ GPU_NUM=8
+ TP=1
+ TEMP=0.6
+ TOP_P=0.95
+ MAX_LEN=32768
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 10:36:56,786	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=905311)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=905311)[0m No module named 'vllm._version'
[36m(pid=905311)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=905671)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=905671)[0m No module named 'vllm._version'
[36m(pid=905671)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=905672)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=905672)[0m No module named 'vllm._version'
[36m(pid=905672)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=905311)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=905670)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=905670)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=905670)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=905311)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=905670)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (19836 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=905311)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=905311)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=905311)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=905311)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=905311)[0m   ],
[36m(ActorRolloutRefWorker pid=905311)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=905311)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=905311)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=905311)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=905311)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=905311)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=905311)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=905311)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=905311)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=905311)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=905311)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=905311)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=905311)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=905311)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=905311)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=905311)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=905311)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=905311)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=905311)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=905311)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=905311)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=905311)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=905311)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=905311)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=905311)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=905311)[0m }
[36m(ActorRolloutRefWorker pid=905311)[0m 
[36m(ActorRolloutRefWorker pid=905311)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=905311)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=905311)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14b2d7cf7ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=905311)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=905670)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1464f81cfec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:38:02 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=905311)[0m WARNING 03-22 10:38:02 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=905670)[0m local rank 0
[36m(ActorRolloutRefWorker pid=905671)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=905673)[0m INFO 03-22 10:38:02 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=905673)[0m WARNING 03-22 10:38:02 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=905667)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=905311)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=905311)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=905311)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=905670)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
len(dataset): 500
wg.worker_names: ['MhbRz6ActorRolloutRefWorker_0:0', 'MhbRz6ActorRolloutRefWorker_0:1', 'MhbRz6ActorRolloutRefWorker_0:2', 'MhbRz6ActorRolloutRefWorker_0:3', 'MhbRz6ActorRolloutRefWorker_0:4', 'MhbRz6ActorRolloutRefWorker_0:5', 'MhbRz6ActorRolloutRefWorker_0:6', 'MhbRz6ActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:38:28 metrics.py:345] Avg prompt throughput: 764.8 tokens/s, Avg generation throughput: 9.4 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=905670)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:38:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3023.5 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:38:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3164.2 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 15x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:38:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3142.0 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:38:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2866.9 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:39:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2678.4 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:39:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2338.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:39:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1988.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:39:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2196.2 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 15x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:39:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1674.1 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:39:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1669.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:39:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1412.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:40:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1267.4 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:40:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1146.5 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 14x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:40:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1091.5 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:40:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1091.9 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:40:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1187.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 15x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:40:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1301.1 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:40:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 971.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:41:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 920.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 16x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:41:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 916.1 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 14x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:41:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1039.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:41:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 859.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:41:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 859.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:41:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 707.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 15x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:41:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 886.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:41:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 797.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:41:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 779.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:42:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 752.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:42:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 687.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:42:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 670.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:42:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 654.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 14x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:42:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 706.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 14x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:42:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 609.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:42:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 602.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:42:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 645.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:42:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:43:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 544.9 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:43:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 583.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:43:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 476.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:43:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 544.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:43:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:43:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 365.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:43:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 372.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:43:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 480.0 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:43:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 479.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905673)[0m INFO 03-22 10:43:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 401.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:44:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 270.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:44:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:44:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 411.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:44:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 366.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:44:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 270.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905672)[0m INFO 03-22 10:44:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 456.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:44:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:44:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:44:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 348.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:44:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 347.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:45:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 204.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:45:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 204.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:45:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:45:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 347.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:45:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 347.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:45:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 204.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905672)[0m INFO 03-22 10:45:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 203.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:45:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:45:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:45:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 347.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:46:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 347.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905673)[0m INFO 03-22 10:46:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 274.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905672)[0m INFO 03-22 10:46:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 142.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:46:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m INFO 03-22 10:46:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905671)[0m INFO 03-22 10:46:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905311)[0m INFO 03-22 10:46:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 279.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905673)[0m INFO 03-22 10:46:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 274.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:46:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=905673)[0m INFO 03-22 10:46:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 274.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=905669)[0m INFO 03-22 10:47:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=905668)[0m INFO 03-22 10:47:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 248.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=905667)[0m INFO 03-22 10:47:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 514.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------+
| Metric               | Value                                                                  |
+======================+========================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k |
+----------------------+------------------------------------------------------------------------+
| dataset              | math.parquet                                                           |
+----------------------+------------------------------------------------------------------------+
| pass@1               | 0.832                                                                  |
+----------------------+------------------------------------------------------------------------+
| cons@1               | 0.832                                                                  |
+----------------------+------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                    |
+----------------------+------------------------------------------------------------------------+
| mean_response_tokens | 7459.622                                                               |
+----------------------+------------------------------------------------------------------------+
| run_hours            | 0.18174238390392727                                                    |
+----------------------+------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=905670)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=905670)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=905667)[0m INFO 03-22 10:47:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 514.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 10:47:51,746	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=933273)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=933273)[0m No module named 'vllm._version'
[36m(pid=933273)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=934209)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=934209)[0m No module named 'vllm._version'
[36m(pid=934209)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=934212)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=934212)[0m No module named 'vllm._version'
[36m(pid=934212)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=934208)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=934210)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=934210)[0m   warnings.warn(
[36m(pid=934210)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=934210)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=934210)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (32702 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=933273)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=933273)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=933273)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=933273)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=933273)[0m   ],
[36m(ActorRolloutRefWorker pid=933273)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=933273)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=933273)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=933273)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=933273)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=933273)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=933273)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=933273)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=933273)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=933273)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=933273)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=933273)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=933273)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=933273)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=933273)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=933273)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=933273)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=933273)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=933273)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=933273)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=933273)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=933273)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=933273)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=933273)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=933273)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=933273)[0m }
[36m(ActorRolloutRefWorker pid=933273)[0m 
[36m(ActorRolloutRefWorker pid=933273)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=933273)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=933273)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1473c0fdbec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=933273)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:48:10 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=934206)[0m WARNING 03-22 10:48:10 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=934211)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14e8cf8f3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=934206)[0m local rank 0
[36m(ActorRolloutRefWorker pid=934210)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=933273)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=933273)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:48:10 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m WARNING 03-22 10:48:10 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=934211)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=933273)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['GbmahGActorRolloutRefWorker_0:0', 'GbmahGActorRolloutRefWorker_0:1', 'GbmahGActorRolloutRefWorker_0:2', 'GbmahGActorRolloutRefWorker_0:3', 'GbmahGActorRolloutRefWorker_0:4', 'GbmahGActorRolloutRefWorker_0:5', 'GbmahGActorRolloutRefWorker_0:6', 'GbmahGActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:48:22 metrics.py:345] Avg prompt throughput: 1686.2 tokens/s, Avg generation throughput: 382.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=934211)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:48:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2972.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:48:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2981.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:48:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3005.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:48:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2998.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:48:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2994.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:48:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2988.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:48:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2951.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:49:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2703.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:49:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2967.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:49:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2971.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:49:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2994.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:49:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2831.1 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:49:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2806.2 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:49:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2910.5 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:49:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2870.2 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:49:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2816.0 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:49:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2891.9 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:50:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2842.4 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:50:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2816.9 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:50:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2726.5 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:50:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2721.4 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:50:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2507.3 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:50:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2363.4 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:50:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2733.2 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:50:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2697.1 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:50:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2634.6 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:50:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2641.7 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:50:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2604.9 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:51:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2555.1 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:51:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2567.8 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:51:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2555.6 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:51:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2590.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:51:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2491.7 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:51:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2415.1 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:51:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2295.5 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:51:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2461.0 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:51:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2426.3 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:51:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2259.8 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:51:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2216.5 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:52:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2230.2 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:52:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2194.3 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:52:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2208.9 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:52:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2081.4 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:52:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2075.8 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:52:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1991.5 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:52:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2160.2 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:52:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2122.5 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:52:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2025.0 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:52:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1946.0 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:52:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1919.7 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:53:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1884.5 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:53:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1917.4 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:53:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1886.2 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:53:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1773.4 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:53:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1762.1 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:53:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1906.3 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:53:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1844.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:53:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1825.5 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:53:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1747.4 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:53:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1735.0 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:53:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1767.2 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:54:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1735.5 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:54:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1690.2 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:54:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1636.3 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:54:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1718.9 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:54:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1696.2 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:54:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1665.5 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:54:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1652.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:54:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1590.7 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:54:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1569.6 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:54:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1543.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:54:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1568.7 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:55:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1584.5 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:55:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1509.3 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:55:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1514.1 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934207)[0m INFO 03-22 10:55:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1426.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:55:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1553.4 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:55:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1527.8 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:55:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1498.6 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:55:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1399.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:55:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1418.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 10:55:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1476.6 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:55:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1470.7 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:56:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1396.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:56:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1462.1 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:56:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1431.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:56:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1303.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:56:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1333.5 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:56:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1327.1 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:56:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1352.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:56:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1344.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:56:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1254.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:56:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1348.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:57:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1362.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:57:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1220.6 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:57:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1272.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:57:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1264.0 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:57:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1172.4 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:57:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1272.5 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:57:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1258.9 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:57:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1297.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:57:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1161.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:57:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1149.9 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:57:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1181.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:58:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1174.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:58:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1103.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:58:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1096.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:58:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1198.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:58:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1212.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:58:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1058.6 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:58:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1122.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:58:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1053.7 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:58:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1027.2 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:58:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1147.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:59:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1143.4 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:59:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1154.1 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934206)[0m INFO 03-22 10:59:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 986.8 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 10:59:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1036.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:59:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 920.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m INFO 03-22 10:59:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 865.6 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:59:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 936.9 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934210)[0m INFO 03-22 10:59:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 931.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 10:59:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1068.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:59:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1082.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 10:59:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1086.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=934209)[0m INFO 03-22 11:00:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 983.0 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=934208)[0m INFO 03-22 11:00:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1031.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.6%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 11:00:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 984.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.9%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 11:00:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 978.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=933273)[0m INFO 03-22 11:00:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 906.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 11:00:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1031.1 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.3%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 11:00:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1024.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.5%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 11:00:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1018.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.8%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 11:00:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1008.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.8%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 11:00:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 988.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.7%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=934212)[0m INFO 03-22 11:01:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 976.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.6%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------+
| Metric               | Value                                                                  |
+======================+========================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k |
+----------------------+------------------------------------------------------------------------+
| dataset              | aime.parquet                                                           |
+----------------------+------------------------------------------------------------------------+
| pass@1               | 0.32083333333333336                                                    |
+----------------------+------------------------------------------------------------------------+
| pass@16              | 0.7                                                                    |
+----------------------+------------------------------------------------------------------------+
| cons@16              | 0.5453703703703704                                                     |
+----------------------+------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                    |
+----------------------+------------------------------------------------------------------------+
| mean_response_tokens | 21953.8                                                                |
+----------------------+------------------------------------------------------------------------+
| run_hours            | 0.22489121576150256                                                    |
+----------------------+------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=934211)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=934211)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime25
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 11:01:36,203	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=968271)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=968271)[0m No module named 'vllm._version'
[36m(pid=968271)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=969164)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=969164)[0m No module named 'vllm._version'
[36m(pid=969164)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=969162)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=969162)[0m No module named 'vllm._version'
[36m(pid=969162)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=969162)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=969160)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=969160)[0m   warnings.warn(
[36m(pid=969166)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=969166)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=969166)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (32594 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=968271)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=968271)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=968271)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=968271)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=968271)[0m   ],
[36m(ActorRolloutRefWorker pid=968271)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=968271)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=968271)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=968271)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=968271)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=968271)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=968271)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=968271)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=968271)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=968271)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=968271)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=968271)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=968271)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=968271)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=968271)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=968271)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=968271)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=968271)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=968271)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=968271)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=968271)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=968271)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=968271)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=968271)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=968271)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=968271)[0m }
[36m(ActorRolloutRefWorker pid=968271)[0m 
[36m(ActorRolloutRefWorker pid=968271)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=968271)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=968271)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x150f9cfebec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=968271)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:01:54 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=969160)[0m WARNING 03-22 11:01:54 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=969166)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14b94460bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=969160)[0m local rank 0
[36m(ActorRolloutRefWorker pid=969163)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=968271)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=968271)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:01:54 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m WARNING 03-22 11:01:54 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=969166)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 30
wg.worker_names: ['UdplhAActorRolloutRefWorker_0:0', 'UdplhAActorRolloutRefWorker_0:1', 'UdplhAActorRolloutRefWorker_0:2', 'UdplhAActorRolloutRefWorker_0:3', 'UdplhAActorRolloutRefWorker_0:4', 'UdplhAActorRolloutRefWorker_0:5', 'UdplhAActorRolloutRefWorker_0:6', 'UdplhAActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'In $\\triangle ABC$ points $D$ and $E$ lie on $\\overline{AB}$ '
              'so that $AD < AE < AB$, while points $F$ and $G$ lie on '
              '$\\overline{AC}$ so that $AF < AG < AC$. Suppose $AD = 4$, $DE '
              '= 16$, $EB = 8$, $AF = 13$, $FG = 52$, and $GC = 26$. Let $M$ '
              'be the reflection of $D$ through $F$, and let $N$ be the '
              'reflection of $G$ through $E$. The area of quadrilateral $DEGF$ '
              "is $288$. Find the area of heptagon $AFNBCEM$. Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'The $9$ members of a baseball team went to an ice-cream parlor '
              'after their game. Each player had a single scoop cone of '
              'chocolate, vanilla, or strawberry ice cream. At least one '
              'player chose each flavor, and the number of players who chose '
              'chocolate was greater than the number of players who chose '
              'vanilla, which was greater than the number of players who chose '
              'strawberry. Let $N$ be the number of different assignments of '
              'flavors to players that meet these conditions. Find the '
              "remainder when $N$ is divided by $1000.$ Let's think step by "
              'step and output the final answer within \\boxed{}.',
   'role': 'user'}]]
[36m(ActorRolloutRefWorker pid=968271)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=968271)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
main_gen.py, input_ids.shape = torch.Size([480, 848]), content: tensor([[  369,   892,   400,    16,    22,   880],
        [   23,    23, 12947,  7379,   279,  3082],
        [ 7379,   279, 26313,   979,   400,    45],
        ...,
        [  279, 26313,   979,   400,    76, 38334],
        [   77,    59, 26888,    18,     3,   369],
        [ 2750,   315,   400,    87, 12947,  7379]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:02:05 metrics.py:345] Avg prompt throughput: 2298.0 tokens/s, Avg generation throughput: 391.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=968271)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:02:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3015.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:02:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3032.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:02:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2994.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:02:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2991.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:02:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2972.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:02:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2969.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:02:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2936.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:02:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2968.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:02:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3012.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:03:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3010.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:03:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2967.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:03:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2958.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:03:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2936.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:03:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2852.3 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:03:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2923.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:03:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2899.8 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:03:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2864.7 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:03:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2824.0 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:03:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2788.2 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:03:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2738.9 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:04:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2696.7 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:04:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2626.5 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:04:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2437.3 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:04:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2566.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:04:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2681.8 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:04:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2678.3 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:04:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2647.8 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:04:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2644.1 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:04:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2609.1 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:04:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2453.2 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:04:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2418.9 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:05:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2468.7 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:05:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2419.5 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:05:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2357.1 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:05:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2434.2 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:05:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2386.9 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:05:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2379.0 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:05:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2358.8 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:05:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2244.1 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:05:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2168.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:05:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2092.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:05:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2129.4 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:06:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1908.1 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:06:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2163.5 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:06:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2142.1 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:06:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2087.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:06:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2026.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:06:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2013.5 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:06:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1841.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:06:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1833.4 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:06:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1895.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:06:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1960.1 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:06:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1935.6 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:07:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1849.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:07:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1844.6 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:07:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1834.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:07:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1721.3 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:07:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1707.4 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:07:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1692.6 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:07:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1748.6 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:07:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1763.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:07:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1750.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:07:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1602.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:08:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1663.2 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:08:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1648.4 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:08:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1551.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:08:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1525.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:08:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1603.7 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:08:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1635.4 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:08:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1603.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:08:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1485.2 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:08:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1476.1 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:08:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1540.4 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:08:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1526.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:09:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1409.0 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:09:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1334.2 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:09:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1323.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:09:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1454.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969164)[0m INFO 03-22 11:09:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1520.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:09:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1338.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:09:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1296.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:09:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1458.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:09:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1434.9 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:09:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1427.0 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:09:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1209.1 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:10:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1371.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:10:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1420.7 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:10:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1265.2 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:10:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1206.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:10:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1195.9 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:10:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1364.0 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:10:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1355.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:10:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1338.3 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:10:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1126.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:10:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1269.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:10:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1258.1 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969164)[0m INFO 03-22 11:11:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1287.4 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:11:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1186.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:11:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1103.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:11:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1205.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:11:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1185.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:11:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1244.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:11:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1238.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:11:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1048.1 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:11:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1151.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:11:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1121.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:11:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1041.2 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:12:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1078.9 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:12:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1074.8 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:12:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1175.5 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:12:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1170.2 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:12:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 984.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:12:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 976.8 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:12:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1063.1 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:12:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1039.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m INFO 03-22 11:12:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 956.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:12:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1003.6 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:13:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1117.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:13:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1113.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969163)[0m INFO 03-22 11:13:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 837.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:13:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1011.6 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=969166)[0m INFO 03-22 11:13:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1004.1 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=969165)[0m INFO 03-22 11:13:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 983.5 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:13:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1074.3 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:13:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1069.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.2%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:13:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 977.6 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:13:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 976.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.3%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=969162)[0m INFO 03-22 11:13:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 960.3 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.7%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=969164)[0m INFO 03-22 11:14:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1015.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.5%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:14:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1044.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 33.2%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:14:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1030.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.2%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=969160)[0m INFO 03-22 11:14:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1001.9 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.9%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:14:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1020.4 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.4%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:14:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1014.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.6%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:14:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 723.9 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.7%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:14:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 989.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.9%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:14:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 986.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.1%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=969161)[0m INFO 03-22 11:14:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 948.0 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------+
| Metric               | Value                                                                  |
+======================+========================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k |
+----------------------+------------------------------------------------------------------------+
| dataset              | aime25.parquet                                                         |
+----------------------+------------------------------------------------------------------------+
| pass@1               | 0.25833333333333336                                                    |
+----------------------+------------------------------------------------------------------------+
| pass@16              | 0.5333333333333333                                                     |
+----------------------+------------------------------------------------------------------------+
| cons@16              | 0.3567063492063492                                                     |
+----------------------+------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                    |
+----------------------+------------------------------------------------------------------------+
| mean_response_tokens | 21601.058333333334                                                     |
+----------------------+------------------------------------------------------------------------+
| run_hours            | 0.22722022387716506                                                    |
+----------------------+------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=968271)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=968271)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 11:15:27,706	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1003445)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1003445)[0m No module named 'vllm._version'
[36m(pid=1003445)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1004434)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1004434)[0m No module named 'vllm._version'
[36m(pid=1004434)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1004436)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1004436)[0m No module named 'vllm._version'
[36m(pid=1004436)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1003445)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1004433)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1004433)[0m   warnings.warn(
[36m(pid=1004431)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1004431)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1004431)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 116, in _wrapper
[36m(ActorRolloutRefWorker pid=1004434)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1004434)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
[36m(ActorRolloutRefWorker pid=1004434)[0m     output: SamplerOutput = self.model.sample(
[36m(ActorRolloutRefWorker pid=1004434)[0m                             ^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
[36m(ActorRolloutRefWorker pid=1004434)[0m     next_tokens = self.sampler(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=1004434)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[36m(ActorRolloutRefWorker pid=1004434)[0m     return self._call_impl(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1004434)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[36m(ActorRolloutRefWorker pid=1004434)[0m     return forward_call(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1004434)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
[36m(ActorRolloutRefWorker pid=1004434)[0m     self._init_sampling_tensors(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
[36m(ActorRolloutRefWorker pid=1004434)[0m     do_min_p) = SamplingTensors.from_sampling_metadata(
[36m(ActorRolloutRefWorker pid=1004434)[0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
[36m(ActorRolloutRefWorker pid=1004434)[0m     sampling_tensors = SamplingTensors.from_lists(
[36m(ActorRolloutRefWorker pid=1004434)[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
[36m(ActorRolloutRefWorker pid=1004434)[0m     temperatures_t = torch.tensor(
[36m(ActorRolloutRefWorker pid=1004434)[0m                      ^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m RuntimeError: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1004434)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1004434)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1004434)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1004434)[0m 
[36m(ActorRolloutRefWorker pid=1004434)[0m 
[36m(ActorRolloutRefWorker pid=1004434)[0m The above exception was the direct cause of the following exception:
[36m(ActorRolloutRefWorker pid=1004434)[0m 
[36m(ActorRolloutRefWorker pid=1004434)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
[36m(ActorRolloutRefWorker pid=1004434)[0m     output = self.inference_engine.generate(
[36m(ActorRolloutRefWorker pid=1004434)[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
[36m(ActorRolloutRefWorker pid=1004434)[0m     return fn(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1004434)[0m            ^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
[36m(ActorRolloutRefWorker pid=1004434)[0m     outputs = self._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=1004434)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
[36m(ActorRolloutRefWorker pid=1004434)[0m     outputs = super()._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=1004434)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
[36m(ActorRolloutRefWorker pid=1004434)[0m     step_outputs = self.llm_engine.step()
[36m(ActorRolloutRefWorker pid=1004434)[0m                    ^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
[36m(ActorRolloutRefWorker pid=1004434)[0m     outputs = self.model_executor.execute_model(
[36m(ActorRolloutRefWorker pid=1004434)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
[36m(ActorRolloutRefWorker pid=1004434)[0m     all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
[36m(ActorRolloutRefWorker pid=1004434)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
[36m(ActorRolloutRefWorker pid=1004434)[0m     return self.model_runner.execute_model(
[36m(ActorRolloutRefWorker pid=1004434)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(ActorRolloutRefWorker pid=1004434)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1004434)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1004434)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
[36m(ActorRolloutRefWorker pid=1004434)[0m     raise type(err)(f"Error in model execution: "
[36m(ActorRolloutRefWorker pid=1004434)[0m RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1004434)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1004434)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1004434)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1004434)[0m 
[36m(ActorRolloutRefWorker pid=1004437)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m   warnings.warn([32m [repeated 7x across cluster][0m
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1003445)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1003445)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1003445)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1003445)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1003445)[0m   ],
[36m(ActorRolloutRefWorker pid=1003445)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1003445)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1003445)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1003445)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1003445)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1003445)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1003445)[0m }
[36m(ActorRolloutRefWorker pid=1003445)[0m 
[36m(ActorRolloutRefWorker pid=1003445)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1003445)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1003445)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14cfca543ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1003445)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1004436)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x143ba57dfec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:15:57 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1004433)[0m WARNING 03-22 11:15:57 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1004433)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1004437)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1003445)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1003445)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:15:58 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m WARNING 03-22 11:15:58 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1004435)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1003445)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 500
wg.worker_names: ['zxZn5AActorRolloutRefWorker_0:0', 'zxZn5AActorRolloutRefWorker_0:1', 'zxZn5AActorRolloutRefWorker_0:2', 'zxZn5AActorRolloutRefWorker_0:3', 'zxZn5AActorRolloutRefWorker_0:4', 'zxZn5AActorRolloutRefWorker_0:5', 'zxZn5AActorRolloutRefWorker_0:6', 'zxZn5AActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:16:10 metrics.py:345] Avg prompt throughput: 1231.2 tokens/s, Avg generation throughput: 680.2 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1004437)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:16:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3081.3 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004431)[0m INFO 03-22 11:16:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3045.9 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:16:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3135.0 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:16:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3064.8 tokens/s, Running: 61 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:16:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2904.9 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:16:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2689.7 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:16:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2236.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:16:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2092.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004435)[0m INFO 03-22 11:17:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1627.8 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:17:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1771.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:17:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1588.7 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:17:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1564.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:17:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1360.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m INFO 03-22 11:17:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1222.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:17:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1029.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:17:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1030.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:17:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1041.9 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:17:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 912.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:18:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 887.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004435)[0m INFO 03-22 11:18:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 703.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m INFO 03-22 11:18:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1001.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:18:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 909.1 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:18:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 881.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:18:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 777.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:18:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 828.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:18:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 826.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004435)[0m INFO 03-22 11:18:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 582.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:18:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 663.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:18:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 603.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:19:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 762.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:19:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 753.2 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:19:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 708.4 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004435)[0m INFO 03-22 11:19:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 520.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m INFO 03-22 11:19:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 471.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:19:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 539.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:19:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 487.0 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:19:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 582.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:19:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 645.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m INFO 03-22 11:19:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 470.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:20:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 371.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:20:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 460.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:20:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:20:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 623.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:20:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 585.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m INFO 03-22 11:20:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 469.4 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:20:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 209.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:20:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 209.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:20:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 394.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:20:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 528.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m INFO 03-22 11:21:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1003445)[0m INFO 03-22 11:21:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 209.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:21:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 393.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004433)[0m INFO 03-22 11:21:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 462.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1004434)[0m INFO 03-22 11:21:22 model_runner_base.py:120] Writing input of failed execution to /tmp/err_execute_model_input_20250322-112122.pkl...
[36m(ActorRolloutRefWorker pid=1004434)[0m WARNING 03-22 11:21:22 model_runner_base.py:143] Failed to pickle inputs of failed execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1004434)[0m WARNING 03-22 11:21:22 model_runner_base.py:143] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1004434)[0m WARNING 03-22 11:21:22 model_runner_base.py:143] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1004434)[0m WARNING 03-22 11:21:22 model_runner_base.py:143] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1004434)[0m WARNING 03-22 11:21:22 model_runner_base.py:143] 
[36m(ActorRolloutRefWorker pid=1004434)[0m Restarting vLLM due to error:  Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1004434)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1004434)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1004434)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1004434)[0m 
[36m(ActorRolloutRefWorker pid=1004434)[0m Retrying...
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=1', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.95', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 147, in main
    output = wg.generate_sequences(data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1004434, ip=20.8.4.28, actor_id=fa7b6e142935859096e2070501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14de6956a9d0>)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
    output: SamplerOutput = self.model.sample(
                            ^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
    next_tokens = self.sampler(logits, sampling_metadata)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
    self._init_sampling_tensors(logits, sampling_metadata)
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
    do_min_p) = SamplingTensors.from_sampling_metadata(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
    sampling_tensors = SamplingTensors.from_lists(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
    temperatures_t = torch.tensor(
                     ^^^^^^^^^^^^^
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1004434, ip=20.8.4.28, actor_id=fa7b6e142935859096e2070501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14de6956a9d0>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
    output = self.inference_engine.generate(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
    outputs = self._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
    outputs = super()._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
    step_outputs = self.llm_engine.step()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
    outputs = self.model_executor.execute_model(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
    all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
    return self.model_runner.execute_model(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
    raise type(err)(f"Error in model execution: "
RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1004434, ip=20.8.4.28, actor_id=fa7b6e142935859096e2070501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14de6956a9d0>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 447, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 276, in generate_sequences
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1004434, ip=20.8.4.28, actor_id=fa7b6e142935859096e2070501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14de6956a9d0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 439, in generate_sequences
    with self.rollout_sharding_manager:
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/sharding_manager/fsdp_vllm.py", line 105, in __exit__
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(ActorRolloutRefWorker pid=1004437)[0m INFO 03-22 11:21:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 393.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 11:21:40,494	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1022290)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1022290)[0m No module named 'vllm._version'
[36m(pid=1022290)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1023123)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1023123)[0m No module named 'vllm._version'
[36m(pid=1023123)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1023121)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1023121)[0m No module named 'vllm._version'
[36m(pid=1023121)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1023121)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1023124)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1023124)[0m   warnings.warn(
[36m(pid=1023124)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1023124)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1023124)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1022290)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1022290)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1022290)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1022290)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1022290)[0m   ],
[36m(ActorRolloutRefWorker pid=1022290)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1022290)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1022290)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1022290)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1022290)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1022290)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1022290)[0m }
[36m(ActorRolloutRefWorker pid=1022290)[0m 
[36m(ActorRolloutRefWorker pid=1022290)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1022290)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1022290)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x150ba6807ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1022290)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:21:58 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1023124)[0m WARNING 03-22 11:21:58 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1023126)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14725a143ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1023121)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1023124)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1022290)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1022290)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:21:58 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m WARNING 03-22 11:21:58 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1023126)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1022290)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['BaOyNNActorRolloutRefWorker_0:0', 'BaOyNNActorRolloutRefWorker_0:1', 'BaOyNNActorRolloutRefWorker_0:2', 'BaOyNNActorRolloutRefWorker_0:3', 'BaOyNNActorRolloutRefWorker_0:4', 'BaOyNNActorRolloutRefWorker_0:5', 'BaOyNNActorRolloutRefWorker_0:6', 'BaOyNNActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:22:09 metrics.py:345] Avg prompt throughput: 1686.2 tokens/s, Avg generation throughput: 562.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1023127)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:22:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3023.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:22:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2963.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:22:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2964.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:22:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2946.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:22:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3009.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:22:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3000.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:22:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2985.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:22:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2765.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:23:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2897.8 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:23:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2889.0 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:23:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2921.3 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:23:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2898.9 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:23:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2807.2 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:23:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2737.3 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:23:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2720.2 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:23:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2694.5 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:23:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2607.4 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023123)[0m INFO 03-22 11:23:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2694.2 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:23:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2721.2 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:24:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2624.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:24:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2590.1 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:24:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2319.9 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:24:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2565.3 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:24:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2468.8 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:24:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2624.5 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:24:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2577.3 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:24:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2341.3 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:24:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2420.3 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:24:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2398.6 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:25:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2392.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:25:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2259.4 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:25:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2334.8 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:25:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2267.9 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:25:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2157.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:25:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2223.3 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:25:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2207.8 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:25:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2197.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:25:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2195.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:25:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2159.4 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:25:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2090.9 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:26:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2068.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023123)[0m INFO 03-22 11:26:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1852.0 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:26:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1814.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:26:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2040.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:26:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1744.3 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:26:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1882.3 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:26:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1999.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:26:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1974.0 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:26:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1846.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:26:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1835.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:26:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1810.4 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:27:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1792.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023123)[0m INFO 03-22 11:27:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1876.2 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023126)[0m INFO 03-22 11:27:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1784.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:27:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1717.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:27:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1683.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:27:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1591.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:27:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1577.5 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:27:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1743.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:27:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1714.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:27:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1507.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:27:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1530.2 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:28:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1631.2 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:28:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1484.2 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:28:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1432.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:28:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1392.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:28:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1361.1 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:28:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1458.6 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:28:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1360.6 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:28:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1348.0 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:28:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1320.1 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:28:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1330.4 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:28:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1321.1 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:29:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1379.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:29:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 956.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:29:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1230.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:29:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1202.7 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:29:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 962.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:29:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 956.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:29:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1204.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:29:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1188.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:29:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1215.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:29:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 917.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:30:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 858.9 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:30:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 961.1 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:30:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 956.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:30:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 756.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:30:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1127.9 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:30:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1056.3 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:30:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 654.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:30:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 806.7 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:30:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 685.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:30:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 662.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:30:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 556.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:31:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 792.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023123)[0m INFO 03-22 11:31:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 850.8 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:31:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 399.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:31:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 597.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:31:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 401.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:31:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 392.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:31:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 442.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023122)[0m INFO 03-22 11:31:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 398.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:31:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 670.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:31:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 518.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023125)[0m INFO 03-22 11:31:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 283.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023124)[0m INFO 03-22 11:32:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 425.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1022290)[0m INFO 03-22 11:32:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 391.3 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:32:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 578.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023121)[0m INFO 03-22 11:32:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 577.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023123)[0m INFO 03-22 11:32:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 583.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023127)[0m INFO 03-22 11:32:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 373.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[2025-03-22 11:32:40,167][pylatexenc.latexwalker][INFO] - Ignoring parse error (tolerant parsing mode): Unexpected mismatching closing brace: '}' @(1,29)
Token indices sequence length is longer than the specified maximum sequence length for this model (17597 > 16384). Running this sequence through the model will result in indexing errors
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
[2025-03-22 11:32:43,849][pylatexenc.latexwalker][INFO] - Ignoring parse error (tolerant parsing mode): Unexpected mismatching closing brace: '}' @(1,29)
+----------------------+----------------------------------------------------------------------+
| Metric               | Value                                                                |
+======================+======================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k |
+----------------------+----------------------------------------------------------------------+
| dataset              | aime.parquet                                                         |
+----------------------+----------------------------------------------------------------------+
| pass@1               | 0.3125                                                               |
+----------------------+----------------------------------------------------------------------+
| pass@16              | 0.7                                                                  |
+----------------------+----------------------------------------------------------------------+
| cons@16              | 0.45                                                                 |
+----------------------+----------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                  |
+----------------------+----------------------------------------------------------------------+
| mean_response_tokens | 17624.252083333333                                                   |
+----------------------+----------------------------------------------------------------------+
| run_hours            | 0.18480542090204027                                                  |
+----------------------+----------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1023123)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1023123)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime25
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 11:32:59,374	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1051976)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1051976)[0m No module named 'vllm._version'
[36m(pid=1051976)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1052854)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1052854)[0m No module named 'vllm._version'
[36m(pid=1052854)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1052858)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1052858)[0m No module named 'vllm._version'
[36m(pid=1052858)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1052854)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1051976)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1051976)[0m   warnings.warn(
[36m(pid=1052856)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1052856)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1052856)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (19210 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1051976)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1051976)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1051976)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1051976)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1051976)[0m   ],
[36m(ActorRolloutRefWorker pid=1051976)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1051976)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1051976)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1051976)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1051976)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1051976)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1051976)[0m }
[36m(ActorRolloutRefWorker pid=1051976)[0m 
[36m(ActorRolloutRefWorker pid=1051976)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1051976)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1051976)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14b580407ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1051976)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:33:17 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1052853)[0m WARNING 03-22 11:33:17 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1052855)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1509f643bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1052852)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1052853)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1051976)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1051976)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1051976)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1051976)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1051976)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1052855)[0m INFO 03-22 11:33:17 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052855)[0m WARNING 03-22 11:33:17 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052855)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052855)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 30
wg.worker_names: ['5cWZv2ActorRolloutRefWorker_0:0', '5cWZv2ActorRolloutRefWorker_0:1', '5cWZv2ActorRolloutRefWorker_0:2', '5cWZv2ActorRolloutRefWorker_0:3', '5cWZv2ActorRolloutRefWorker_0:4', '5cWZv2ActorRolloutRefWorker_0:5', '5cWZv2ActorRolloutRefWorker_0:6', '5cWZv2ActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Find the sum of all integer bases $b>9$ for which $17_b$ is a '
              "divisor of $97_b.$ Let's think step by step and output the "
              'final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'In $\\triangle ABC$ points $D$ and $E$ lie on $\\overline{AB}$ '
              'so that $AD < AE < AB$, while points $F$ and $G$ lie on '
              '$\\overline{AC}$ so that $AF < AG < AC$. Suppose $AD = 4$, $DE '
              '= 16$, $EB = 8$, $AF = 13$, $FG = 52$, and $GC = 26$. Let $M$ '
              'be the reflection of $D$ through $F$, and let $N$ be the '
              'reflection of $G$ through $E$. The area of quadrilateral $DEGF$ '
              "is $288$. Find the area of heptagon $AFNBCEM$. Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'The $9$ members of a baseball team went to an ice-cream parlor '
              'after their game. Each player had a single scoop cone of '
              'chocolate, vanilla, or strawberry ice cream. At least one '
              'player chose each flavor, and the number of players who chose '
              'chocolate was greater than the number of players who chose '
              'vanilla, which was greater than the number of players who chose '
              'strawberry. Let $N$ be the number of different assignments of '
              'flavors to players that meet these conditions. Find the '
              "remainder when $N$ is divided by $1000.$ Let's think step by "
              'step and output the final answer within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 848]), content: tensor([[  369,   892,   400,    16,    22,   880],
        [   23,    23, 12947,  7379,   279,  3082],
        [ 7379,   279, 26313,   979,   400,    45],
        ...,
        [  279, 26313,   979,   400,    76, 38334],
        [   77,    59, 26888,    18,     3,   369],
        [ 2750,   315,   400,    87, 12947,  7379]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:33:28 metrics.py:345] Avg prompt throughput: 2297.1 tokens/s, Avg generation throughput: 654.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1052855)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:33:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2966.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:33:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2967.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:33:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2970.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:33:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2984.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:33:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2980.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:34:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2969.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:34:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2958.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:34:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2699.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:34:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2924.5 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:34:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2871.3 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052855)[0m INFO 03-22 11:34:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2769.8 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:34:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2724.2 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:34:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2715.8 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:34:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2626.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:34:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2619.6 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052858)[0m INFO 03-22 11:34:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2615.9 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:35:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2610.1 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:35:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2597.6 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:35:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2585.0 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:35:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2487.2 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:35:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2468.1 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:35:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2430.4 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:35:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2440.3 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:35:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2387.0 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:35:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2423.0 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:35:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2420.1 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:36:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2404.1 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052858)[0m INFO 03-22 11:36:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2423.4 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:36:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2307.1 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:36:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2285.6 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:36:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2221.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:36:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2240.5 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:36:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2227.7 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:36:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2260.7 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:36:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2240.1 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:36:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2116.5 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:36:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2146.0 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:37:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2121.4 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:37:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2097.1 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:37:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2018.3 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:37:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2001.0 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:37:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2049.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:37:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1949.6 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:37:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1921.4 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052858)[0m INFO 03-22 11:37:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1948.3 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:37:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1917.0 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:37:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1894.5 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:37:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1882.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:38:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1807.3 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:38:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1795.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:38:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1763.2 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:38:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1741.1 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:38:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1744.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:38:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1725.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052858)[0m INFO 03-22 11:38:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1728.7 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:38:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1706.4 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:38:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1691.3 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:38:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1684.5 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:39:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1411.9 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:39:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1638.7 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:39:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1615.7 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:39:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1541.6 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:39:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1525.2 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:39:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1514.9 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:39:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1490.3 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:39:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1443.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:39:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1124.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:39:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1400.6 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:39:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1379.6 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:40:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1312.8 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:40:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1300.5 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:40:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1312.5 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:40:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1031.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:40:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1168.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:40:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1048.9 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:40:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1012.6 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:40:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1017.0 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:40:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 971.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:40:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 650.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:41:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 898.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:41:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 868.8 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:41:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 911.9 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052858)[0m INFO 03-22 11:41:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 600.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:41:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 750.7 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:41:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1145.3 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:41:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 466.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:41:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 697.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:41:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 691.4 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:41:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 689.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052858)[0m INFO 03-22 11:42:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 266.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:42:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 575.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:42:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 862.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:42:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 797.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:42:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 396.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052856)[0m INFO 03-22 11:42:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 396.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:42:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 519.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:42:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 519.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:42:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 395.3 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:42:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 394.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:42:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 335.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052857)[0m INFO 03-22 11:43:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 335.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:43:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 452.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052853)[0m INFO 03-22 11:43:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 338.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:43:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1051976)[0m INFO 03-22 11:43:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:43:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 332.0 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:43:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 332.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:43:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 313.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1052852)[0m INFO 03-22 11:43:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 264.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+----------------------------------------------------------------------+
| Metric               | Value                                                                |
+======================+======================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k |
+----------------------+----------------------------------------------------------------------+
| dataset              | aime25.parquet                                                       |
+----------------------+----------------------------------------------------------------------+
| pass@1               | 0.27708333333333335                                                  |
+----------------------+----------------------------------------------------------------------+
| pass@16              | 0.5333333333333333                                                   |
+----------------------+----------------------------------------------------------------------+
| cons@16              | 0.38333333333333336                                                  |
+----------------------+----------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                  |
+----------------------+----------------------------------------------------------------------+
| mean_response_tokens | 16353.13125                                                          |
+----------------------+----------------------------------------------------------------------+
| run_hours            | 0.18425396276844871                                                  |
+----------------------+----------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1052852)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1052852)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-fuserl-sft-v3-bs16-ep5-lr3e-5-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-r1-bs16-ep5-lr3e-5-cutoff-16k DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 11:44:35,314	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1082306)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1082306)[0m No module named 'vllm._version'
[36m(pid=1082306)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1083263)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1083263)[0m No module named 'vllm._version'
[36m(pid=1083263)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1083259)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1083259)[0m No module named 'vllm._version'
[36m(pid=1083259)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1082306)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1083258)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1083258)[0m   warnings.warn(
[36m(pid=1083260)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1083260)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1083260)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083264)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 116, in _wrapper
[36m(ActorRolloutRefWorker pid=1083261)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1083261)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
[36m(ActorRolloutRefWorker pid=1083261)[0m     output: SamplerOutput = self.model.sample(
[36m(ActorRolloutRefWorker pid=1083261)[0m                             ^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
[36m(ActorRolloutRefWorker pid=1083261)[0m     next_tokens = self.sampler(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=1083261)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[36m(ActorRolloutRefWorker pid=1083261)[0m     return self._call_impl(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1083261)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[36m(ActorRolloutRefWorker pid=1083261)[0m     return forward_call(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1083261)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
[36m(ActorRolloutRefWorker pid=1083261)[0m     self._init_sampling_tensors(logits, sampling_metadata)
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
[36m(ActorRolloutRefWorker pid=1083261)[0m     do_min_p) = SamplingTensors.from_sampling_metadata(
[36m(ActorRolloutRefWorker pid=1083261)[0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
[36m(ActorRolloutRefWorker pid=1083261)[0m     sampling_tensors = SamplingTensors.from_lists(
[36m(ActorRolloutRefWorker pid=1083261)[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
[36m(ActorRolloutRefWorker pid=1083261)[0m     temperatures_t = torch.tensor(
[36m(ActorRolloutRefWorker pid=1083261)[0m                      ^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m RuntimeError: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1083261)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1083261)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1083261)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1083261)[0m 
[36m(ActorRolloutRefWorker pid=1083261)[0m 
[36m(ActorRolloutRefWorker pid=1083261)[0m The above exception was the direct cause of the following exception:
[36m(ActorRolloutRefWorker pid=1083261)[0m 
[36m(ActorRolloutRefWorker pid=1083261)[0m Traceback (most recent call last):
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
[36m(ActorRolloutRefWorker pid=1083261)[0m     output = self.inference_engine.generate(
[36m(ActorRolloutRefWorker pid=1083261)[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
[36m(ActorRolloutRefWorker pid=1083261)[0m     return fn(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1083261)[0m            ^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
[36m(ActorRolloutRefWorker pid=1083261)[0m     outputs = self._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=1083261)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
[36m(ActorRolloutRefWorker pid=1083261)[0m     outputs = super()._run_engine(use_tqdm=use_tqdm)
[36m(ActorRolloutRefWorker pid=1083261)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
[36m(ActorRolloutRefWorker pid=1083261)[0m     step_outputs = self.llm_engine.step()
[36m(ActorRolloutRefWorker pid=1083261)[0m                    ^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
[36m(ActorRolloutRefWorker pid=1083261)[0m     outputs = self.model_executor.execute_model(
[36m(ActorRolloutRefWorker pid=1083261)[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
[36m(ActorRolloutRefWorker pid=1083261)[0m     all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
[36m(ActorRolloutRefWorker pid=1083261)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
[36m(ActorRolloutRefWorker pid=1083261)[0m     return self.model_runner.execute_model(
[36m(ActorRolloutRefWorker pid=1083261)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(ActorRolloutRefWorker pid=1083261)[0m     return func(*args, **kwargs)
[36m(ActorRolloutRefWorker pid=1083261)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(ActorRolloutRefWorker pid=1083261)[0m   File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
[36m(ActorRolloutRefWorker pid=1083261)[0m     raise type(err)(f"Error in model execution: "
[36m(ActorRolloutRefWorker pid=1083261)[0m RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1083261)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1083261)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1083261)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1083261)[0m 
[36m(ActorRolloutRefWorker pid=1083260)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083260)[0m   warnings.warn([32m [repeated 7x across cluster][0m
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1082306)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1082306)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1082306)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1082306)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1082306)[0m   ],
[36m(ActorRolloutRefWorker pid=1082306)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1082306)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1082306)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1082306)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1082306)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1082306)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1082306)[0m }
[36m(ActorRolloutRefWorker pid=1082306)[0m 
[36m(ActorRolloutRefWorker pid=1082306)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1082306)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1082306)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1477bc20bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1082306)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=1083263)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1428a8ce3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1083263)[0m INFO 03-22 11:45:03 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1083263)[0m WARNING 03-22 11:45:03 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1083260)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1083258)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1082306)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=1082306)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:45:04 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m WARNING 03-22 11:45:04 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1083260)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=1082306)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
len(dataset): 500
wg.worker_names: ['JoQYYLActorRolloutRefWorker_0:0', 'JoQYYLActorRolloutRefWorker_0:1', 'JoQYYLActorRolloutRefWorker_0:2', 'JoQYYLActorRolloutRefWorker_0:3', 'JoQYYLActorRolloutRefWorker_0:4', 'JoQYYLActorRolloutRefWorker_0:5', 'JoQYYLActorRolloutRefWorker_0:6', 'JoQYYLActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:45:15 metrics.py:345] Avg prompt throughput: 1098.8 tokens/s, Avg generation throughput: 679.2 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1083260)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:45:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3134.4 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:45:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3129.9 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083264)[0m INFO 03-22 11:45:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3137.3 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:45:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3148.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:45:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3112.9 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083260)[0m INFO 03-22 11:45:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2963.6 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:45:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2549.1 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:46:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2363.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083264)[0m INFO 03-22 11:46:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2454.7 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:46:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2081.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:46:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2023.4 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083260)[0m INFO 03-22 11:46:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2215.9 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:46:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1955.8 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:46:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1883.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:46:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1368.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:46:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1256.6 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083264)[0m INFO 03-22 11:46:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1469.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:46:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1148.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083259)[0m INFO 03-22 11:47:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1469.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:47:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1334.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:47:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1075.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:47:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1025.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:47:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1018.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:47:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 854.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083259)[0m INFO 03-22 11:47:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1035.2 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:47:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1001.6 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:47:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1002.5 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:47:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 838.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:48:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 837.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:48:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 792.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:48:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 793.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083259)[0m INFO 03-22 11:48:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 850.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083259)[0m INFO 03-22 11:48:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 792.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:48:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 758.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:48:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 758.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:48:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 773.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:48:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 582.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:48:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 665.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:48:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 635.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083259)[0m INFO 03-22 11:49:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 513.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:49:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 563.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:49:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 563.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:49:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 590.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:49:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 583.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:49:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:49:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 477.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:49:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 476.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083259)[0m INFO 03-22 11:49:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 452.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:49:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 395.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083258)[0m INFO 03-22 11:50:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 459.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:50:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 403.5 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:50:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 346.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1082306)[0m INFO 03-22 11:50:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 345.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083260)[0m INFO 03-22 11:50:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 596.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083262)[0m INFO 03-22 11:50:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 395.1 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:50:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 350.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1083261)[0m INFO 03-22 11:50:32 model_runner_base.py:120] Writing input of failed execution to /tmp/err_execute_model_input_20250322-115032.pkl...
[36m(ActorRolloutRefWorker pid=1083261)[0m WARNING 03-22 11:50:32 model_runner_base.py:143] Failed to pickle inputs of failed execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1083261)[0m WARNING 03-22 11:50:32 model_runner_base.py:143] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1083261)[0m WARNING 03-22 11:50:32 model_runner_base.py:143] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1083261)[0m WARNING 03-22 11:50:32 model_runner_base.py:143] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1083261)[0m WARNING 03-22 11:50:32 model_runner_base.py:143] 
[36m(ActorRolloutRefWorker pid=1083261)[0m Restarting vLLM due to error:  Error in model execution: CUDA error: an illegal memory access was encountered
[36m(ActorRolloutRefWorker pid=1083261)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(ActorRolloutRefWorker pid=1083261)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(ActorRolloutRefWorker pid=1083261)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(ActorRolloutRefWorker pid=1083261)[0m 
[36m(ActorRolloutRefWorker pid=1083261)[0m Retrying...
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=1', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.95', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 147, in main
    output = wg.generate_sequences(data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1083261, ip=20.8.4.28, actor_id=b1836e007a3263ad0b77111a01000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x151daf9b4cd0>)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner.py", line 1708, in execute_model
    output: SamplerOutput = self.model.sample(
                            ^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 433, in sample
    next_tokens = self.sampler(logits, sampling_metadata)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 231, in forward
    self._init_sampling_tensors(logits, sampling_metadata)
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py", line 195, in _init_sampling_tensors
    do_min_p) = SamplingTensors.from_sampling_metadata(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 471, in from_sampling_metadata
    sampling_tensors = SamplingTensors.from_lists(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/model_executor/sampling_metadata.py", line 529, in from_lists
    temperatures_t = torch.tensor(
                     ^^^^^^^^^^^^^
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


The above exception was the direct cause of the following exception:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1083261, ip=20.8.4.28, actor_id=b1836e007a3263ad0b77111a01000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x151daf9b4cd0>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 207, in generate_sequences
    output = self.inference_engine.generate(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/utils.py", line 1063, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 353, in generate
    outputs = self._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 166, in _run_engine
    outputs = super()._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 879, in _run_engine
    step_outputs = self.llm_engine.step()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 1386, in step
    outputs = self.model_executor.execute_model(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 163, in execute_model
    all_outputs = self.worker.execute_model(execute_model_req=execute_model_req)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 267, in execute_model
    return self.model_runner.execute_model(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/worker/model_runner_base.py", line 146, in _wrapper
    raise type(err)(f"Error in model execution: "
RuntimeError: Error in model execution: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1083261, ip=20.8.4.28, actor_id=b1836e007a3263ad0b77111a01000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x151daf9b4cd0>)
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 447, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 276, in generate_sequences
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::ActorRolloutRefWorker.generate_sequences()[39m (pid=1083261, ip=20.8.4.28, actor_id=b1836e007a3263ad0b77111a01000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x151daf9b4cd0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 439, in generate_sequences
    with self.rollout_sharding_manager:
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/sharding_manager/fsdp_vllm.py", line 105, in __exit__
    torch.cuda.empty_cache()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/cuda/memory.py", line 170, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 11:50:49,818	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1101085)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1101085)[0m No module named 'vllm._version'
[36m(pid=1101085)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1102027)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1102027)[0m No module named 'vllm._version'
[36m(pid=1102027)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1102021)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1102021)[0m No module named 'vllm._version'
[36m(pid=1102021)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1102027)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=1102026)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=1102026)[0m   warnings.warn(
[36m(pid=1102026)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1102026)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1102026)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (32618 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1101085)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1101085)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1101085)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1101085)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1101085)[0m   ],
[36m(ActorRolloutRefWorker pid=1101085)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1101085)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1101085)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1101085)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1101085)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1101085)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1101085)[0m }
[36m(ActorRolloutRefWorker pid=1101085)[0m 
[36m(ActorRolloutRefWorker pid=1101085)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1101085)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1101085)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14edcec27ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1101085)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:51:08 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1102021)[0m WARNING 03-22 11:51:08 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1102022)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14f7cf00fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1102021)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1102021)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1101085)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=1101085)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:51:08 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m WARNING 03-22 11:51:08 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=1102022)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=1101085)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['mZUpl9ActorRolloutRefWorker_0:0', 'mZUpl9ActorRolloutRefWorker_0:1', 'mZUpl9ActorRolloutRefWorker_0:2', 'mZUpl9ActorRolloutRefWorker_0:3', 'mZUpl9ActorRolloutRefWorker_0:4', 'mZUpl9ActorRolloutRefWorker_0:5', 'mZUpl9ActorRolloutRefWorker_0:6', 'mZUpl9ActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:51:19 metrics.py:345] Avg prompt throughput: 1690.7 tokens/s, Avg generation throughput: 443.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=1102023)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:51:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3050.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:51:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3049.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:51:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2984.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:51:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2983.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:51:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3015.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:51:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3010.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:51:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2960.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:52:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2962.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:52:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2704.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:52:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2971.1 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:52:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3015.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:52:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2955.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102024)[0m INFO 03-22 11:52:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2882.7 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:52:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2950.8 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:52:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2926.3 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:52:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2880.3 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:52:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2920.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:52:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2880.9 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:53:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2882.7 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:53:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2808.4 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:53:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2805.9 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:53:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2510.5 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:53:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2739.2 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:53:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2738.8 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:53:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2735.1 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:53:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2782.6 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:53:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2696.0 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:53:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2719.8 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:54:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2592.0 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:54:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2563.2 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:54:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2639.9 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:54:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2541.6 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:54:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2489.4 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:54:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2477.7 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:54:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2476.8 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:54:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2441.7 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:54:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2329.7 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:54:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2250.4 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:54:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2249.3 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:55:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2216.5 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:55:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2208.9 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:55:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1900.0 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:55:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2185.5 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:55:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2161.3 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:55:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2073.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:55:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2034.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:55:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2023.1 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:55:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1986.0 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:55:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1984.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:55:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1900.8 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:56:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1873.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:56:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1957.1 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102024)[0m INFO 03-22 11:56:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1869.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:56:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1857.8 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:56:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1857.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:56:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1837.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:56:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1748.5 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:56:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1725.3 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:56:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1733.6 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 11:56:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1693.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:56:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1761.8 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:57:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1740.2 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102024)[0m INFO 03-22 11:57:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1664.1 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:57:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1667.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:57:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1657.7 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:57:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1665.7 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:57:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1609.1 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:57:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1586.5 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 11:57:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1543.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:57:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1620.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102024)[0m INFO 03-22 11:57:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1551.5 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:57:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1529.4 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:58:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1581.5 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:58:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1284.6 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:58:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1473.7 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:58:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1449.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:58:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1136.3 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 11:58:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1125.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 11:58:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1401.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:58:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1516.2 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 11:58:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1506.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102024)[0m INFO 03-22 11:58:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1370.3 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102024)[0m INFO 03-22 11:58:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1363.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:59:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1356.0 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:59:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1318.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 11:59:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1305.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:59:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1339.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 11:59:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1331.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 11:59:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1361.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102027)[0m INFO 03-22 11:59:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1257.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:59:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1255.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 11:59:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1239.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 11:59:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1249.3 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 11:59:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1241.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:00:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1336.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 12:00:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1142.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:00:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1224.1 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 26.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:00:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1217.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 12:00:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1261.1 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 12:00:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1252.7 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 12:00:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1119.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 12:00:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1097.1 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 12:00:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1168.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:00:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1244.6 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 12:00:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1065.1 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:01:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1163.3 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:01:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1156.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 12:01:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1178.2 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 12:01:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1171.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 12:01:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1022.1 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 12:01:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1017.2 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 12:01:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1098.5 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:01:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1170.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:01:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1166.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 31.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 12:01:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 991.5 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 12:01:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 984.6 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:02:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1082.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 29.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 12:02:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1096.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1101085)[0m INFO 03-22 12:02:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 949.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 12:02:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1010.6 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:02:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1112.3 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 32.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 12:02:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 935.0 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m INFO 03-22 12:02:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 930.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:02:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1019.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 28.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:02:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1003.6 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.7%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 12:02:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1009.5 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 27.1%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102026)[0m INFO 03-22 12:03:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1001.4 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 24.9%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102022)[0m INFO 03-22 12:03:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 952.6 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.1%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:03:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1057.4 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.7%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:03:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1044.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 30.9%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102021)[0m INFO 03-22 12:03:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 828.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102025)[0m INFO 03-22 12:03:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1008.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 25.2%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-----------------------------------------------------------------------+
| Metric               | Value                                                                 |
+======================+=======================================================================+
| model_path           | DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k |
+----------------------+-----------------------------------------------------------------------+
| dataset              | aime.parquet                                                          |
+----------------------+-----------------------------------------------------------------------+
| pass@1               | 0.33958333333333335                                                   |
+----------------------+-----------------------------------------------------------------------+
| pass@16              | 0.7                                                                   |
+----------------------+-----------------------------------------------------------------------+
| cons@16              | 0.5880952380952381                                                    |
+----------------------+-----------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                   |
+----------------------+-----------------------------------------------------------------------+
| mean_response_tokens | 21554.783333333333                                                    |
+----------------------+-----------------------------------------------------------------------+
| run_hours            | 0.21605548487769236                                                   |
+----------------------+-----------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=1102023)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1102023)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime25
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-22 12:04:01,586	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=1134918)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1134918)[0m No module named 'vllm._version'
[36m(pid=1134918)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1135861)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1135861)[0m No module named 'vllm._version'
[36m(pid=1135861)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=1135866)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=1135866)[0m No module named 'vllm._version'
[36m(pid=1135866)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=1135861)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=1134918)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=1134918)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k",
[36m(ActorRolloutRefWorker pid=1134918)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=1134918)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=1134918)[0m   ],
[36m(ActorRolloutRefWorker pid=1134918)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=1134918)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=1134918)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=1134918)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=1134918)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=1134918)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=1134918)[0m }
[36m(ActorRolloutRefWorker pid=1134918)[0m 
[36m(ActorRolloutRefWorker pid=1134918)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1134918)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=1134918)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x148dbcfe3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=1134918)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=1135864)[0m INFO 03-22 12:04:19 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=1135864)[0m WARNING 03-22 12:04:19 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=1135865)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14a9a39e3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=1135864)[0m local rank 0
[36m(ActorRolloutRefWorker pid=1135861)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=1135864)[0m 
[36m(ActorRolloutRefWorker pid=1135864)[0m an27:1135864:1137115 [0] misc/socket.cc:30 NCCL WARN socketProgressOpt: Call to recv from 99.72.4.28<32011> failed : Connection reset by peer
[36m(ActorRolloutRefWorker pid=1134918)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime25.parquet', 'data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k/aime25/aime25_n_16_temp_0.6_topp_0.95_maxlen_32768.json', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-s1k-math-qwq-bs16-ep5-lr3e-5-cutoff-16k', 'rollout.temperature=0.6', 'rollout.response_length=32768', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.95', 'rollout.tensor_model_parallel_size=1', '+data.skip_format_reward=True']
Traceback (most recent call last):
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/trainer/main_generation.py", line 81, in main
    wg.init_model()
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(DistBackendError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=1135864, ip=20.8.4.28, actor_id=f022f1b660ef31b3853ab9c801000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x14dc68779450>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 358, in init_model
    self.rollout, self.rollout_sharding_manager = self._build_rollout()
                                                  ^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/fsdp_workers.py", line 293, in _build_rollout
    rollout = vLLMRollout(actor_module=self.actor_module_fsdp,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 98, in __init__
    self.inference_engine = LLM(actor_module,
                            ^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 147, in __init__
    self.llm_engine = LLMEngine.from_engine_args(model, tokenizer, engine_args)  # TODO: check usagecontext
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 393, in from_engine_args
    engine = cls(
             ^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 227, in __init__
    self._initialize_kv_caches()
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 484, in _initialize_kv_caches
    self.model_executor.determine_num_available_blocks())
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 125, in determine_num_available_blocks
    num_blocks = self.worker.determine_num_available_blocks()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 223, in determine_num_available_blocks
    torch.distributed.all_reduce(num_gpu_blocks,
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2288, in all_reduce
    work = group.allreduce([tensor], opts)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:275, remote process exited or there was a network error, NCCL version 2.20.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgressOpt: Call to recv from 99.72.4.28<32011> failed : Connection reset by peer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(pid=1135864)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=1135864)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=1135864)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=1135867)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1135866)[0m INFO 03-22 12:04:19 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1135866)[0m WARNING 03-22 12:04:19 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1135866)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=1135866)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
