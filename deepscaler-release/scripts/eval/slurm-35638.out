+ export VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ VLLM_ATTENTION_BACKEND=FLASH_ATTN
+ export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+ MODEL_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k
+ OUTPUT_ROOT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs
+ GPU_NUM=8
+ TP=1
+ TEMP=0.6
+ TOP_P=0.95
+ MAX_LEN=32768
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 11:56:15,120	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2469109)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2469109)[0m No module named 'vllm._version'
[36m(pid=2469109)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2469481)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2469481)[0m No module named 'vllm._version'
[36m(pid=2469481)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2469480)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2469480)[0m No module named 'vllm._version'
[36m(pid=2469480)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2469109)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=2469478)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=2469478)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2469478)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2469109)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=2469477)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (20753 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2469109)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2469109)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30",
[36m(ActorRolloutRefWorker pid=2469109)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2469109)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2469109)[0m   ],
[36m(ActorRolloutRefWorker pid=2469109)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2469109)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2469109)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2469109)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2469109)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2469109)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2469109)[0m }
[36m(ActorRolloutRefWorker pid=2469109)[0m 
[36m(ActorRolloutRefWorker pid=2469109)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2469109)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2469109)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x143d09a6fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2469109)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=2469480)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x147c0d1d3ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:57:35 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2469109)[0m WARNING 03-21 11:57:35 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2469109)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2469476)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 11:57:35 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m WARNING 03-21 11:57:35 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=2469109)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=2469476)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2469477)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=2469109)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
len(dataset): 500
wg.worker_names: ['Oiatf6ActorRolloutRefWorker_0:0', 'Oiatf6ActorRolloutRefWorker_0:1', 'Oiatf6ActorRolloutRefWorker_0:2', 'Oiatf6ActorRolloutRefWorker_0:3', 'Oiatf6ActorRolloutRefWorker_0:4', 'Oiatf6ActorRolloutRefWorker_0:5', 'Oiatf6ActorRolloutRefWorker_0:6', 'Oiatf6ActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:58:01 metrics.py:345] Avg prompt throughput: 1146.3 tokens/s, Avg generation throughput: 12.3 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2469109)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:58:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3083.9 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.[32m [repeated 15x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:58:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3134.5 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:58:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3116.8 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:58:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2746.0 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:58:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2559.0 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:58:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2402.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:58:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2132.2 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:58:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1984.7 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 11:59:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1771.3 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:59:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1702.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:59:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1657.6 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469477)[0m INFO 03-21 11:59:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1517.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:59:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1165.2 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469475)[0m INFO 03-21 11:59:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1119.3 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 11:59:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 932.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 11:59:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1391.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:59:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1017.9 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 11:59:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 962.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469475)[0m INFO 03-21 12:00:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1015.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:00:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1027.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:00:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 978.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:00:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 690.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:00:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 630.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:00:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 713.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:00:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 725.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:00:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 596.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:00:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 584.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:00:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 542.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:01:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 469.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:01:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 470.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:01:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 349.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:01:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 469.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:01:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:01:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 343.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:01:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:01:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:01:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 273.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:02:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 529.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:02:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:02:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 322.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:02:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 273.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:02:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 465.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:02:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 465.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:02:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 293.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:02:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 204.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:02:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 204.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:02:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 238.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:03:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 308.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:03:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 273.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:03:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 202.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:03:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 201.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:03:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:03:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:03:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 208.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:03:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:03:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:03:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:04:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:04:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:04:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 273.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:04:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:04:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 178.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:04:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 140.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:04:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:04:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:04:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469475)[0m INFO 03-21 12:04:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 179.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:05:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 140.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:05:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 139.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:05:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:05:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469475)[0m INFO 03-21 12:05:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469475)[0m INFO 03-21 12:05:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:05:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 140.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469476)[0m INFO 03-21 12:05:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 139.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:05:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469109)[0m INFO 03-21 12:05:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469475)[0m INFO 03-21 12:05:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469475)[0m INFO 03-21 12:06:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469480)[0m INFO 03-21 12:06:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469479)[0m INFO 03-21 12:06:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469481)[0m INFO 03-21 12:06:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469478)[0m INFO 03-21 12:06:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 268.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469477)[0m INFO 03-21 12:06:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                          |
+======================+================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                                                                                                                                                                   |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.846                                                                                                                                                                                                                                          |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@1               | 0.846                                                                                                                                                                                                                                          |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5731.896                                                                                                                                                                                                                                       |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.17856889327367145                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2469477)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2469477)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 12:07:03,012	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2497074)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2497074)[0m No module named 'vllm._version'
[36m(pid=2497074)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2498021)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2498021)[0m No module named 'vllm._version'
[36m(pid=2498021)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2498024)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2498024)[0m No module named 'vllm._version'
[36m(pid=2498024)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2498021)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=2498021)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2498021)[0m   warnings.warn(
[36m(pid=2498026)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=2498026)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2498026)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (22040 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2497074)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2497074)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30",
[36m(ActorRolloutRefWorker pid=2497074)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2497074)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2497074)[0m   ],
[36m(ActorRolloutRefWorker pid=2497074)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2497074)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2497074)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2497074)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2497074)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2497074)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2497074)[0m }
[36m(ActorRolloutRefWorker pid=2497074)[0m 
[36m(ActorRolloutRefWorker pid=2497074)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2497074)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2497074)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14cdf7ac7ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2497074)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=2498026)[0m INFO 03-21 12:07:21 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2498026)[0m WARNING 03-21 12:07:21 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2498021)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14b9e53cfec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=2498019)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2498025)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2497074)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=2497074)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:07:21 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m WARNING 03-21 12:07:21 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2498022)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=2497074)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['rrgniKActorRolloutRefWorker_0:0', 'rrgniKActorRolloutRefWorker_0:1', 'rrgniKActorRolloutRefWorker_0:2', 'rrgniKActorRolloutRefWorker_0:3', 'rrgniKActorRolloutRefWorker_0:4', 'rrgniKActorRolloutRefWorker_0:5', 'rrgniKActorRolloutRefWorker_0:6', 'rrgniKActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:07:33 metrics.py:345] Avg prompt throughput: 1688.5 tokens/s, Avg generation throughput: 598.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2498022)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:07:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2954.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:07:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3043.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:07:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3041.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:07:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2985.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:07:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2982.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:08:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2966.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:08:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2918.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:08:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2692.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:08:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3019.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:08:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3014.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:08:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2886.9 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:08:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2903.2 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:08:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2889.4 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:08:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2835.1 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:08:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2657.3 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498026)[0m INFO 03-21 12:09:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2689.4 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:09:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2719.9 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:09:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2699.3 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:09:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2555.9 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:09:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2585.2 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:09:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2488.5 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:09:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2246.1 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:09:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2507.7 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:09:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2517.9 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:09:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2399.5 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:09:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2424.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:10:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2333.2 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:10:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2282.2 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:10:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2229.2 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:10:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2204.7 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:10:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2376.7 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:10:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2157.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:10:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2156.7 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498024)[0m INFO 03-21 12:10:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2183.2 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:10:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2212.7 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:10:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2008.3 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:10:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1985.3 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:11:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1967.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:11:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2098.7 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498026)[0m INFO 03-21 12:11:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1997.2 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:11:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1970.4 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498024)[0m INFO 03-21 12:11:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2012.1 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:11:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1801.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:11:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1704.1 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:11:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1822.8 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:11:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1751.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:11:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1499.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:11:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1675.4 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:12:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1860.3 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:12:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1746.3 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498025)[0m INFO 03-21 12:12:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1693.4 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498024)[0m INFO 03-21 12:12:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1729.1 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:12:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1724.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:12:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1521.8 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:12:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1314.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:12:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1685.0 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:12:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1658.5 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:12:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1506.2 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498025)[0m INFO 03-21 12:13:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1337.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498024)[0m INFO 03-21 12:13:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1491.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:13:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1571.7 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:13:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1418.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:13:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1029.5 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:13:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1028.3 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:13:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1462.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:13:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1253.1 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498025)[0m INFO 03-21 12:13:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 960.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498024)[0m INFO 03-21 12:13:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1304.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:13:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1282.8 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:14:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1280.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:14:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1173.9 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:14:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 979.1 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:14:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 979.6 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:14:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1320.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:14:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1168.3 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:14:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1140.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498025)[0m INFO 03-21 12:14:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 852.3 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:14:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1089.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:14:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1061.1 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:14:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1020.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:15:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 807.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:15:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1073.2 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498025)[0m INFO 03-21 12:15:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 667.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498024)[0m INFO 03-21 12:15:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 756.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:15:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1074.0 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:15:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 936.3 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:15:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 460.2 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:15:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 342.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:15:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 759.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:15:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 929.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498025)[0m INFO 03-21 12:16:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 624.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498024)[0m INFO 03-21 12:16:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 733.7 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:16:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 715.7 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:16:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 737.5 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:16:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 272.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2497074)[0m INFO 03-21 12:16:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 272.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:16:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 700.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:16:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 816.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498023)[0m INFO 03-21 12:16:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 815.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498025)[0m INFO 03-21 12:16:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 385.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:16:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 883.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:17:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 578.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m INFO 03-21 12:17:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 577.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:17:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 580.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498019)[0m INFO 03-21 12:17:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 579.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:17:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 776.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:17:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 776.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2498021)[0m INFO 03-21 12:17:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 772.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                          |
+======================+================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                                                                                                                                                                   |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.29375                                                                                                                                                                                                                                        |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@16              | 0.7                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@16              | 0.49777777777777776                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16525.54375                                                                                                                                                                                                                                    |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.181356909804874                                                                                                                                                                                                                              |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2498022)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2498022)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 12:18:10,476	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2526478)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2526478)[0m No module named 'vllm._version'
[36m(pid=2526478)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2527367)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2527367)[0m No module named 'vllm._version'
[36m(pid=2527367)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2527364)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2527364)[0m No module named 'vllm._version'
[36m(pid=2527364)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2526478)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=2527369)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=2527369)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2527369)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2527367)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=2527368)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (32562 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2526478)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2526478)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60",
[36m(ActorRolloutRefWorker pid=2526478)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2526478)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2526478)[0m   ],
[36m(ActorRolloutRefWorker pid=2526478)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2526478)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2526478)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2526478)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2526478)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2526478)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2526478)[0m }
[36m(ActorRolloutRefWorker pid=2526478)[0m 
[36m(ActorRolloutRefWorker pid=2526478)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2526478)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2526478)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14c926847ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2526478)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=2527368)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x145cd2f43ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:19:00 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2527364)[0m WARNING 03-21 12:19:00 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2527364)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2527367)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2526478)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=2526478)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:19:02 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m WARNING 03-21 12:19:02 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2527364)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 500
wg.worker_names: ['EUM3eAActorRolloutRefWorker_0:0', 'EUM3eAActorRolloutRefWorker_0:1', 'EUM3eAActorRolloutRefWorker_0:2', 'EUM3eAActorRolloutRefWorker_0:3', 'EUM3eAActorRolloutRefWorker_0:4', 'EUM3eAActorRolloutRefWorker_0:5', 'EUM3eAActorRolloutRefWorker_0:6', 'EUM3eAActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
[36m(ActorRolloutRefWorker pid=2526478)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=2526478)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:19:13 metrics.py:345] Avg prompt throughput: 1229.4 tokens/s, Avg generation throughput: 390.0 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2526478)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:19:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3103.6 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:19:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3123.8 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:19:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3048.3 tokens/s, Running: 61 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:19:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3013.7 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:19:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3020.6 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:19:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2494.7 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:19:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2333.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:19:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2104.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:20:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1686.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527363)[0m INFO 03-21 12:20:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1629.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:20:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2073.5 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:20:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1843.9 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:20:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1420.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:20:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1321.6 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:20:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1218.8 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:20:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1101.1 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:20:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1355.8 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:20:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1224.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:20:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 893.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:21:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 813.6 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:21:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 900.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:21:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 843.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:21:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1019.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:21:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1017.2 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:21:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 883.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:21:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 772.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:21:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 650.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:21:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 588.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:21:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 597.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:22:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 898.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:22:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 896.9 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:22:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 660.5 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:22:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 619.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:22:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 472.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:22:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 595.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:22:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 534.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:22:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 775.8 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:22:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 776.5 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:22:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 351.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:22:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 333.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:23:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 340.3 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:23:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 471.8 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:23:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 341.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:23:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 341.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:23:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 592.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:23:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:23:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:23:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 205.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:23:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 343.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:23:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:24:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 222.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:24:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 592.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:24:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 592.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:24:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:24:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:24:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:24:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:24:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:24:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:24:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 592.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:24:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:25:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:25:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:25:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:25:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:25:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527369)[0m INFO 03-21 12:25:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 266.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:25:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 592.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:25:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 591.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:25:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:25:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 205.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:25:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:26:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:26:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:26:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:26:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 466.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:26:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:26:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 205.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:26:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:26:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527365)[0m INFO 03-21 12:26:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:26:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.7 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527364)[0m INFO 03-21 12:27:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m INFO 03-21 12:27:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 205.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:27:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527367)[0m INFO 03-21 12:27:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527363)[0m INFO 03-21 12:27:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:27:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527369)[0m INFO 03-21 12:27:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 200.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                          |
+======================+================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                                                                                                                                                                   |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.826                                                                                                                                                                                                                                          |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@1               | 0.826                                                                                                                                                                                                                                          |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5653.564                                                                                                                                                                                                                                       |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.1635623190800349                                                                                                                                                                                                                             |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2526478)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2526478)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2527368)[0m INFO 03-21 12:27:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%.
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 12:28:11,088	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2553532)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2553532)[0m No module named 'vllm._version'
[36m(pid=2553532)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2554435)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2554435)[0m No module named 'vllm._version'
[36m(pid=2554435)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2554463)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2554463)[0m No module named 'vllm._version'
[36m(pid=2554463)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2554435)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=2554442)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2554442)[0m   warnings.warn(
[36m(pid=2554449)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=2554449)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2554449)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554424)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (17690 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2553532)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2553532)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60",
[36m(ActorRolloutRefWorker pid=2553532)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2553532)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2553532)[0m   ],
[36m(ActorRolloutRefWorker pid=2553532)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2553532)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2553532)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2553532)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2553532)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2553532)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2553532)[0m }
[36m(ActorRolloutRefWorker pid=2553532)[0m 
[36m(ActorRolloutRefWorker pid=2553532)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2553532)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2553532)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x15183a637ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2553532)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:28:29 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2554442)[0m WARNING 03-21 12:28:29 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2554457)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x150915aebec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=2554424)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2554430)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2553532)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=2553532)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:28:29 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m WARNING 03-21 12:28:29 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2554449)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=2553532)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['RNnR5sActorRolloutRefWorker_0:0', 'RNnR5sActorRolloutRefWorker_0:1', 'RNnR5sActorRolloutRefWorker_0:2', 'RNnR5sActorRolloutRefWorker_0:3', 'RNnR5sActorRolloutRefWorker_0:4', 'RNnR5sActorRolloutRefWorker_0:5', 'RNnR5sActorRolloutRefWorker_0:6', 'RNnR5sActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:28:42 metrics.py:345] Avg prompt throughput: 1687.0 tokens/s, Avg generation throughput: 466.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2554424)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:28:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2967.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554449)[0m INFO 03-21 12:28:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2988.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:28:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2997.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:29:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3044.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:29:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2995.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:29:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2947.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:29:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2943.2 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554424)[0m INFO 03-21 12:29:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3046.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:29:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2919.2 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554449)[0m INFO 03-21 12:29:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2957.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:29:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2950.6 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:29:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2852.3 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:29:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2758.3 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:30:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2717.4 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554449)[0m INFO 03-21 12:30:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2588.4 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:30:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2727.1 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:30:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2653.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:30:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2647.6 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:30:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2625.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554424)[0m INFO 03-21 12:30:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2659.0 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:30:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2442.3 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554449)[0m INFO 03-21 12:30:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2327.0 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:30:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2528.9 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:30:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2398.2 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:31:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2508.0 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:31:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2506.3 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554424)[0m INFO 03-21 12:31:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2523.6 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:31:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2317.2 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:31:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2233.6 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554449)[0m INFO 03-21 12:31:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2238.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:31:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2234.0 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:31:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2286.2 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:31:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2401.2 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:31:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1935.2 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:32:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2085.5 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:32:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1852.2 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:32:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2173.0 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:32:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2150.7 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:32:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2149.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:32:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2128.2 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:32:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1942.2 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554449)[0m INFO 03-21 12:32:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1972.2 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:32:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1998.3 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:32:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1702.9 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:32:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1986.1 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:33:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1963.8 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:33:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1703.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:33:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1700.0 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:33:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1565.6 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:33:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1815.1 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:33:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1793.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:33:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1440.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:33:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1477.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:33:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1380.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:33:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1689.8 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:34:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1671.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:34:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1647.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:34:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1259.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:34:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1326.5 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:34:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1192.6 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:34:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1529.8 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:34:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1425.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:34:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1397.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:34:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1167.4 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:34:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1079.8 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:35:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1001.0 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:35:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1410.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:35:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1178.0 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:35:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1122.8 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:35:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1022.0 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:35:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1018.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:35:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 731.3 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:35:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1280.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:35:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1043.4 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:35:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1041.2 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:35:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 848.9 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:36:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 914.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:36:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 914.8 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:36:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 636.8 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:36:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1216.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:36:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 651.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:36:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 650.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:36:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 797.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:36:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 578.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:36:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1155.5 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:36:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 390.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:37:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 530.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554449)[0m INFO 03-21 12:37:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 688.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:37:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 632.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:37:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 586.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:37:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 458.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554457)[0m INFO 03-21 12:37:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 950.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:37:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 459.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:37:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 459.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m INFO 03-21 12:37:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 508.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:37:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 575.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554442)[0m INFO 03-21 12:38:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 574.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554430)[0m INFO 03-21 12:38:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 335.0 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:38:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2553532)[0m INFO 03-21 12:38:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 397.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:38:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 892.9 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:38:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 892.3 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:38:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 799.8 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:38:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 801.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:38:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 799.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:38:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 799.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2554463)[0m INFO 03-21 12:39:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 779.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                          |
+======================+================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                                                                                                                                                                   |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.29375                                                                                                                                                                                                                                        |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@16              | 0.7333333333333333                                                                                                                                                                                                                             |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@16              | 0.5166666666666667                                                                                                                                                                                                                             |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16502.5875                                                                                                                                                                                                                                     |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.18622457451290553                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2554435)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2554435)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 12:39:36,520	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2583608)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2583608)[0m No module named 'vllm._version'
[36m(pid=2583608)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2584505)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2584505)[0m No module named 'vllm._version'
[36m(pid=2584505)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2584500)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2584500)[0m No module named 'vllm._version'
[36m(pid=2584500)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2583608)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=2584504)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=2584504)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2584504)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2584502)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=2584505)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (16590 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2583608)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2583608)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90",
[36m(ActorRolloutRefWorker pid=2583608)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2583608)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2583608)[0m   ],
[36m(ActorRolloutRefWorker pid=2583608)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2583608)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2583608)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2583608)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2583608)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2583608)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2583608)[0m }
[36m(ActorRolloutRefWorker pid=2583608)[0m 
[36m(ActorRolloutRefWorker pid=2583608)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2583608)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2583608)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x144856f3bec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2583608)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=2584504)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x144644023ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:40:27 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2584502)[0m WARNING 03-21 12:40:27 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2584501)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2584502)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2583608)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=2583608)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:40:28 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m WARNING 03-21 12:40:28 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2584500)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
len(dataset): 500
wg.worker_names: ['Ku9cA0ActorRolloutRefWorker_0:0', 'Ku9cA0ActorRolloutRefWorker_0:1', 'Ku9cA0ActorRolloutRefWorker_0:2', 'Ku9cA0ActorRolloutRefWorker_0:3', 'Ku9cA0ActorRolloutRefWorker_0:4', 'Ku9cA0ActorRolloutRefWorker_0:5', 'Ku9cA0ActorRolloutRefWorker_0:6', 'Ku9cA0ActorRolloutRefWorker_0:7']
[1/1] Start to process.
[36m(ActorRolloutRefWorker pid=2583608)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=2583608)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:40:40 metrics.py:345] Avg prompt throughput: 1230.5 tokens/s, Avg generation throughput: 830.8 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2584503)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:40:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3174.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:40:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3104.6 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:40:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3090.1 tokens/s, Running: 61 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:41:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3070.5 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:41:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2852.9 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:41:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2455.6 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:41:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2490.4 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:41:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2101.2 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:41:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1978.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584503)[0m INFO 03-21 12:41:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1579.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:41:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1526.0 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:41:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1407.5 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584506)[0m INFO 03-21 12:41:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1229.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:42:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1426.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:42:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1199.5 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:42:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 778.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:42:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 667.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:42:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1171.5 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:42:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1061.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:42:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 857.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:42:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 851.8 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:42:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 925.1 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:42:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 663.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584506)[0m INFO 03-21 12:42:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 778.7 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:43:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 867.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:43:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 836.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:43:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 696.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:43:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 835.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:43:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 537.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:43:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 588.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:43:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 791.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:43:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 540.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:43:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 482.3 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584503)[0m INFO 03-21 12:43:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 577.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:44:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584506)[0m INFO 03-21 12:44:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 408.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 13x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:44:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 782.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:44:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 344.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:44:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 281.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584500)[0m INFO 03-21 12:44:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 405.3 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:44:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 278.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:44:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:44:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 603.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:44:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:45:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584500)[0m INFO 03-21 12:45:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 404.3 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2583608)[0m INFO 03-21 12:45:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 82.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:45:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:45:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 539.9 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:45:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:45:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 277.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:45:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 402.0 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:45:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 373.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:45:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:46:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 475.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:46:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:46:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:46:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 272.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:46:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 272.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:46:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:46:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 386.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:46:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:46:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584500)[0m INFO 03-21 12:46:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 341.9 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:46:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:47:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:47:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 214.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:47:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:47:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:47:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 150.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584500)[0m INFO 03-21 12:47:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 341.8 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584506)[0m INFO 03-21 12:47:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 140.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:47:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 136.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:47:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 205.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:47:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:48:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:48:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 207.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:48:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 140.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584504)[0m INFO 03-21 12:48:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 140.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584500)[0m INFO 03-21 12:48:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584500)[0m INFO 03-21 12:48:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m INFO 03-21 12:48:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 70.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:48:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:48:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:48:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 206.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584502)[0m INFO 03-21 12:48:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 196.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584503)[0m INFO 03-21 12:49:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584503)[0m INFO 03-21 12:49:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                          |
+======================+================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                                                                                                                                                                   |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.832                                                                                                                                                                                                                                          |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@1               | 0.832                                                                                                                                                                                                                                          |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5653.49                                                                                                                                                                                                                                        |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.1630826394425498                                                                                                                                                                                                                             |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2584505)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584505)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2584501)[0m INFO 03-21 12:49:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 116.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 12:49:37,296	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2610678)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2610678)[0m No module named 'vllm._version'
[36m(pid=2610678)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2611621)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2611621)[0m No module named 'vllm._version'
[36m(pid=2611621)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2611623)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2611623)[0m No module named 'vllm._version'
[36m(pid=2611623)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2611621)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=2611622)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2611622)[0m   warnings.warn(
[36m(pid=2611622)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=2611622)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2611622)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (19079 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2610678)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2610678)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90",
[36m(ActorRolloutRefWorker pid=2610678)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2610678)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2610678)[0m   ],
[36m(ActorRolloutRefWorker pid=2610678)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2610678)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2610678)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2610678)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2610678)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2610678)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2610678)[0m }
[36m(ActorRolloutRefWorker pid=2610678)[0m 
[36m(ActorRolloutRefWorker pid=2610678)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2610678)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2610678)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x142a651cfec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2610678)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:49:55 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2611621)[0m WARNING 03-21 12:49:55 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2611620)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14e1d30efec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=2611621)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2611621)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2610678)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=2610678)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:49:55 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m WARNING 03-21 12:49:55 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2611611)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=2610678)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['4ww0qgActorRolloutRefWorker_0:0', '4ww0qgActorRolloutRefWorker_0:1', '4ww0qgActorRolloutRefWorker_0:2', '4ww0qgActorRolloutRefWorker_0:3', '4ww0qgActorRolloutRefWorker_0:4', '4ww0qgActorRolloutRefWorker_0:5', '4ww0qgActorRolloutRefWorker_0:6', '4ww0qgActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:50:07 metrics.py:345] Avg prompt throughput: 1688.2 tokens/s, Avg generation throughput: 586.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2611611)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:50:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2975.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:50:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3024.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:50:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3026.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:50:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2980.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:50:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2990.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:50:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2991.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:50:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2993.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:50:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2774.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:50:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2955.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:51:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2996.4 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:51:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2858.4 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:51:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2920.5 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:51:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2854.2 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:51:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2844.3 tokens/s, Running: 57 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:51:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2720.6 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:51:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2709.7 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:51:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2706.9 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:51:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2705.3 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:51:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2567.5 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:51:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2564.1 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:52:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2596.3 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:52:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2276.3 tokens/s, Running: 50 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:52:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2489.7 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:52:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2447.3 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:52:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2235.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:52:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2397.6 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:52:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2393.7 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:52:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2295.9 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:52:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2354.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:52:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2428.1 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:53:02 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2397.4 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:53:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2327.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:53:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2092.7 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:53:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2082.3 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:53:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2075.5 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:53:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2118.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:53:37 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2223.9 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:53:42 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2235.2 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:53:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2097.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:53:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1900.4 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:53:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1887.4 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:54:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1945.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:54:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1931.9 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:54:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1961.3 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:54:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1841.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:54:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1808.3 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:54:32 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1839.4 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:54:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1702.9 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:54:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1700.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:54:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1791.6 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:54:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1785.6 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:54:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1606.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:55:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1586.5 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:55:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1699.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:55:17 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1613.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:55:22 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1592.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:55:27 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1459.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:55:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1527.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:55:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1483.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:55:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1379.8 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:55:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1528.6 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:55:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1327.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:55:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1297.1 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:56:07 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1368.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:56:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1470.0 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:56:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1189.9 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:56:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1295.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:56:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1293.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:56:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1148.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:56:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1342.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 12:56:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1432.9 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:56:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 978.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:56:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1097.8 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:57:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1254.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:57:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1078.7 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:57:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 940.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:57:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1161.2 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:57:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1002.6 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:57:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1238.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 20.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 12:57:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1290.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 22.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:57:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 778.7 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:57:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 861.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:57:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1003.6 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611623)[0m INFO 03-21 12:57:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 844.9 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:58:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1032.7 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:58:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 709.4 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:58:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 703.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:58:18 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 970.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:58:23 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 698.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:58:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 698.2 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 12:58:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1166.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 23.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:58:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 619.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:58:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 799.6 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:58:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 509.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611621)[0m INFO 03-21 12:58:58 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 590.7 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:59:03 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 858.9 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:59:08 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 859.3 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m INFO 03-21 12:59:13 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 515.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 12:59:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 945.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:59:28 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 680.8 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611617)[0m INFO 03-21 12:59:33 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 686.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611622)[0m INFO 03-21 12:59:38 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 333.4 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611603)[0m INFO 03-21 12:59:43 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 638.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:59:48 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 746.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2610678)[0m INFO 03-21 12:59:53 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 740.8 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 12:59:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 889.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 879.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.4%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 778.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 2x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 780.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 780.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 779.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 733.3 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 695.4 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2611620)[0m INFO 03-21 13:00:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 603.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.8%, CPU KV cache usage: 0.0%.
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                          |
+======================+================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                                                                                                                                                                   |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.29583333333333334                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@16              | 0.8                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@16              | 0.5227513227513227                                                                                                                                                                                                                             |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                            |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16979.1                                                                                                                                                                                                                                        |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.1889087747202979                                                                                                                                                                                                                             |
+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2611611)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2611611)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ for MODEL_NAME in DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-30 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-60 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-90 DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ MODEL_PATH=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ OUTPUT_DIR=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ DATA_TYPE=math
+ N=1
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=1 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 13:01:11,715	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2641173)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2641173)[0m No module named 'vllm._version'
[36m(pid=2641173)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2642111)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2642111)[0m No module named 'vllm._version'
[36m(pid=2642111)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2642110)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2642110)[0m No module named 'vllm._version'
[36m(pid=2642110)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2642113)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=2642115)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=2642115)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2642115)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2642113)[0m   warnings.warn(
[36m(ActorRolloutRefWorker pid=2642111)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (32692 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 1,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132/math/math_n_1_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/math.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2641173)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2641173)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132",
[36m(ActorRolloutRefWorker pid=2641173)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2641173)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2641173)[0m   ],
[36m(ActorRolloutRefWorker pid=2641173)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2641173)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2641173)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2641173)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2641173)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2641173)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2641173)[0m }
[36m(ActorRolloutRefWorker pid=2641173)[0m 
[36m(ActorRolloutRefWorker pid=2641173)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2641173)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2641173)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x144a7c1cfec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2641173)[0m Before building vllm rollout, memory allocated (GB): 0.43093395233154297, memory reserved (GB): 3.32421875
[36m(ActorRolloutRefWorker pid=2642114)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x1483f2e2fec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642111)[0m INFO 03-21 13:01:56 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2642111)[0m WARNING 03-21 13:01:56 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2642111)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2642112)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2641173)[0m before init cache memory allocated: 4.063946752GB, reserved: 4.217372672GB
[36m(ActorRolloutRefWorker pid=2641173)[0m after init cache memory allocated: 78.579951616GB, reserved: 78.733377536GB
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:01:58 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m WARNING 03-21 13:01:58 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2642114)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m After building vllm rollout, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
[36m(ActorRolloutRefWorker pid=2641173)[0m After building sharding manager, memory allocated (GB): 69.86855983734131, memory reserved (GB): 73.326171875
len(dataset): 500
wg.worker_names: ['dgo83JActorRolloutRefWorker_0:0', 'dgo83JActorRolloutRefWorker_0:1', 'dgo83JActorRolloutRefWorker_0:2', 'dgo83JActorRolloutRefWorker_0:3', 'dgo83JActorRolloutRefWorker_0:4', 'dgo83JActorRolloutRefWorker_0:5', 'dgo83JActorRolloutRefWorker_0:6', 'dgo83JActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Convert the point $(0,3)$ in rectangular coordinates to polar '
              'coordinates.  Enter your answer in the form $(r,\\theta),$ '
              "where $r > 0$ and $0 \\le \\theta < 2 \\pi.$ Let's think step "
              'by step and output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Define\n'
              '\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2} \\quad \\text{and} '
              '\\quad q = \\sum_{k = 1}^\\infty \\frac{1}{k^3}.\\]Find a way '
              'to write\n'
              '\\[\\sum_{j = 1}^\\infty \\sum_{k = 1}^\\infty \\frac{1}{(j + '
              "k)^3}\\]in terms of $p$ and $q.$ Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) '
              "+f(-1)+f(0)$? Express your answer as a common fraction. Let's "
              'think step by step and output the final answer within '
              '\\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([500, 809]), content: tensor([[  220,    15,     3,   323,   400,    15],
        [  488,   595, 29776,    18, 11035,    60],
        [ 4080,    16,  7257,    69,     7,    15],
        ...,
        [23921, 11067,   614,   279,  1852,  3084],
        [   64,    62,    18,   284,   264,    62],
        [  284,   220,    20,    17, 24884, 43298]])
dp_size 8 is not divisible by real_batch_size 500, add 4 dummy data
[1/1] Start to generate.
ZHS batch len: 504
[36m(ActorRolloutRefWorker pid=2642113)[0m INFO 03-21 13:02:10 metrics.py:345] Avg prompt throughput: 1229.7 tokens/s, Avg generation throughput: 490.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2642115)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m INFO 03-21 13:02:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3131.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:02:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3006.5 tokens/s, Running: 62 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642109)[0m INFO 03-21 13:02:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3117.7 tokens/s, Running: 63 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:02:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2999.9 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:02:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2842.4 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:02:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2740.5 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m INFO 03-21 13:02:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2314.3 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:02:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2109.1 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642109)[0m INFO 03-21 13:03:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1819.5 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:03:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1488.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:03:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1593.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:03:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1457.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:03:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1306.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:03:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1227.4 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m INFO 03-21 13:03:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 990.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642109)[0m INFO 03-21 13:03:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1198.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:03:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1020.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:03:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 997.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:03:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 902.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:04:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1012.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:04:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 777.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m INFO 03-21 13:04:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 643.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:04:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 836.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:04:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 723.7 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:04:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 656.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:04:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 608.9 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:04:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 536.9 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:04:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 654.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:04:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 599.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:05:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 469.4 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:05:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 468.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:05:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 454.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:05:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 455.0 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m INFO 03-21 13:05:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 209.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:05:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 470.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:05:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 470.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:05:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:05:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 454.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:05:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 454.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642113)[0m INFO 03-21 13:06:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 140.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:06:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 405.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:06:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 405.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:06:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 274.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:06:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 585.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:06:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 453.9 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:06:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:06:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 276.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642112)[0m INFO 03-21 13:06:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 274.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:06:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 523.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:07:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 453.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:07:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:07:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:07:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 522.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:07:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 452.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:07:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 401.0 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:07:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:07:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:07:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 521.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.4%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:07:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 521.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:08:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 263.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:08:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:08:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 275.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:08:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 395.3 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 12x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:08:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 395.6 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:08:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 199.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:08:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 183.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:08:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 83.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:08:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 334.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:08:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 334.5 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:09:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 198.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:09:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:09:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 72.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:09:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 269.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:09:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 198.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:09:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:09:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:09:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 203.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:09:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 203.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:09:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 199.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:10:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2641173)[0m INFO 03-21 13:10:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:10:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 203.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:10:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 203.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:10:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 199.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642111)[0m INFO 03-21 13:10:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 73.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m INFO 03-21 13:10:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 203.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%.[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642114)[0m INFO 03-21 13:10:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 167.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                           |
+======================+=================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132 |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | math.parquet                                                                                                                                                                                                                                    |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.836                                                                                                                                                                                                                                           |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@1               | 0.836                                                                                                                                                                                                                                           |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                             |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 5559.782                                                                                                                                                                                                                                        |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.1635301594601737                                                                                                                                                                                                                              |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2642115)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2642115)[0m   warnings.warn([32m [repeated 7x across cluster][0m
+ DATA_TYPE=aime
+ N=16
+ echo 'Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Model Path: /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ echo 'Datasets: '
Datasets: 
+ echo 'Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132'
Output Directory: /GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132
+ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet data.output_path=/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json data.n_samples=16 data.batch_size=2048 model.path=/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132 rollout.temperature=0.6 rollout.response_length=32768 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.95 rollout.tensor_model_parallel_size=1 +data.skip_format_reward=True
/GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
ANTLR runtime and generated code versions disagree: 4.7.2!=4.9.3
2025-03-21 13:11:52,132	INFO worker.py:1841 -- Started a local Ray instance.
[36m(pid=2669668)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2669668)[0m No module named 'vllm._version'
[36m(pid=2669668)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2670560)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2670560)[0m No module named 'vllm._version'
[36m(pid=2670560)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=2670552)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=2670552)[0m No module named 'vllm._version'
[36m(pid=2670552)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(ActorRolloutRefWorker pid=2669668)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorRolloutRefWorker pid=2670552)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(ActorRolloutRefWorker pid=2670552)[0m   warnings.warn(
[36m(pid=2670559)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 5x across cluster][0m
[36m(pid=2670559)[0m No module named 'vllm._version'[32m [repeated 5x across cluster][0m
[36m(pid=2670559)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 5x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
Token indices sequence length is longer than the specified maximum sequence length for this model (24098 > 16384). Running this sequence through the model will result in indexing errors
{'actor': {'fsdp_config': {'fsdp_size': -1,
                           'grad_offload': False,
                           'optimizer_offload': False,
                           'param_offload': False,
                           'wrap_policy': {'min_num_params': 0}},
           'optim': {'lr': 1e-06,
                     'lr_warmup_steps_ratio': 0.0,
                     'min_lr_ratio': None,
                     'total_training_steps': -1,
                     'warmup_style': 'constant'},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 2048,
          'data_source_key': 'data_source',
          'n_samples': 16,
          'output_path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/eval_outputs/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132/aime/aime_n_16_temp_0.6_topp_0.95_maxlen_32768.json',
          'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/deepscaler-release/processed_data/aime.parquet',
          'prompt_key': 'prompt',
          'response_key': 'responses',
          'reward_model_key': 'reward_model',
          'skip_format_reward': True},
 'model': {'external_lib': None,
           'path': '/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132'},
 'rollout': {'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.95,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': 8,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'micro_batch_size': 256,
             'n': 1,
             'n_val': 1,
             'name': 'vllm',
             'prompt_length': 1536,
             'response_length': 32768,
             'temperature': 0.6,
             'tensor_model_parallel_size': 1,
             'top_k': -1,
             'top_p': 0.95},
 'trainer': {'n_gpus_per_node': 8, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=2669668)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=2669668)[0m   "_name_or_path": "/GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132",
[36m(ActorRolloutRefWorker pid=2669668)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=2669668)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=2669668)[0m   ],
[36m(ActorRolloutRefWorker pid=2669668)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "bos_token_id": 151646,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "eos_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=2669668)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "max_position_embeddings": 131072,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=2669668)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "rope_theta": 10000,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "tie_word_embeddings": false,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "torch_dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=2669668)[0m   "transformers_version": "4.45.2",
[36m(ActorRolloutRefWorker pid=2669668)[0m   "use_cache": false,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "use_mrope": false,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=2669668)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=2669668)[0m }
[36m(ActorRolloutRefWorker pid=2669668)[0m 
[36m(ActorRolloutRefWorker pid=2669668)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2669668)[0m Qwen2ForCausalLM contains 1.78B parameters
[36m(ActorRolloutRefWorker pid=2669668)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14cdccbf7ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(ActorRolloutRefWorker pid=2669668)[0m Before building vllm rollout, memory allocated (GB): 0.4375143051147461, memory reserved (GB): 3.330078125
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:12:10 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ActorRolloutRefWorker pid=2670552)[0m WARNING 03-21 13:12:10 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(ActorRolloutRefWorker pid=2670562)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x14867a547ec0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ActorRolloutRefWorker pid=2669668)[0m local rank 0
[36m(ActorRolloutRefWorker pid=2670552)[0m NCCL version 2.20.5+cuda12.4
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:12:11 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m WARNING 03-21 13:12:11 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m local rank 0[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m before init cache memory allocated: 4.071012352GB, reserved: 4.223664128GB
[36m(ActorRolloutRefWorker pid=2670552)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(ActorRolloutRefWorker pid=2670562)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m after init cache memory allocated: 78.554445824GB, reserved: 78.739668992GB
[36m(ActorRolloutRefWorker pid=2669668)[0m After building vllm rollout, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
[36m(ActorRolloutRefWorker pid=2669668)[0m After building sharding manager, memory allocated (GB): 69.84480571746826, memory reserved (GB): 73.33203125
len(dataset): 30
wg.worker_names: ['to3T1SActorRolloutRefWorker_0:0', 'to3T1SActorRolloutRefWorker_0:1', 'to3T1SActorRolloutRefWorker_0:2', 'to3T1SActorRolloutRefWorker_0:3', 'to3T1SActorRolloutRefWorker_0:4', 'to3T1SActorRolloutRefWorker_0:5', 'to3T1SActorRolloutRefWorker_0:6', 'to3T1SActorRolloutRefWorker_0:7']
[1/1] Start to process.
repeated_chat_lst0
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}]]
repeated_chat_lst1
[[{'content': 'Every morning Aya goes for a $9$-kilometer-long walk and stops '
              'at a coffee shop afterwards. When she walks at a constant speed '
              'of $s$ kilometers per hour, the walk takes her 4 hours, '
              'including $t$ minutes spent in the coffee shop. When she walks '
              '$s+2$ kilometers per hour, the walk takes her 2 hours and 24 '
              'minutes, including $t$ minutes spent in the coffee shop. '
              'Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find '
              'the number of minutes the walk takes her, including the $t$ '
              "minutes spent in the coffee shop. Let's think step by step and "
              'output the final answer within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'There exist real numbers $x$ and $y$, both greater than 1, such '
              'that '
              '$\\log_x\\left(y^x\\right)=\\log_y\\left(x^{4y}\\right)=10$. '
              "Find $xy$. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}],
 [{'content': 'Alice and Bob play the following game. A stack of $n$ tokens '
              'lies before them. The players take turns with Alice going '
              'first. On each turn, the player removes either $1$ token or $4$ '
              'tokens from the stack. Whoever removes the last token wins. '
              'Find the number of positive integers $n$ less than or equal to '
              '$2024$ for which there exists a strategy for Bob that '
              "guarantees that Bob will win the game regardless of Alice's "
              "play. Let's think step by step and output the final answer "
              'within \\boxed{}.',
   'role': 'user'}]]
main_gen.py, input_ids.shape = torch.Size([480, 411]), content: tensor([[ 4227,  4990,  1059,    11,  2670,   279],
        [   59,  2359,  2075, 47822,    19,    88],
        [  369, 14261,   429, 35655,   429, 14261],
        ...,
        [32696, 47822,    17,    74,  5410,    59],
        [ 1091,  5779, 17767,    65,    59,  1318],
        [   13,    18,    21,    21,    11,    15]])
[1/1] Start to generate.
ZHS batch len: 480
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:12:24 metrics.py:345] Avg prompt throughput: 1237.6 tokens/s, Avg generation throughput: 8.8 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
[36m(ActorRolloutRefWorker pid=2670562)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 32768, 'detokenize': False, 'temperature': 0.6, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:12:29 metrics.py:345] Avg prompt throughput: 52.3 tokens/s, Avg generation throughput: 2972.5 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:12:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3031.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:12:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3030.0 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:12:44 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2990.9 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:12:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2985.3 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:12:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2959.7 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:13:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2953.8 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:13:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3005.1 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670563)[0m INFO 03-21 13:13:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2962.6 tokens/s, Running: 60 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:13:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2965.3 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:13:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2965.0 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:13:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2918.9 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:13:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2843.6 tokens/s, Running: 56 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:13:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2870.8 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:13:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2775.5 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:13:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2785.8 tokens/s, Running: 55 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.9%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:13:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2666.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:14:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2597.2 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:14:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2623.3 tokens/s, Running: 52 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:14:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2632.0 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:14:21 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2610.9 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:14:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2262.7 tokens/s, Running: 49 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:14:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2465.0 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:14:39 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2464.5 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:14:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2188.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:14:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2449.6 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:14:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2274.9 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:15:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2525.4 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670563)[0m INFO 03-21 13:15:09 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2330.2 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:15:14 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2479.8 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:15:19 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2202.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:15:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2189.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:15:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1943.2 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:15:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2103.6 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:15:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2329.4 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:15:49 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2193.7 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:15:54 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2190.2 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:15:59 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2013.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:16:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1843.8 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:16:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1935.3 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:16:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2099.3 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670563)[0m INFO 03-21 13:16:24 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1975.9 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:16:29 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1949.8 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:16:34 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1891.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.0%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:16:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1500.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:16:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1525.2 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:16:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1824.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:16:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1816.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670563)[0m INFO 03-21 13:17:04 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1578.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:17:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1715.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:17:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1582.2 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:17:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1255.6 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:17:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1623.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:17:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1506.8 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:17:36 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1633.2 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:17:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1530.2 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:17:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1530.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:17:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1148.3 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.2%, CPU KV cache usage: 0.0%.[32m [repeated 11x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:18:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1385.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:18:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1306.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:18:11 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1334.4 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670563)[0m INFO 03-21 13:18:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1245.2 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:18:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1470.0 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.9%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:18:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1446.4 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.4%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:18:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1360.8 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:18:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1038.3 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:18:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1037.2 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:18:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1261.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:18:56 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 899.1 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:19:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1129.7 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:19:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1129.5 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670563)[0m INFO 03-21 13:19:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 983.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:19:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1294.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:19:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1238.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.6%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:19:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 931.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:19:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1010.6 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:19:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 748.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:19:46 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 747.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 8x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:19:51 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1026.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:20:00 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1158.7 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:20:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1149.8 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.0%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:20:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1132.0 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:20:15 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 779.2 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:20:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 688.3 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:20:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 802.4 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:20:31 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 760.0 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:20:40 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1067.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 18.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670558)[0m INFO 03-21 13:20:45 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 641.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.8%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:20:50 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 644.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.1%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:20:55 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 559.8 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:21:01 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 965.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:21:06 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 516.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.9%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:21:12 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 652.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670563)[0m INFO 03-21 13:21:20 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 704.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:21:25 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 991.1 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 19.2%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670552)[0m INFO 03-21 13:21:30 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 522.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.7%, CPU KV cache usage: 0.0%.[32m [repeated 10x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670559)[0m INFO 03-21 13:21:35 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 501.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:21:41 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 793.5 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.8%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m INFO 03-21 13:21:47 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 454.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:21:52 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 460.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.[32m [repeated 9x across cluster][0m
[36m(ActorRolloutRefWorker pid=2669668)[0m INFO 03-21 13:21:57 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 461.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:22:05 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 868.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670561)[0m INFO 03-21 13:22:10 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 866.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:22:16 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 636.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.[32m [repeated 4x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670560)[0m INFO 03-21 13:22:26 metrics.py:345] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 499.4 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.[32m [repeated 3x across cluster][0m
<class 'list'> <class 'str'>
length cutoff ratio: 0.0
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Metric               | Value                                                                                                                                                                                                                                           |
+======================+=================================================================================================================================================================================================================================================+
| model_path           | /GLOBALFS/gznwp_3/qxj/lgzhong/LLaMA-Factory/saves/fuser1/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k/DeepSeek-R1-Distill-Qwen-1.5B-armo-judge-sol-dpo-beta0.1-lr5e-7-ep1-bs16-cutoff-16k-checkpoint-132 |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| dataset              | aime.parquet                                                                                                                                                                                                                                    |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@1               | 0.2791666666666667                                                                                                                                                                                                                              |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pass@16              | 0.6666666666666666                                                                                                                                                                                                                              |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cons@16              | 0.4847222222222222                                                                                                                                                                                                                              |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| cutoff_raio          | 0.0                                                                                                                                                                                                                                             |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| mean_response_tokens | 16436.795833333334                                                                                                                                                                                                                              |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| run_hours            | 0.18011359916792977                                                                                                                                                                                                                             |
+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[36m(ActorRolloutRefWorker pid=2670562)[0m /GLOBALFS/gznwp_3/anaconda3/envs/360_llama_fac/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(ActorRolloutRefWorker pid=2670562)[0m   warnings.warn([32m [repeated 7x across cluster][0m
